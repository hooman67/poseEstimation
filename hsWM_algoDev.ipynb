{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import openpyxl as oxl\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from copy import deepcopy\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "#this is to automatically parse xml into dict\n",
    "import xmltodict\n",
    "\n",
    "import collections\n",
    "\n",
    "import math\n",
    "\n",
    "#for finding the shortest distance btw curve and point\n",
    "from scipy.optimize import fmin_cobyla\n",
    "\n",
    "# This is needed if the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "#imports from object-detection module\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preparing WM logs using keyPoint detection and YOLO LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Method Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def draw_patch_keypoints(image, patch_keypoints, validKeypoints = []):\n",
    "    colors = [[255, 255, 51], [0, 255, 0], [0, 0, 255], [255, 0, 0], [153, 255, 255]]\n",
    "    circle_radius=5\n",
    "\n",
    "    for i, joint_keypoint in enumerate(patch_keypoints):\n",
    "        x, y = joint_keypoint\n",
    "        \n",
    "        if x == 0 or y == 0:\n",
    "            continue\n",
    "            \n",
    "        if len(validKeypoints) > 1 and joint_keypoint not in validKeypoints:\n",
    "            continue\n",
    "\n",
    "        cv2.circle(image, (x, y), circle_radius, colors[i], -1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def draw_fittedCurves_for1setOfKeypoints(image, setof_keypoints, esimatorFunction, colorNb=0):\n",
    "    #colors = [[204, 0, 204], [255, 255, 51], [255, 51, 255], [153, 51, 255], [255, 102, 255], [178, 102, 255]]\n",
    "    colors = [[255, 255, 51], [0, 255, 0], [0, 0, 255], [255, 0, 0], [153, 255, 255]]\n",
    "    \n",
    "    #pts = [[p[0], int(esimatorFunction(p[0]))] for p in setof_keypoints if(p[0] > 0 and p[1]>0)]\n",
    "    pts = [[indx, int(esimatorFunction(indx))] for indx in range(10, 600, 50)]\n",
    "    pts_np = np.array(pts, np.int32)\n",
    "    pts_np = pts_np.reshape((-1,1,2))\n",
    "    cv2.polylines(image,[pts_np],False,colors[colorNb])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def draw_box(image, box):\n",
    "    colors = [(0, 255, 0), (0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0),(0, 255, 255)]\n",
    "    labels=[\"Tooth\", \"Toothline\", \"BucketBB\", \"MatInside\", \"WearArea\"]\n",
    "    image_h, image_w, _ = image.shape\n",
    "    \n",
    "    if len(box) > 3:\n",
    "        xmin = int(box[0] * image_w)\n",
    "        xmax = int(box[1] * image_w)\n",
    "        ymin = int(box[2] * image_h)\n",
    "        ymax = int(box[3] * image_h)\n",
    "        label, score = box[4:6]\n",
    "        #print(str(xmin) + '  ' + str(xmax) + '  '  + str(ymin) + '  ' + str(ymax) + '  ' + label)\n",
    "        \n",
    "        #add tooth length (from box) as a field\n",
    "        box.append(ymax-ymin)\n",
    "\n",
    "        if xmin < 0: xmin = 0\n",
    "        if ymin < 0: ymin = 0\n",
    "\n",
    "        color = colors[labels.index(label)]\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "\n",
    "        font_increase = 1.\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            str(score),\n",
    "            (xmin, ymin - 6),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            8e-4 * image_h * font_increase,\n",
    "            color, 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def draw_all_boxes(image, boxesDict):\n",
    "    for key in boxesDict.keys():\n",
    "        if 'keypoints' not in key and key not in ['nbOfDetectedTeeth','fileName', 'fittedCurves', '2ndDerivFittedCurves']:\n",
    "            image = draw_box(image, boxesDict[key])\n",
    "            \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def draw_all_keypoints_boxes_andCurves(inImage, resultsDict, numberOfTeeth, refKey='', regTypeKeyword='', drawOnlyValidated=False, doNotDrawBoxes=True, numberOflandmarksIncludingToothTip = 5):\n",
    "\n",
    "    image = inImage.copy()\n",
    "    \n",
    "    if regTypeKeyword == '':\n",
    "        esimatorFunctions = resultsDict['fittedCurves']\n",
    "        \n",
    "        for toothNb in range(numberOfTeeth):\n",
    "            toothKeyPointKey = regTypeKeyword + 'keypointsForTooth_' + str(toothNb + 1)\n",
    "\n",
    "            if toothKeyPointKey in resultsDict:\n",
    "\n",
    "                if drawOnlyValidated:\n",
    "                    image = draw_patch_keypoints(image, resultsDict[toothKeyPointKey], resultsDict[regTypeKeyword +'validatedKeypoints'])\n",
    "                else:\n",
    "                    image = draw_patch_keypoints(image, resultsDict[toothKeyPointKey], [])\n",
    "\n",
    "\n",
    "        for keypointNb in range(numberOflandmarksIncludingToothTip):\n",
    "            toothKeyPointKey = 'keypoints_' + str(keypointNb + 1)\n",
    "\n",
    "            if toothKeyPointKey in esimatorFunctions:\n",
    "                image = draw_fittedCurves_for1setOfKeypoints(image, resultsDict[toothKeyPointKey], esimatorFunctions[toothKeyPointKey], colorNb=keypointNb)\n",
    "\n",
    "\n",
    "        if not doNotDrawBoxes:\n",
    "            draw_all_boxes(image, resultsDict)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "    elif (regTypeKeyword + 'fittedCurves') in resultsDict['registrations'][refKey].keys():\n",
    "        esimatorFunctions = resultsDict['registrations'][refKey][regTypeKeyword + 'fittedCurves']\n",
    "    \n",
    "        for toothNb in range(numberOfTeeth):\n",
    "            toothKeyPointKey = regTypeKeyword + 'keypointsForTooth_' + str(toothNb + 1)\n",
    "\n",
    "            if toothKeyPointKey in resultsDict['registrations'][refKey]:\n",
    "\n",
    "                if drawOnlyValidated:\n",
    "                    image = draw_patch_keypoints(image, resultsDict['registrations'][refKey][toothKeyPointKey], resultsDict['validatedKeypoints'])\n",
    "                else:\n",
    "                    image = draw_patch_keypoints(image, resultsDict['registrations'][refKey][toothKeyPointKey], [])\n",
    "\n",
    "\n",
    "        for keypointNb in range(numberOflandmarksIncludingToothTip):\n",
    "            toothKeyPointKey = 'keypoints_' + str(keypointNb + 1)\n",
    "\n",
    "            if toothKeyPointKey in esimatorFunctions:\n",
    "                image = draw_fittedCurves_for1setOfKeypoints(image, resultsDict[toothKeyPointKey], esimatorFunctions[toothKeyPointKey], colorNb=keypointNb)\n",
    "\n",
    "\n",
    "        if not doNotDrawBoxes:\n",
    "            draw_all_boxes(image, resultsDict)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def draw_just_keypoints_fromGroundTruth(inImage, resultsDict, numberOfTeeth, refKey='', numberOflandmarksIncludingToothTip = 5):\n",
    "\n",
    "    image = inImage.copy()\n",
    "        \n",
    "    for toothNb in range(numberOfTeeth):\n",
    "        toothKeyPointKey ='keypointsForTooth_' + str(toothNb + 1)\n",
    "\n",
    "        if toothKeyPointKey in resultsDict:\n",
    "                image = draw_patch_keypoints(image, resultsDict[toothKeyPointKey], [])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dimg(framesDir, fileName, teethBoxes, keypoints):\n",
    "    inImage = cv2.imread(framesDir + fileName.replace('.json','.png'))\n",
    "    outImage = draw_all_keypoints(inImage, data[0], circle_radius=3)\n",
    "    outImage = draw_boxes(outImage, data[1]) \n",
    "    plt.imshow(outImage)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getFrameTime(resultsDict, resultsKey, fileName):\n",
    "    for timeKey in resultsDict[resultsKey].keys():\n",
    "        if fileName in resultsDict[resultsKey][timeKey]['fileName']:\n",
    "            print(timeKey)\n",
    "            print(resultsDict[resultsKey][timeKey]['fileName'])\n",
    "            print('\\n')\n",
    "            return timeKey\n",
    "    \n",
    "    print('could not find the requested file')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loadResults(resultsDir, rawFramesDir=None):\n",
    "    #Load JSON prediciton results from disc into dict\n",
    "    resultsDirectories = []\n",
    "\n",
    "\n",
    "    \n",
    "    #for resultsDir in resultsDirectories:\n",
    "    resultsDir = wmsDir\n",
    "    resultKey = resultsDir.split('/')[-3]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    resultsDic = {}\n",
    "\n",
    "    datetimemask = \"%Y.%m.%d %H.%M.%S\"\n",
    "    \n",
    "    resultsDic[resultKey] = {}\n",
    "\n",
    "    zeroTimeRef = None\n",
    "\n",
    "    for fileName in sorted(os.listdir(resultsDir)):\n",
    "        if fileName and '.json' in fileName:\n",
    "   \n",
    "            fileNameAr = fileName[:len(fileName)-5].split('_')\n",
    "            time = fileNameAr[1] + ' ' + fileNameAr[2]\n",
    "            dateTime = datetime.strptime(time, datetimemask)\n",
    "\n",
    "            curHourSince = 0\n",
    "\n",
    "            if zeroTimeRef == None:\n",
    "                zeroTimeRef = dateTime\n",
    "            else:\n",
    "                timeDif = dateTime - zeroTimeRef\n",
    "                totalSeconds = timeDif.seconds\n",
    "                totalDays = timeDif.days\n",
    "                curHourSince = totalSeconds/3600 + totalDays*24\n",
    "\n",
    "\n",
    "\n",
    "            with open(resultsDir + fileName, 'r') as fjson:\n",
    "                data = tuple(json.load(fjson))\n",
    "                #print(fileName)\n",
    "\n",
    "                resultsDic[resultKey][curHourSince] = {}      \n",
    "                resultsDic[resultKey][curHourSince]['time'] = time\n",
    "                resultsDic[resultKey][curHourSince]['keypoints'] = data[0]\n",
    "                resultsDic[resultKey][curHourSince]['teeth'] = data[1]\n",
    "                resultsDic[resultKey][curHourSince]['buckets'] = data[2]\n",
    "                resultsDic[resultKey][curHourSince]['nbOfDetectedTeeth'] = len(data[1])\n",
    "                resultsDic[resultKey][curHourSince]['fileName'] = resultsDir + fileName.replace('.json', '.png')\n",
    "                tempImage = cv2.imread(resultsDic[resultKey][curHourSince]['fileName'])\n",
    "                image_h, image_w, _ = tempImage.shape\n",
    "                resultsDic[resultKey][curHourSince]['image_h'] = image_h\n",
    "                resultsDic[resultKey][curHourSince]['image_w'] = image_w\n",
    "                \n",
    "\n",
    "\n",
    "            #print(resultsDic)\n",
    "            #dimg(rawFramesDir, fileName, data)\n",
    "            #break\n",
    "\n",
    "\n",
    "\n",
    "    print(\"loaded the results for  \" + str(len(resultsDic[resultKey])) + \"   frames. For key: \" + resultKey)\n",
    "    return resultsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def parseResults(resultsDic, numberOfTeeth):\n",
    "    numberOflandmarksIncludingToothTip = 5\n",
    "    paresedResultsDict = {}\n",
    "    \n",
    "    for resKey in resultsDic.keys():\n",
    "        paresedResultsDict[resKey] = {}\n",
    "        \n",
    "        for time in resultsDic[resKey].keys():\n",
    "            paresedResultsDict[resKey][time] = {}\n",
    "            \n",
    "            paresedResultsDict[resKey][time]['nbOfDetectedTeeth'] = resultsDic[resKey][time]['nbOfDetectedTeeth'] \n",
    "            paresedResultsDict[resKey][time]['fileName'] = resultsDic[resKey][time]['fileName']\n",
    "            paresedResultsDict[resKey][time]['image_h'] = resultsDic[resKey][time]['image_h']\n",
    "            paresedResultsDict[resKey][time]['image_w'] = resultsDic[resKey][time]['image_w']\n",
    "            \n",
    "            #parse the bucket objects\n",
    "            for obj in resultsDic[resKey][time]['buckets']:\n",
    "                paresedResultsDict[resKey][time][obj[4]] = obj\n",
    "                \n",
    "            #parse the teeth \n",
    "            toothNb = 1\n",
    "            \n",
    "            #TODO: delete this\n",
    "            #print(paresedResultsDict[resKey][time]['fileName'])\n",
    "            \n",
    "            for obj in sorted(resultsDic[resKey][time]['teeth'], key=lambda rv: rv[0]):\n",
    "                paresedResultsDict[resKey][time]['Tooth_' + str(toothNb)] = obj\n",
    "                toothNb += 1\n",
    "                \n",
    "            toothNb = 1\n",
    "            for keypointsSet in sorted(resultsDic[resKey][time]['keypoints'], key=lambda kv: kv[0]):           \n",
    "                paresedResultsDict[resKey][time]['keypointsForTooth_' + str(toothNb)] = keypointsSet\n",
    "                toothNb += 1\n",
    "                \n",
    "                \n",
    "            for keypointsNb in range(numberOflandmarksIncludingToothTip):       \n",
    "                paresedResultsDict[resKey][time]['keypoints_' + str(keypointsNb + 1)] = [keypointsSet[keypointsNb] for keypointsSet in sorted(resultsDic[resKey][time]['keypoints'], key=lambda kv: kv[0])]\n",
    "            \n",
    "                \n",
    "    return paresedResultsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getMinDistanceBtwPointAndToothBox(toothBox, landmarkPointsList, image_h):\n",
    "    outDist = 10000\n",
    "    \n",
    "    yminBox = int(toothBox[2] * image_h)\n",
    "    ymaxBox = int(toothBox[3] * image_h)\n",
    "    \n",
    "    x0, y0 = landmarkPointsList[0]\n",
    "    _, y1 = landmarkPointsList[0]\n",
    "        \n",
    "    if not (x0 == 0 or y0 == 0):\n",
    "        outDist = min( min( abs(yminBox - y0), abs(ymaxBox - y0) ), min( abs(yminBox - y1), abs(ymaxBox - y1) ) )\n",
    "\n",
    "    return outDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getDistanceBtwEdges(leftBox, rightBox):\n",
    "    xmaxLeft = float(leftBox[1])\n",
    "    xminRight = float(rightBox[0])\n",
    "\n",
    "    return xminRight - xmaxLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reject1_badBoxesAndLandmarks(\n",
    "    parsedResultsDic,\n",
    "    rejectedResultsDir,\n",
    "    numberOfTeeth,\n",
    "    minToothBoxDistanceAllowed,\n",
    "    numberOflandmarksIncludingToothTip,\n",
    "    lanmark2farFromBox_epsilon,\n",
    "    landmarks2close2eachother_epsilon,\n",
    "    verbose=False):\n",
    "\n",
    "    filteredResults = deepcopy(parsedResultsDic)\n",
    "    \n",
    "    \n",
    "    for resKey in parsedResultsDic.keys():\n",
    "        deletedCount = 0\n",
    "        deletedDuplicateKeypointCount = 0\n",
    "        \n",
    "        for time in parsedResultsDic[resKey].keys():\n",
    "            filePath = paresedResultsDict[resKey][time]['fileName']\n",
    "            fileName = filePath.split('/')[-1]\n",
    "            \n",
    "            \n",
    "            #***********************************************************************************************#\n",
    "            #reject1 get rid of adjacent tooth boxes that are too close to eachother\n",
    "            for toothNb in range(numberOfTeeth - 1):\n",
    "                toothKeyLeft = 'Tooth_' + str(toothNb + 1)\n",
    "                toothKeyRight = 'Tooth_' + str(toothNb + 2)\n",
    "                \n",
    "                if toothKeyLeft in parsedResultsDic[resKey][time] and toothKeyRight in parsedResultsDic[resKey][time]:\n",
    "                    distanceBtwAdjTeeth = getDistanceBtwEdges(\n",
    "                        parsedResultsDic[resKey][time][toothKeyLeft],\n",
    "                        parsedResultsDic[resKey][time][toothKeyRight]\n",
    "                    )\n",
    "\n",
    "                    if distanceBtwAdjTeeth <= minToothBoxDistanceAllowed:\n",
    "                        del filteredResults[resKey][time]['Tooth_' + str(toothNb + 2)]\n",
    "                        paresedResultsDict[resKey][time]['nbOfDetectedTeeth'] = 0 #this garantees reject\n",
    "                        filteredResults[resKey][time]['nbOfDetectedTeeth'] = 0 #this garantees reject\n",
    "                        \n",
    "                        if verbose:\n",
    "                            print('\\nrejected:\\n' + str(filePath) + '\\nbecause adjacent teeth were too close.')\n",
    "            #***********************************************************************************************#\n",
    "                        \n",
    "            \n",
    "            #***********************************************************************************************#\n",
    "            #reject2  get rid of toothtips and lipshrouds that are not inside their tooth box\n",
    "            for toothNb in range(numberOfTeeth - 1):\n",
    "                toothKey = 'Tooth_' + str(toothNb + 1)  \n",
    "                keypointKey = 'keypointsForTooth_' + str(toothNb + 1)\n",
    "                \n",
    "                if toothKey in filteredResults[resKey][time]:\n",
    "                    miDis = getMinDistanceBtwPointAndToothBox(\n",
    "                        filteredResults[resKey][time][toothKey],\n",
    "                        filteredResults[resKey][time][keypointKey],\n",
    "                        filteredResults[resKey][time]['image_h'])\n",
    "\n",
    "                    if( miDis > lanmark2farFromBox_epsilon ):\n",
    "                        filteredResults[resKey][time][keypointKey][0] = [0, 0]\n",
    "                        filteredResults[resKey][time][keypointKey][1] = [0, 0]\n",
    "                        filteredResults[resKey][time]['keypoints_' + str(1)][toothNb] = [0, 0]\n",
    "                        filteredResults[resKey][time]['keypoints_' + str(2)][toothNb] = [0, 0]\n",
    "                        paresedResultsDict[resKey][time]['nbOfDetectedTeeth'] = 0 #this garantees reject\n",
    "                        filteredResults[resKey][time]['nbOfDetectedTeeth'] = 0 #this garantees reject\n",
    "                        if verbose:\n",
    "                            print('\\nrejected:\\n' + str(filePath) + '\\nbecause landmarks were too far from box.')\n",
    "            #***********************************************************************************************#\n",
    "                    \n",
    "                            \n",
    "\n",
    "            #Not a reject yet get rid of landmarks with Xcords that are too close to eachother on adjacent teeth\n",
    "            for lanmarkNb in range(numberOflandmarksIncludingToothTip):\n",
    "                for toothNb in range(numberOfTeeth - 1):\n",
    "                    if 'keypointsForTooth_' + str(toothNb+1) in filteredResults[resKey][time] and 'keypointsForTooth_' + str(toothNb+2) in filteredResults[resKey][time]:\n",
    "                        \n",
    "                        val2del = filteredResults[resKey][time]['keypointsForTooth_' + str(toothNb+2)][lanmarkNb]\n",
    "                        \n",
    "                        diff = abs(filteredResults[resKey][time]['keypointsForTooth_' + str(toothNb+1)][lanmarkNb][0] - val2del[0])\n",
    "\n",
    "                        if diff < landmarks2close2eachother_epsilon:\n",
    "                            filteredResults[resKey][time]['keypointsForTooth_' + str(toothNb+2)][lanmarkNb] = [0, 0]\n",
    "                            filteredResults[resKey][time]['keypoints_' + str(lanmarkNb+1)][toothNb+1] = [0, 0]\n",
    "                                                                                                               \n",
    "                            deletedDuplicateKeypointCount +=1\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "            \n",
    "            #***********************************************************************************************#\n",
    "            #reject3 not enough teeth boxes detected. (frames with missing TTips are rejected later)\n",
    "            if paresedResultsDict[resKey][time]['nbOfDetectedTeeth']  < numberOfTeeth:\n",
    "                shutil.copy(filePath, rejectedResultsDir)\n",
    "                \n",
    "                if verbose:\n",
    "                    print('\\nrejected:\\n' + str(filePath) + '\\nbecause not enough teeth were detected.')\n",
    "                \n",
    "                del filteredResults[resKey][time]\n",
    "                deletedCount += 1\n",
    "            #***********************************************************************************************#\n",
    "\n",
    "                \n",
    "            '''\n",
    "            #reject4 no wearArea detected\n",
    "            elif 'WearArea' not in paresedResultsDict[resKey][time].keys():\n",
    "                shutil.copy(filePath, rejectedResultsDir)\n",
    "                print('\\nrejected:\\n' + str(filePath) + '\\nbecause wearArea was not detected.')\n",
    "                del filteredResults[resKey][time]\n",
    "                deletedCount += 1\n",
    "            '''\n",
    "            \n",
    "    \n",
    "        print('\\nfor results set: ' + resKey + '  rejected ' + str(deletedCount) + ' logs from the parsedResultsDic which were not copied into filteredResults. And removed ' +str(deletedDuplicateKeypointCount) + '  landmarks that had Xcords too close to each other.' )\n",
    "        \n",
    "        return filteredResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fitCurve2keypoints(keypoints, numberOfTeeth, keypointTypeString):\n",
    "    numberOflandmarksIncludingToothTip = 5\n",
    "    degreeOfPolyn = 2\n",
    "    minNumberOflandmarksNeededToFitCurve = 3\n",
    "    \n",
    "    estimatedFunctions = {}\n",
    "    \n",
    "    for landmarkNb in range(numberOflandmarksIncludingToothTip):\n",
    "        landmarkKey = keypointTypeString + str(landmarkNb + 1)\n",
    "        key2Stor = 'keypoints_' + str(landmarkNb + 1)\n",
    "        \n",
    "        x = np.ndarray(shape=(1,))\n",
    "        y = np.ndarray(shape=(1,))\n",
    "        \n",
    "        for point in keypoints[landmarkKey]:\n",
    "            if(point[0] > 0 and point[1] > 0):\n",
    "                x = np.vstack([x, point[0]])\n",
    "                y = np.vstack([y, point[1]])\n",
    "            \n",
    "        x = x[1:,]\n",
    "        y = y[1:,]\n",
    "        x = x.reshape(-1)\n",
    "        y = y.reshape(-1)\n",
    "        \n",
    "        if len(x) >= minNumberOflandmarksNeededToFitCurve and len(y) >= minNumberOflandmarksNeededToFitCurve:\n",
    "            z = np.polyfit(x, y, degreeOfPolyn)\n",
    "\n",
    "            estimatedFunctions[key2Stor] = np.poly1d(z)\n",
    "        \n",
    "    \n",
    "    return estimatedFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get2ndDerivativeOfCurves(fittC):\n",
    "    secondDervs = {}\n",
    "    for key in fittC.keys():\n",
    "        secondDervs[key] = fittC[key].deriv().deriv().c[0]\n",
    "        \n",
    "    return secondDervs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getShortestDistance2Curve(testPoint, curveFunc, maxItr, verbose=False):\n",
    "    \n",
    "    def minimizationObjective(X):\n",
    "        x,y = X\n",
    "        return np.sqrt( (x - testPoint[0])**2 + (y - testPoint[1])**2 )\n",
    "\n",
    "    def minimizationCritaria(X):\n",
    "        #fmin_cobyla will make sure this is always >= 0. So I'm making sure this is > 0 only when the point is on the curve.\n",
    "        x,y = X\n",
    "        return abs(curveFunc(x) - y)*-1\n",
    "\n",
    "    minDistanceSoFar = sys.maxsize\n",
    "    initialGuess = testPoint\n",
    "    \n",
    "    for itr in range(maxItr):\n",
    "        projectedPoint = fmin_cobyla(minimizationObjective, x0=initialGuess, cons=[minimizationCritaria])\n",
    "        curDistance = minimizationObjective(projectedPoint)\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            print('itr:  ' + str(itr))\n",
    "            print('minDistanceSoFar:   ' + str(minDistanceSoFar))\n",
    "            print('projectedPoint is:   ' + str(projectedPoint))\n",
    "            print('shortestDistance is:  ' + str(curDistance))\n",
    "\n",
    "            x = np.linspace(-100, 1000, 100)\n",
    "            plt.plot(x, curveFunc(x), 'r-', label='f(x)')\n",
    "            plt.plot(testPoint[0], testPoint[1], 'bo', label='testPoint')\n",
    "            plt.plot(projectedPoint[0], projectedPoint[1], 'bx', label='projectedPoint')\n",
    "            plt.plot([testPoint[0], projectedPoint[0]], [testPoint[1], projectedPoint[1]], 'g-', label='shortest distance')\n",
    "            plt.axis('equal')\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('y')\n",
    "            plt.legend(loc='best')\n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        if curDistance < minDistanceSoFar:\n",
    "            minDistanceSoFar = curDistance\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    projectedPointAsInt = [int(projectedPoint[0]), int(projectedPoint[1])]\n",
    "    return curDistance, projectedPointAsInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reject2_soft_removeBadCurves(filteredResultsDict, path2saveCurves, rejectedPredsDir, curvDerivTreshDic, verbose=False):\n",
    "    \n",
    "    cleanedUpResultsDict = deepcopy(filteredResultsDict)\n",
    "    \n",
    "    for resKey in filteredResultsDict.keys():\n",
    "        deletedKeypointsCount = 0\n",
    "        totalNbOfKeyPoints = 0\n",
    "        deletedCurvesCount = 0\n",
    "        totalNbOfCurves = 0\n",
    "        problematicFramesCount = 0\n",
    "        \n",
    "        for time in filteredResultsDict[resKey].keys():\n",
    "            frameHadIssues = False\n",
    "            fileName = filteredResultsDict[resKey][time]['fileName'].split('/')[-1]\n",
    "            filePath = path2saveCurves + fileName\n",
    "            \n",
    "            \n",
    "            for keypointsKey in curvDerivTreshDic.keys():\n",
    "                totalNbOfKeyPoints += 1\n",
    "                \n",
    "                #***********************************************************************************************#\n",
    "                #reject4 no curve calculated for this keypoint type (because there was less than 2 of them)\n",
    "                if keypointsKey not in filteredResultsDict[resKey][time]['fittedCurves']:\n",
    "                    del(cleanedUpResultsDict[resKey][time][keypointsKey])\n",
    "                    #shutil.copy(filePath, rejectedPredsDir)\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print('\\nrejected:\\n' + str(filePath) + '\\nbecause no curve was fitted for this keypoint type. For keypointkey: ' + keypointsKey)\n",
    "                    \n",
    "                    deletedKeypointsCount += 1\n",
    "                    frameHadIssues = True\n",
    "                #***********************************************************************************************#\n",
    "                    \n",
    "            \n",
    "            #***********************************************************************************************#\n",
    "            #reject5 2nd derivative of fitted curve for this keypoint type doesnt satisfy thresholds        \n",
    "            for keypointsKey in filteredResultsDict[resKey][time]['2ndDerivFittedCurves'].keys():\n",
    "                totalNbOfCurves += 1\n",
    "                derivative = filteredResultsDict[resKey][time]['2ndDerivFittedCurves'][keypointsKey]\n",
    "                \n",
    "                if derivative < curvDerivTreshDic[keypointsKey][0]\\\n",
    "                or derivative > curvDerivTreshDic[keypointsKey][1]:\n",
    "                    \n",
    "                    if keypointsKey in cleanedUpResultsDict[resKey][time]:\n",
    "                        del(cleanedUpResultsDict[resKey][time][keypointsKey])\n",
    "                        del(cleanedUpResultsDict[resKey][time]['2ndDerivFittedCurves'][keypointsKey])\n",
    "                        del(cleanedUpResultsDict[resKey][time]['fittedCurves'][keypointsKey])\n",
    "\n",
    "                        shutil.copy(filePath, rejectedPredsDir)\n",
    "                        \n",
    "                        if verbose:\n",
    "                            print('\\nreject2_soft rejected:\\n' + str(filePath) + '\\nbecause derivative of fitted curve didnt fit the criteria. For keypointkey: ' + keypointsKey)\n",
    "                            \n",
    "                        deletedCurvesCount += 1\n",
    "                        frameHadIssues = True\n",
    "                #***********************************************************************************************#\n",
    "                \n",
    "\n",
    "            if frameHadIssues:\n",
    "                problematicFramesCount += 1\n",
    "\n",
    "        print('\\nfor results set: ' + resKey + ':\\n---Total of  ' + str(problematicFramesCount) + '  frames had issues, so not all of their info were copied from filteredResults into cleanedUpResultsDict.\\n'+ '---rejected  ' + str(deletedCurvesCount) + '  curves out of the  ' + str(totalNbOfCurves) +'  in total because the derivative of fitted curve didnt fit the criteria.' + '\\n---rejected  ' + str(deletedKeypointsCount) + '  keypoints out of  '+ str(totalNbOfKeyPoints) +'  in total because we couldnt fit a curve to them.\\n')\n",
    "        \n",
    "        return cleanedUpResultsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reject3_soft_replaceLandmarks2farFromCurve(cleanedUpResultsDict, path2SavedCurves, path2saveRejectedLandmarks, maxDistanceBtwLandmarkAndCurve_replacement, maxDistanceBtwLandmarkAndCurve_rejection, maxItr_findingShortestDistance2Curve, replaceBadLandmarkWithProjection, verbose=False):\n",
    "    #reject 6. Get rid of zeros and landmarks too far from their curves.\n",
    "    #keypoints not in validated will not be used for image2image registration\n",
    "    \n",
    "    for resKey in cleanedUpResultsDict.keys():\n",
    "        landmarksNotCopiedToValid = 0\n",
    "        replacedLandmarks2farFromCurve = 0\n",
    "        totalNbOfLandmakrs = 0\n",
    "        \n",
    "        for time in cleanedUpResultsDict[resKey].keys():\n",
    "            cleanedUpResultsDict[resKey][time]['validatedKeypoints'] = []\n",
    "            \n",
    "            fileName = cleanedUpResultsDict[resKey][time]['fileName'].split('/')[-1]\n",
    "            filePath = path2SavedCurves + fileName\n",
    "            \n",
    "            \n",
    "            # setup the confidences array to store number of good landmarks\n",
    "            confidences = {}\n",
    "            for tnb in range(NUMBER_OF_TEETH):\n",
    "                confidences['tooth_' + str(tnb+1)] = 0\n",
    "            ###############################################################\n",
    "            \n",
    "            \n",
    "            for ln in range(numberOflandmarksIncludingToothTip):\n",
    "                keypointType = 'keypoints_' + str(ln + 1)\n",
    "                \n",
    "                if keypointType in cleanedUpResultsDict[resKey][time]['2ndDerivFittedCurves'].keys():\n",
    "                    \n",
    "                    for tn in range(NUMBER_OF_TEETH):\n",
    "                        curKeyPoint = cleanedUpResultsDict[resKey][time][keypointType][tn]\n",
    "\n",
    "                        if not (curKeyPoint[0] == 0 and curKeyPoint[1] == 0):\n",
    "                            totalNbOfLandmakrs +=1\n",
    "\n",
    "                            dist2Curv, projectedPoint = getShortestDistance2Curve(curKeyPoint, cleanedUpResultsDict[resKey][time]['fittedCurves'][keypointType], maxItr_findingShortestDistance2Curve)\n",
    "\n",
    "                            \n",
    "                            if dist2Curv > maxDistanceBtwLandmarkAndCurve_rejection:\n",
    "                                shutil.copy(filePath, path2saveRejectedLandmarks)\n",
    "                                landmarksNotCopiedToValid += 1\n",
    "\n",
    "                                if verbose:\n",
    "                                    print('\\nrejected a kypoint in:\\n' + str(filePath) + '\\nbecause the keypoint was too far from the curve. For keypointkey: ' + keypointType + '   keyPont:  ' + str(curKeyPoint) + '\\ndistance to curve was:  ' + str(dist2Curv) + '.')\n",
    "                                    \n",
    "                            elif dist2Curv > maxDistanceBtwLandmarkAndCurve_replacement and\\\n",
    "                            replaceBadLandmarkWithProjection == True:\n",
    "                                \n",
    "                                    cleanedUpResultsDict[resKey][time]['validatedKeypoints'].append(projectedPoint)\n",
    "\n",
    "                                    cleanedUpResultsDict[resKey][time][keypointType][tn] = projectedPoint\n",
    "                                    cleanedUpResultsDict[resKey][time]['keypointsForTooth_' + str(tn + 1)][ln] = projectedPoint\n",
    "                                    replacedLandmarks2farFromCurve += 1\n",
    "\n",
    "                                    if verbose:\n",
    "                                        print('\\nreplaced a kypoint in:\\n' + str(filePath) + '\\nbecause it was too far from the curve. For keypointkey: ' + keypointType + '   keyPont:  ' + str(curKeyPoint) + '\\ndistance to curve was:  ' + str(dist2Curv) + '\\nWe replaced this keypoint with its projection to the curve instead which was found to be:  ' + str(projectedPoint) )\n",
    "                                    \n",
    "                            else :\n",
    "                                cleanedUpResultsDict[resKey][time]['validatedKeypoints'].append(curKeyPoint)\n",
    "                                confidences['tooth_' + str(tn + 1)] += 1\n",
    "                                \n",
    "\n",
    "                                 \n",
    "\n",
    "                                    \n",
    "            cleanedUpResultsDict[resKey][time]['confidences'] = confidences\n",
    "            \n",
    "            \n",
    "    print('\\nfor results set: ' + resKey + ':\\n---replaced  ' + str(replacedLandmarks2farFromCurve) + '  landmarks out of  ' + str(totalNbOfLandmakrs)+ '  in total with their projections on the curve. Total of  '+ str(landmarksNotCopiedToValid) + '  landmarks were NOT added to validated and frames were copies in path2saveRejectedLandmarks.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def countValidLandmarks(resDictForFrame, minNbOfDetectedPointsForOtherLandmarkTypes):\n",
    "    detectedLandmakTypesCount = 0\n",
    "    detectedLipShroudCount = 0\n",
    "    detectedToothTipCount = 0\n",
    "    \n",
    "    \n",
    "    if 'keypoints_1' in resDictForFrame:\n",
    "        detectedToothTipCount = len([x for x in resDictForFrame['keypoints_1'] if x in resDictForFrame['validatedKeypoints']])\n",
    "        \n",
    "    \n",
    "    if 'keypoints_2' in resDictForFrame:\n",
    "        detectedLipShroudCount = len([x for x in resDictForFrame['keypoints_2'] if x in resDictForFrame['validatedKeypoints']])\n",
    "\n",
    "    \n",
    "    if 'keypoints_3' in resDictForFrame and\\\n",
    "    len([x for x in resDictForFrame['keypoints_3'] if x in resDictForFrame['validatedKeypoints']]) >= minNbOfDetectedPointsForOtherLandmarkTypes:\n",
    "        detectedLandmakTypesCount += 1\n",
    "        \n",
    "        \n",
    "    if 'keypoints_4' in resDictForFrame and\\\n",
    "    len([x for x in resDictForFrame['keypoints_4'] if x in resDictForFrame['validatedKeypoints']]) >= minNbOfDetectedPointsForOtherLandmarkTypes:\n",
    "        detectedLandmakTypesCount += 1\n",
    "        \n",
    "        \n",
    "    if 'keypoints_5' in resDictForFrame and\\\n",
    "    len([x for x in resDictForFrame['keypoints_5'] if x in resDictForFrame['validatedKeypoints']]) >= minNbOfDetectedPointsForOtherLandmarkTypes:\n",
    "        detectedLandmakTypesCount += 1\n",
    "\n",
    "        \n",
    "    return detectedLandmakTypesCount, detectedLipShroudCount, detectedToothTipCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reject4_notEnoughValidLandmarks(cleanedUpResultsDict, rejectedResultsDir, minNbOfDetectedPointsForTTandLS, minNbOfDetectedPointsForOtherLandmarkTypes, numberOfTeeth, verbose=False):\n",
    "\n",
    "    finalResultsDict = deepcopy(cleanedUpResultsDict)\n",
    "    \n",
    "    for resKey in cleanedUpResultsDict.keys():\n",
    "        deletedCount = 0\n",
    "        totalFramesCount = 0\n",
    "        \n",
    "        for time in cleanedUpResultsDict[resKey].keys():\n",
    "            totalFramesCount += 1\n",
    "            alreadyRejected = False\n",
    "            filePath = cleanedUpResultsDict[resKey][time]['fileName']\n",
    "            fileName = filePath.split('/')[-1]\n",
    "            path2FrameWithCurve = path2saveCurves + fileName\n",
    "            \n",
    "            \n",
    "            detectedLandmakTypesCount, detectedLipShroudCount, detectedToothTipCount = countValidLandmarks(\n",
    "                cleanedUpResultsDict[resKey][time],\n",
    "                minNbOfDetectedPointsForOtherLandmarkTypes\n",
    "            )\n",
    "            \n",
    "            #reject1 not enough teeth boxes + tips detected.\n",
    "            if detectedToothTipCount < minNbOfDetectedPointsForTTandLS:\n",
    "                shutil.copy(path2FrameWithCurve, rejectedResultsDir)\n",
    "                \n",
    "                if verbose:\n",
    "                    print('\\nrejected:\\n' + str(filePath) + '\\nbecause not enough toothTips were detected. We counted   ' + str(detectedToothTipCount) + '  toothTips for this log.')\n",
    "                    \n",
    "                del finalResultsDict[resKey][time]\n",
    "                \n",
    "                if not alreadyRejected:\n",
    "                    deletedCount += 1\n",
    "                    alreadyRejected = True\n",
    "                \n",
    "            \n",
    "            #reject2 not enough lipShroud landmarks are detected\n",
    "            elif detectedLipShroudCount < minNbOfDetectedPointsForTTandLS:\n",
    "                shutil.copy(path2FrameWithCurve, rejectedResultsDir)\n",
    "                \n",
    "                if verbose:\n",
    "                    print('\\nrejected:\\n' + str(filePath) + '\\nbecause not enough lipshrouds were detected. We counted   ' + str(detectedLipShroudCount) + '  lipShrouds for this log.')\n",
    "                \n",
    "                del finalResultsDict[resKey][time]\n",
    "                \n",
    "                if not alreadyRejected:\n",
    "                    deletedCount += 1\n",
    "                    alreadyRejected = True\n",
    "                \n",
    "                \n",
    "            #reject3 not enough registeration landmarks detected\n",
    "            elif detectedLandmakTypesCount < 1:\n",
    "                shutil.copy(path2FrameWithCurve, rejectedResultsDir)\n",
    "                \n",
    "                if verbose:\n",
    "                    print('\\nrejected:\\n' + str(filePath) + '\\nbecause no other landmarks types aside from TT and LS were detected.')\n",
    "                del finalResultsDict[resKey][time]\n",
    "                if not alreadyRejected:\n",
    "                    deletedCount += 1\n",
    "                    alreadyRejected = True\n",
    "            \n",
    "        \n",
    "                \n",
    "        print('\\nfor results set: ' + resKey + '\\n---rejected  ' + str(deletedCount) + '  logs out of the total of  ' + str(totalFramesCount) +'  which were not copied from cleanedUpResultsDict into finalResultsDict.')\n",
    "        \n",
    "        return finalResultsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10,
     11,
     55,
     99,
     143,
     187,
     231,
     275,
     319,
     367,
     411,
     455,
     499,
     543,
     587
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getReferenceRatios(refKey):\n",
    "    \n",
    "    path2RefImage = mainPath + 'referenceFrames/images/' + refKey + '.png'\n",
    "    path2Reflabel = mainPath + 'referenceFrames/labels/' + refKey + '_landmarkCoords.xml'\n",
    "    refkeyPointsDic = getRefDict(path2Reflabel, path2RefImage)\n",
    "\n",
    "    def getRatio(lm1, lm2, lm3, lm4):\n",
    "        return (lm2[1]-lm1[1])/(lm4[1]-lm3[1])\n",
    "    \n",
    "    if NUMBER_OF_TEETH > 6:\n",
    "        minAllowedRatiosDict = {\n",
    "            'tooth_1':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['liftingEye_1'], \n",
    "                     refkeyPointsDic['bucketLandmark_1']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['liftingEye_1'], \n",
    "                     refkeyPointsDic['castLip_1']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['castLip_1'], \n",
    "                     refkeyPointsDic['bucketLandmark_1']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['liftingEye_1']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['castLip_1']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['bucketLandmark_1']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_2':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['liftingEye_2'], \n",
    "                     refkeyPointsDic['bucketLandmark_2']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['liftingEye_2'], \n",
    "                     refkeyPointsDic['castLip_2']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['castLip_2'], \n",
    "                     refkeyPointsDic['bucketLandmark_2']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['liftingEye_2']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['castLip_2']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['bucketLandmark_2']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_3':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['liftingEye_3'], \n",
    "                     refkeyPointsDic['bucketLandmark_3']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['liftingEye_3'], \n",
    "                     refkeyPointsDic['castLip_3']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['castLip_3'], \n",
    "                     refkeyPointsDic['bucketLandmark_3']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['liftingEye_3']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['castLip_3']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['bucketLandmark_3']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_4':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['liftingEye_4'], \n",
    "                     refkeyPointsDic['bucketLandmark_4']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['liftingEye_4'], \n",
    "                     refkeyPointsDic['castLip_4']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['castLip_4'], \n",
    "                     refkeyPointsDic['bucketLandmark_4']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['liftingEye_4']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['castLip_4']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['bucketLandmark_4']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_5':{\n",
    "                 'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['liftingEye_5'], \n",
    "                     refkeyPointsDic['bucketLandmark_5']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['liftingEye_5'], \n",
    "                     refkeyPointsDic['castLip_5']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['castLip_5'], \n",
    "                     refkeyPointsDic['bucketLandmark_5']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['liftingEye_5']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['castLip_5']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['bucketLandmark_5']\n",
    "                 ),\n",
    "            },\n",
    "            'tooth_6':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['liftingEye_6'], \n",
    "                     refkeyPointsDic['bucketLandmark_6']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['liftingEye_6'], \n",
    "                     refkeyPointsDic['castLip_6']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['castLip_6'], \n",
    "                     refkeyPointsDic['bucketLandmark_6']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['liftingEye_6']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['castLip_6']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['bucketLandmark_6']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_7':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_7'],\n",
    "                     refkeyPointsDic['lipShroud_7'], \n",
    "                     refkeyPointsDic['liftingEye_7'], \n",
    "                     refkeyPointsDic['bucketLandmark_7']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_7'],\n",
    "                     refkeyPointsDic['lipShroud_7'], \n",
    "                     refkeyPointsDic['liftingEye_7'], \n",
    "                     refkeyPointsDic['castLip_7']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_7'],\n",
    "                     refkeyPointsDic['lipShroud_7'], \n",
    "                     refkeyPointsDic['castLip_7'], \n",
    "                     refkeyPointsDic['bucketLandmark_7']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_7'],\n",
    "                     refkeyPointsDic['lipShroud_7'], \n",
    "                     refkeyPointsDic['lipShroud_7'], \n",
    "                     refkeyPointsDic['liftingEye_7']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_7'],\n",
    "                     refkeyPointsDic['lipShroud_7'], \n",
    "                     refkeyPointsDic['lipShroud_7'], \n",
    "                     refkeyPointsDic['castLip_7']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_7'],\n",
    "                     refkeyPointsDic['lipShroud_7'], \n",
    "                     refkeyPointsDic['lipShroud_7'], \n",
    "                     refkeyPointsDic['bucketLandmark_7']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_8':{\n",
    "                 'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_8'],\n",
    "                     refkeyPointsDic['lipShroud_8'], \n",
    "                     refkeyPointsDic['liftingEye_8'], \n",
    "                     refkeyPointsDic['bucketLandmark_8']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_8'],\n",
    "                     refkeyPointsDic['lipShroud_8'], \n",
    "                     refkeyPointsDic['liftingEye_8'], \n",
    "                     refkeyPointsDic['castLip_8']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_8'],\n",
    "                     refkeyPointsDic['lipShroud_8'], \n",
    "                     refkeyPointsDic['castLip_8'], \n",
    "                     refkeyPointsDic['bucketLandmark_8']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_8'],\n",
    "                     refkeyPointsDic['lipShroud_8'], \n",
    "                     refkeyPointsDic['lipShroud_8'], \n",
    "                     refkeyPointsDic['liftingEye_8']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_8'],\n",
    "                     refkeyPointsDic['lipShroud_8'], \n",
    "                     refkeyPointsDic['lipShroud_8'], \n",
    "                     refkeyPointsDic['castLip_8']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_8'],\n",
    "                     refkeyPointsDic['lipShroud_8'], \n",
    "                     refkeyPointsDic['lipShroud_8'], \n",
    "                     refkeyPointsDic['bucketLandmark_8']\n",
    "                 ),\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        minAllowedRatiosDict = {\n",
    "            'tooth_1':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['liftingEye_1'], \n",
    "                     refkeyPointsDic['bucketLandmark_1']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['liftingEye_1'], \n",
    "                     refkeyPointsDic['castLip_1']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['castLip_1'], \n",
    "                     refkeyPointsDic['bucketLandmark_1']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['liftingEye_1']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['castLip_1']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_1'],\n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['lipShroud_1'], \n",
    "                     refkeyPointsDic['bucketLandmark_1']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_2':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['liftingEye_2'], \n",
    "                     refkeyPointsDic['bucketLandmark_2']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['liftingEye_2'], \n",
    "                     refkeyPointsDic['castLip_2']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['castLip_2'], \n",
    "                     refkeyPointsDic['bucketLandmark_2']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['liftingEye_2']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['castLip_2']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_2'],\n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['lipShroud_2'], \n",
    "                     refkeyPointsDic['bucketLandmark_2']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_3':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['liftingEye_3'], \n",
    "                     refkeyPointsDic['bucketLandmark_3']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['liftingEye_3'], \n",
    "                     refkeyPointsDic['castLip_3']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['castLip_3'], \n",
    "                     refkeyPointsDic['bucketLandmark_3']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['liftingEye_3']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['castLip_3']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_3'],\n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['lipShroud_3'], \n",
    "                     refkeyPointsDic['bucketLandmark_3']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_4':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['liftingEye_4'], \n",
    "                     refkeyPointsDic['bucketLandmark_4']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['liftingEye_4'], \n",
    "                     refkeyPointsDic['castLip_4']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['castLip_4'], \n",
    "                     refkeyPointsDic['bucketLandmark_4']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['liftingEye_4']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['castLip_4']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_4'],\n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['lipShroud_4'], \n",
    "                     refkeyPointsDic['bucketLandmark_4']\n",
    "                 ), \n",
    "            },\n",
    "            'tooth_5':{\n",
    "                 'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['liftingEye_5'], \n",
    "                     refkeyPointsDic['bucketLandmark_5']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['liftingEye_5'], \n",
    "                     refkeyPointsDic['castLip_5']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['castLip_5'], \n",
    "                     refkeyPointsDic['bucketLandmark_5']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['liftingEye_5']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['castLip_5']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_5'],\n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['lipShroud_5'], \n",
    "                     refkeyPointsDic['bucketLandmark_5']\n",
    "                 ),\n",
    "            },\n",
    "            'tooth_6':{\n",
    "                'tt2ls_over_le2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['liftingEye_6'], \n",
    "                     refkeyPointsDic['bucketLandmark_6']\n",
    "                 ),\n",
    "                'tt2ls_over_le2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['liftingEye_6'], \n",
    "                     refkeyPointsDic['castLip_6']\n",
    "                 ),\n",
    "                'tt2ls_over_cl2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['castLip_6'], \n",
    "                     refkeyPointsDic['bucketLandmark_6']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2le': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['liftingEye_6']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2cl': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['castLip_6']\n",
    "                 ),\n",
    "                'tt2ls_over_ls2bk': \n",
    "                 getRatio(\n",
    "                     refkeyPointsDic['toothTip_6'],\n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['lipShroud_6'], \n",
    "                     refkeyPointsDic['bucketLandmark_6']\n",
    "                 ), \n",
    "            },\n",
    "        }\n",
    "        \n",
    "    \n",
    "    return minAllowedRatiosDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Loading the json prediction results into resultsDic, parsing, and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     22,
     31,
     40,
     49,
     107,
     176,
     229
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# CONFIGS\n",
    "mainPath = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_Sishen_cable/PH01_2800/'\n",
    "\n",
    "# in case you wanna use groundTruth\n",
    "wmsDir = mainPath +  'groundTruthLabels/' # 'groundTruthLabels/'  'yolo_preds/'\n",
    "\n",
    "##########THESE ARE GLOBAL##############\n",
    "NUMBER_OF_TEETH = 8  #for cable 8  for hydraulic 6\n",
    "numberOflandmarksIncludingToothTip = 5\n",
    "verboseAboutRejections = False\n",
    "TOTAL_EXPECTED_LANDMARKS_ON_LOG = NUMBER_OF_TEETH * numberOflandmarksIncludingToothTip\n",
    "########################################\n",
    "\n",
    "#for reject1\n",
    "minToothBoxDistanceAllowed =  0.0 #0.0  -1000000  if distanceBtwAdjTeeth <= minToothBoxDistanceAllowed: REJECT\n",
    "lanmark2farFromBox_epsilon =  1000000  #10   1000000   if( miDis > lanmark2farFromBox_epsilon ): REJECT\n",
    "landmarks2close2eachother_epsilon = 20 #20 -1000000   if diff < landmarks2close2eachother_epsilon: REJECT\n",
    "\n",
    "\n",
    "#for reject2\n",
    "'''\n",
    "# used this for hydraulic. With libre groundTruth too\n",
    "curvDerivTreshDic = {\n",
    "    'keypoints_1' : [0.0001, 0.002],\n",
    "    'keypoints_2' : [0.0001, 0.002],\n",
    "    'keypoints_3' : [0.0001, 0.002],\n",
    "    'keypoints_4' : [0.0001, 0.002],\n",
    "    'keypoints_5' : [-0.0001, 0.002],\n",
    "}\n",
    "\n",
    "# used this for hydraulic too. Just to be stricter\n",
    "curvDerivTreshDic = {\n",
    "    'keypoints_1' : [0.0001, 0.002],\n",
    "    'keypoints_2' : [0.0009, 0.002],\n",
    "    'keypoints_3' : [0.0001, 0.002],\n",
    "    'keypoints_4' : [0.0001, 0.002],\n",
    "    'keypoints_5' : [-0.0001, 0.002],\n",
    "}\n",
    "\n",
    "# used this for cable\n",
    "curvDerivTreshDic = {\n",
    "    'keypoints_1' : [0.0001, 0.0042],\n",
    "    'keypoints_2' : [0.0001, 0.0042],\n",
    "    'keypoints_3' : [0.0009, 0.0042],\n",
    "    'keypoints_4' : [0.0009, 0.0042],\n",
    "    'keypoints_5' : [0.0009, 0.0042],\n",
    "}\n",
    "'''\n",
    "# used this for cable\n",
    "curvDerivTreshDic = {\n",
    "    'keypoints_1' : [0.0001, 0.0042],\n",
    "    'keypoints_2' : [0.0001, 0.0042],\n",
    "    'keypoints_3' : [0.0009, 0.0042],\n",
    "    'keypoints_4' : [0.0009, 0.0042],\n",
    "    'keypoints_5' : [0.0009, 0.0042],\n",
    "}\n",
    "\n",
    "\n",
    "#for reject3\n",
    "maxDistanceBtwLandmarkAndCurve_replacement = 3 # used 3 for all cable and hydraulic\n",
    "maxDistanceBtwLandmarkAndCurve_rejection = 100\n",
    "maxItr_findingShortestDistance2Curve = 10\n",
    "replaceBadLandmarkWithProjection = True\n",
    "\n",
    "#for reject4\n",
    "minNbOfDetectedPointsForTTandLS = NUMBER_OF_TEETH\n",
    "minNbOfDetectedPointsForOtherLandmarkTypes = 3\n",
    "\n",
    "\n",
    "#for registration\n",
    "'''\n",
    "#for hydraulic test used referenceFrames/images/WMDL_2018.09.11_10.50.26.png'\n",
    "# first try cable was with referenceFrames/images/WMDL_2018.09.11_06.43.19.png' images/WMDL_2018.09.11_06.21.57.png' was better tho, WMDL_2018.09.11_06.30.39 is middle\n",
    "\n",
    "\n",
    "# used this for  PH01_2800\n",
    "references2use = ['WMDL_2018.09.11_06.21.57', 'WMDL_2018.09.11_06.30.39', 'WMDL_2018.09.11_06.43.19']\n",
    "\n",
    "# used this for  PH02_2800\n",
    "references2use = ['WMDL_2018.11.05_10.13.29', 'WMDL_2018.11.06_11.26.35', 'WMDL_2018.11.04_12.37.28', 'WMDL_2018.11.06_11.38.56', 'WMDL_2018.11.05_11.10.03']\n",
    "\n",
    "#used this for PH03-2800\n",
    "references2use = ['WMDL_2019.02.05_08.16.35', 'WMDL_2019.02.05_08.41.56']\n",
    "\n",
    "#used this for PH03-4100:\n",
    "couldn't find any good images so used the same ones as in above (PH03-2800)\n",
    "\n",
    "# used this for wmdlLogs_Pinto (hydraulic):\n",
    "references2use = ['1_20161116-074000_0001n0_9767', '1_20161116-152500_0001n0_783']\n",
    "\n",
    "#used this for wmdlLogs_aitik (hydraulic)\n",
    "references2use = ['WMDL_2019.02.27_10.03.11','WMDL_2017.11.27_23.58.12', 'WMDL_2017.11.28_00.33.32', 'WMDL_2017.11.27_23.52.22']\n",
    "'''\n",
    "# used this for  PH01_2800\n",
    "references2use = ['WMDL_2018.09.11_06.21.57', 'WMDL_2018.09.11_06.30.39', 'WMDL_2018.09.11_06.43.19']\n",
    "#1st ref is used below for cleaning up final lengths (valid) \n",
    "\n",
    "\n",
    "#For cleaning up final lengths (valid) \n",
    "#for cable PH01_2800 using ref WMDL_2018.09.11_06.21.57_labeled\n",
    "refKey = references2use[0]\n",
    "referenceRatiosDict = getReferenceRatios(refKey)\n",
    "\n",
    "\n",
    "'''\n",
    "#Best for PH01_2800 cable\n",
    "refKey = 'WMDL_2018.09.11_06.21.57'\n",
    "maxAllowedDistBtwRatiosDict = {\n",
    "        'tooth_1':{\n",
    "            'tt2ls_over_le2bk': 0.5,\n",
    "            'tt2ls_over_le2cl': 0.5,\n",
    "            'tt2ls_over_cl2bk': 0.5,\n",
    "            'tt2ls_over_ls2le': 0.5, \n",
    "            'tt2ls_over_ls2cl': 0.5, \n",
    "            'tt2ls_over_ls2bk': 0.5,\n",
    "        },\n",
    "        'tooth_2':{ # at 1, you see no effects.\n",
    "            'tt2ls_over_le2bk': 0.5, \n",
    "            'tt2ls_over_le2cl': 0.5, \n",
    "            'tt2ls_over_cl2bk': 0.5,\n",
    "            'tt2ls_over_ls2le': 0.5, \n",
    "            'tt2ls_over_ls2cl': 0.5,\n",
    "            'tt2ls_over_ls2bk': 0.5,\n",
    "        },\n",
    "        'tooth_3':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1, # at 0.5 with all rest being 1, only this one has an effect\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        },\n",
    "        'tooth_4':{\n",
    "            'tt2ls_over_le2bk': 1.1,\n",
    "            'tt2ls_over_le2cl': 1.1,\n",
    "            'tt2ls_over_cl2bk': 1.1,\n",
    "            'tt2ls_over_ls2le': 1.1,\n",
    "            'tt2ls_over_ls2cl': 1.1,\n",
    "            'tt2ls_over_ls2bk': 1.1,\n",
    "        },\n",
    "        'tooth_5':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1,\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        },\n",
    "        'tooth_6':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1,\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        },\n",
    "        'tooth_7':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1,\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        },\n",
    "        'tooth_8':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1,\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "#for hydraulic. But it can be better. This just allows everything through\n",
    "maxAllowedDistBtwRatiosDict = {\n",
    "        'tooth_1':{\n",
    "            'tt2ls_over_le2bk': 10,\n",
    "            'tt2ls_over_le2cl': 10,\n",
    "            'tt2ls_over_cl2bk': 10,\n",
    "            'tt2ls_over_ls2le': 10, \n",
    "            'tt2ls_over_ls2cl': 10, \n",
    "            'tt2ls_over_ls2bk': 10,\n",
    "        },\n",
    "        'tooth_2':{ # at 1, you see no effects.\n",
    "            'tt2ls_over_le2bk': 10, \n",
    "            'tt2ls_over_le2cl': 10, \n",
    "            'tt2ls_over_cl2bk': 10,\n",
    "            'tt2ls_over_ls2le': 10, \n",
    "            'tt2ls_over_ls2cl': 10,\n",
    "            'tt2ls_over_ls2bk': 10,\n",
    "        },\n",
    "        'tooth_3':{\n",
    "            'tt2ls_over_le2bk': 10,\n",
    "            'tt2ls_over_le2cl': 10,\n",
    "            'tt2ls_over_cl2bk': 10,\n",
    "            'tt2ls_over_ls2le': 10, # at 0.5 with all rest being 1, only this one has an effect\n",
    "            'tt2ls_over_ls2cl': 10,\n",
    "            'tt2ls_over_ls2bk': 10,\n",
    "        },\n",
    "        'tooth_4':{\n",
    "            'tt2ls_over_le2bk': 10,\n",
    "            'tt2ls_over_le2cl': 10,\n",
    "            'tt2ls_over_cl2bk': 10,\n",
    "            'tt2ls_over_ls2le': 10,\n",
    "            'tt2ls_over_ls2cl': 10,\n",
    "            'tt2ls_over_ls2bk': 10,\n",
    "        },\n",
    "        'tooth_5':{\n",
    "            'tt2ls_over_le2bk': 10,\n",
    "            'tt2ls_over_le2cl': 10,\n",
    "            'tt2ls_over_cl2bk': 10,\n",
    "            'tt2ls_over_ls2le': 10,\n",
    "            'tt2ls_over_ls2cl': 10,\n",
    "            'tt2ls_over_ls2bk': 10,\n",
    "        },\n",
    "        'tooth_6':{\n",
    "            'tt2ls_over_le2bk': 10,\n",
    "            'tt2ls_over_le2cl': 10,\n",
    "            'tt2ls_over_cl2bk': 10,\n",
    "            'tt2ls_over_ls2le': 10,\n",
    "            'tt2ls_over_ls2cl': 10,\n",
    "            'tt2ls_over_ls2bk': 10,\n",
    "        },\n",
    "    }\n",
    "'''\n",
    "#Best for PH01_2800 cable\n",
    "refKey = 'WMDL_2018.09.11_06.21.57'\n",
    "maxAllowedDistBtwRatiosDict = {\n",
    "        'tooth_1':{\n",
    "            'tt2ls_over_le2bk': 0.5,\n",
    "            'tt2ls_over_le2cl': 0.5,\n",
    "            'tt2ls_over_cl2bk': 0.5,\n",
    "            'tt2ls_over_ls2le': 0.5, \n",
    "            'tt2ls_over_ls2cl': 0.5, \n",
    "            'tt2ls_over_ls2bk': 0.5,\n",
    "        },\n",
    "        'tooth_2':{ # at 1, you see no effects.\n",
    "            'tt2ls_over_le2bk': 0.5, \n",
    "            'tt2ls_over_le2cl': 0.5, \n",
    "            'tt2ls_over_cl2bk': 0.5,\n",
    "            'tt2ls_over_ls2le': 0.5, \n",
    "            'tt2ls_over_ls2cl': 0.5,\n",
    "            'tt2ls_over_ls2bk': 0.5,\n",
    "        },\n",
    "        'tooth_3':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1, # at 0.5 with all rest being 1, only this one has an effect\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        },\n",
    "        'tooth_4':{\n",
    "            'tt2ls_over_le2bk': 1.1,\n",
    "            'tt2ls_over_le2cl': 1.1,\n",
    "            'tt2ls_over_cl2bk': 1.1,\n",
    "            'tt2ls_over_ls2le': 1.1,\n",
    "            'tt2ls_over_ls2cl': 1.1,\n",
    "            'tt2ls_over_ls2bk': 1.1,\n",
    "        },\n",
    "        'tooth_5':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1,\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        },\n",
    "        'tooth_6':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1,\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        },\n",
    "        'tooth_7':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1,\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        },\n",
    "        'tooth_8':{\n",
    "            'tt2ls_over_le2bk': 1,\n",
    "            'tt2ls_over_le2cl': 1,\n",
    "            'tt2ls_over_cl2bk': 1,\n",
    "            'tt2ls_over_ls2le': 1,\n",
    "            'tt2ls_over_ls2cl': 1,\n",
    "            'tt2ls_over_ls2bk': 1,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "maxAllowed_detectedAboveRefTT = 1\n",
    "\n",
    "\n",
    "#not used\n",
    "minAllowed_toothLength = 0#10\n",
    "maxAllowed_toothLength = 300#30\n",
    "\n",
    "#for calculating secondary confidence.\n",
    "weightOfToothConfidence = 1\n",
    "weightOfLogConfidence = 1.2 #we decided on 1.1 but I used 1.2 for hydraulic and traj investigations for some reason\n",
    "\n",
    "\n",
    "#**** only used by getRegisteredPointsV3.rejects logs where regError using LS is smaller than using all landmarks.\n",
    "regEr_WithLs_lessThan_withAll_multiple = 1000 # used 1 for hydraulic. For cable 1000 to disable this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load JSON prediciton results from disc into dict\n",
    "\n",
    "rawFramesDir = mainPath + 'Frame/'\n",
    "rejectedPredsDir = mainPath + 'rejected_notAllTeeth'\n",
    "\n",
    "resultsDict = loadResults(wmsDir)\n",
    "paresedResultsDict = parseResults(resultsDict, numberOfTeeth= NUMBER_OF_TEETH)\n",
    "\n",
    "filteredResultsDict = reject1_badBoxesAndLandmarks(\n",
    "    paresedResultsDict,\n",
    "    rejectedPredsDir,\n",
    "    NUMBER_OF_TEETH,\n",
    "    minToothBoxDistanceAllowed,\n",
    "    numberOflandmarksIncludingToothTip,\n",
    "    lanmark2farFromBox_epsilon,\n",
    "    landmarks2close2eachother_epsilon,\n",
    "    verbose = verboseAboutRejections)\n",
    "\n",
    "keyT = mainPath.split('/')[-2]\n",
    "print('\\nfinalStats:')\n",
    "print('---resultsDict length:  '  + str(len(resultsDict[keyT])))\n",
    "print('---paresedResultsDict length:  ' + str(len(paresedResultsDict[keyT])))\n",
    "print('---filteredResultsDict length:  ' + str(len(filteredResultsDict[keyT])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit curves to all landmarks, calculate curve derives, save the vis img\n",
    "path2saveCurves = mainPath + 'curves/'\n",
    "\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "\n",
    "for resKey in filteredResultsDict.keys():\n",
    "    for time in filteredResultsDict[resKey].keys():\n",
    "        fileName = filteredResultsDict[resKey][time]['fileName'].split('/')[-1]\n",
    "        \n",
    "        fittC = fitCurve2keypoints(filteredResultsDict[resKey][time], numberOfTeeth, 'keypoints_')\n",
    "        \n",
    "        filteredResultsDict[resKey][time]['fittedCurves'] = fittC\n",
    "        filteredResultsDict[resKey][time]['2ndDerivFittedCurves'] = get2ndDerivativeOfCurves(fittC)\n",
    "        \n",
    "        inImage = cv2.imread(rawFramesDir + fileName)\n",
    "        if inImage is None:\n",
    "            print('ERROR: couldnot open image:\\n' + str(rawFramesDir + fileName))\n",
    "            break\n",
    "\n",
    "        outImage =  draw_all_keypoints_boxes_andCurves(inImage, filteredResultsDict[resKey][time], numberOfTeeth)\n",
    "\n",
    "        cv2.imwrite(path2saveCurves + fileName, outImage)\n",
    "        \n",
    "\n",
    "\n",
    "    print('\\nfor results set: ' + resKey + '\\n---Saved the calculated curves for  ' + str(len(os.listdir(path2saveCurves)))  + '   frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove curves that fail derivative test and landmarks with no curves\n",
    "path2saveRejectedCurves = mainPath + 'rejectedCurves/'\n",
    "\n",
    "cleanedUpResultsDict = reject2_soft_removeBadCurves(\n",
    "    filteredResultsDict,\n",
    "    path2saveCurves,\n",
    "    path2saveRejectedCurves,\n",
    "    curvDerivTreshDic,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "keyT = mainPath.split('/')[-2]\n",
    "print('\\nfinalStats:')\n",
    "print('---filteredResultsDict length:  '  + str(len(filteredResultsDict[keyT])))\n",
    "print('---cleanedUpResultsDict length:  ' + str(len(cleanedUpResultsDict[keyT])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reject3 Replace landmakrs that are too far from their curves with their projections on the curve\n",
    "path2saveRejectedLandmarks = mainPath + 'rejectedLandmakrs/'\n",
    "\n",
    "reject3_soft_replaceLandmarks2farFromCurve(\n",
    "    cleanedUpResultsDict,\n",
    "    path2saveCurves,\n",
    "    path2saveRejectedLandmarks,\n",
    "    maxDistanceBtwLandmarkAndCurve_replacement,\n",
    "    maxDistanceBtwLandmarkAndCurve_rejection,\n",
    "    maxItr_findingShortestDistance2Curve,\n",
    "    replaceBadLandmarkWithProjection,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add secondary confidence based on avg of #landmarks for specific tooth and total #landmarks for log\n",
    "nbOfProcessedTeeth = 0\n",
    "\n",
    "for resKey in cleanedUpResultsDict.keys():\n",
    "    for time in cleanedUpResultsDict[resKey].keys():\n",
    "        cleanedUpResultsDict[resKey][time]['secondaryConfidences'] = {}\n",
    "        \n",
    "        cleanedUpResultsDict[resKey][time]['logConfidence'] = sum(\n",
    "            cleanedUpResultsDict[resKey][time]['confidences'].values()\n",
    "        ) / TOTAL_EXPECTED_LANDMARKS_ON_LOG\n",
    "        \n",
    "        for toothKey in cleanedUpResultsDict[resKey][time]['confidences'].keys():\n",
    "            cleanedUpResultsDict[resKey][time]['secondaryConfidences'][toothKey] =\\\n",
    "            ( weightOfToothConfidence * cleanedUpResultsDict[resKey][time]['confidences'][toothKey] / numberOflandmarksIncludingToothTip + weightOfLogConfidence * cleanedUpResultsDict[resKey][time]['logConfidence'] ) / (weightOfToothConfidence + weightOfLogConfidence)\n",
    "            \n",
    "            nbOfProcessedTeeth += 1\n",
    "            \n",
    "            \n",
    "    print('for resKey ' + resKey + ' added secondary confidences for  ' + str(nbOfProcessedTeeth) + '  teeth out of the total of  ' + str(len(cleanedUpResultsDict[resKey]) * NUMBER_OF_TEETH) + '  teeth that we should have.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reject4 Remove logs where we don't have all toothTips, or enough landmarks for registeration\n",
    "path2saveRejectedLogs = mainPath + 'rejected_notEnoughLandmarks/'\n",
    "\n",
    "finalResultsDict = reject4_notEnoughValidLandmarks(\n",
    "    cleanedUpResultsDict,\n",
    "    path2saveRejectedLogs,\n",
    "    minNbOfDetectedPointsForTTandLS,\n",
    "    minNbOfDetectedPointsForOtherLandmarkTypes,\n",
    "    numberOfTeeth= NUMBER_OF_TEETH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# visualize the final cleaned up dict\n",
    "path2vis = mainPath + 'finalVisBeforeRegisteration/'\n",
    "\n",
    "for resKey in finalResultsDict.keys():\n",
    "    for time in finalResultsDict[resKey].keys():\n",
    "        fileName = finalResultsDict[resKey][time]['fileName'].split('/')[-1]\n",
    "        \n",
    "        inImage = cv2.imread(rawFramesDir + fileName)\n",
    "\n",
    "        outImage =  draw_all_keypoints_boxes_andCurves(inImage, finalResultsDict[resKey][time], NUMBER_OF_TEETH, drawOnlyValidated=True)\n",
    "\n",
    "        cv2.imwrite(path2vis + fileName, outImage)\n",
    "        \n",
    "    print('\\nfor results set: ' + resKey + '\\n---Saved the visualized images for  ' + str(len(os.listdir(path2vis)))  + '   frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Convert groundTuth XML to the json format used by this algo\n",
    "path2SaveJsons = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10/groundTruthLabels/'\n",
    "\n",
    "tree = ET.parse('/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10/groundTruth_Imageinfo.xml')\n",
    "\n",
    "\n",
    "\n",
    "#same bucket array everywhere\n",
    "bucketAr = [\n",
    "    [0.0, 0.0, 0.0, 0.0, \"Toothline\", \"00\"], \n",
    "    [0.0, 0.0, 0.0, 0.0, \"BucketBB\", \"00\"],\n",
    "    [0.0, 0.0, 0.0, 0.0, \"WearArea\", \"00\"]\n",
    "]\n",
    "\n",
    "for img in tree.getroot().findall('XMLSaveThumbnail'):\n",
    "    #setup the arrays to save into json\n",
    "    teethAr = []\n",
    "    keyPointsAr = []\n",
    "    for i in range(NUMBER_OF_TEETH):\n",
    "        teethAr.append([])\n",
    "        keyPointsAr.append([[0,0],[0,0],[0,0],[0,0],[0,0]])\n",
    "        \n",
    "        \n",
    "    \n",
    "    #go though the data\n",
    "    imgName = img.attrib['Path']\n",
    "    \n",
    "    allContainers = img.findall('Container')\n",
    "    for toothInd in range(len(allContainers)):\n",
    "        toothContainer = allContainers[toothInd]\n",
    "        \n",
    "        toothXmin = int(float(toothContainer.find('X_CanvasLeft').text))\n",
    "        toothYmin = int(float(toothContainer.find('Y_CanvasTop').text))\n",
    "        width = int(float(toothContainer.find('Width').text))\n",
    "        height = int(float(toothContainer.find('Height').text))\n",
    "        \n",
    "        if toothInd >= len(teethAr):\n",
    "            print('Error:  imgName:')\n",
    "            print(imgName)\n",
    "            print('toothInd:')\n",
    "            print(str(toothInd))\n",
    "            break\n",
    "        teethAr[toothInd] = [toothXmin, toothXmin + width, toothYmin, toothYmin + height, \"Tooth\", \"00\"]\n",
    "        keyPointsAr[toothInd][0] =  [(toothXmin + int(width/2)), toothYmin]\n",
    "        \n",
    "        for item in toothContainer.findall('PointLandmarks'):\n",
    "            xCord = int(float(item.find('X').text))\n",
    "            yCord = int(float(item.find('Y').text))\n",
    "            label = str(item.find('Label').text)\n",
    "            \n",
    "            if label == 'Lip Shroud':\n",
    "                keyPointsAr[toothInd][1] = [xCord, yCord]\n",
    "            elif label == 'Lifting Eye':\n",
    "                keyPointsAr[toothInd][2] = [xCord, yCord]\n",
    "            elif label == 'Cast Lip':\n",
    "                keyPointsAr[toothInd][3] = [xCord, yCord]\n",
    "            elif label == 'Bucket':\n",
    "                keyPointsAr[toothInd][4] = [xCord, yCord]\n",
    "            else:\n",
    "                print('ERROR: unknown label type  ' + label + '   for tooth  ' + str(toothInd) + '  for image:\\n' + imgName + '\\n')\n",
    "\n",
    "                \n",
    "    #save JSON\n",
    "    json2save = [keyPointsAr, teethAr, bucketAr]\n",
    "\n",
    "    with open(path2SaveJsons + imgName.replace('.png', '.json'), 'w') as fjson:\n",
    "        json.dump(json2save, fjson) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# visualize the groundTruth data (filteredResultsDict)\n",
    "path2vis = mainPath + 'groundTruthVisualization/'\n",
    "\n",
    "for resKey in filteredResultsDict.keys():\n",
    "    for time in filteredResultsDict[resKey].keys():\n",
    "        fileName = filteredResultsDict[resKey][time]['fileName'].split('/')[-1]\n",
    "        \n",
    "        inImage = cv2.imread(rawFramesDir + fileName)\n",
    "\n",
    "        outImage =  draw_just_keypoints_fromGroundTruth(inImage, filteredResultsDict[resKey][time], NUMBER_OF_TEETH)\n",
    "\n",
    "        cv2.imwrite(path2vis + fileName, outImage)\n",
    "        \n",
    "    print('\\nfor results set: ' + resKey + '\\n---Saved the visualized images for  ' + str(len(os.listdir(path2vis)))  + '   frames.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Looking at tooth Lengths from prepared WM logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Method Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### registeration stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRefDict(path2labelXml, path2UnlabeledImage):\n",
    "    refkeyPointsDic = {}\n",
    "    \n",
    "    img = cv2.imread(path2UnlabeledImage)\n",
    "    if img is None:\n",
    "        print('faild to find ref image. You probably forgot to set its name in config')\n",
    "    height, width, dim=img.shape\n",
    "\n",
    "    with open(path2labelXml) as fd:\n",
    "        tempDic = xmltodict.parse(fd.read())\n",
    "        \n",
    "        for typeK in tempDic['hs_frame_wear_landmarks'].keys():\n",
    "            if not typeK == 'img_name':\n",
    "                for nbK in tempDic['hs_frame_wear_landmarks'][typeK]:\n",
    "                    xcor = int(float(tempDic['hs_frame_wear_landmarks'][typeK][nbK]['@x']) * width)\n",
    "                    ycor = int(float(tempDic['hs_frame_wear_landmarks'][typeK][nbK]['@y']) * height)\n",
    "                    refkeyPointsDic[nbK] = [xcor, ycor]\n",
    "                \n",
    "    return refkeyPointsDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualizeRefDict(refDict, path2refImage, numberOfTeeth):\n",
    "    numberOfLandmarks = 5\n",
    "\n",
    "    \n",
    "    trgAr = []\n",
    "\n",
    "    landmakrsList = ['toothTip_', 'lipShroud_', 'liftingEye_', 'castLip_', 'bucketLandmark_']\n",
    "\n",
    "    for i in range(numberOfLandmarks):\n",
    "        keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "        for j in range(numberOfTeeth):\n",
    "            trgAr.append(refkeyPointsDic[landmakrsList[i] + str(j+1)])\n",
    "\n",
    "    trgPoints = getRegPointSetFromArray(trgAr)\n",
    "\n",
    "\n",
    "    refImage = cv2.imread(path2RefImage)\n",
    "    \n",
    "    displayPointsSetOnImage(refImage, trgPoints)\n",
    "    \n",
    "    \n",
    "    #plt.imshow(refImage)\n",
    "    #plt.title('visualizing refDict')\n",
    "    #plt.show()\n",
    "    \n",
    "    return refImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRegPointSetFromArray(validPoints):\n",
    "    outPoints = np.zeros((1, len(validPoints), 2), np.int32)\n",
    "    counter = 0\n",
    "    \n",
    "    for pp in validPoints:\n",
    "        outPoints[0, counter, 0] = int(pp[0])\n",
    "        outPoints[0, counter, 1] = int(pp[1])\n",
    "        counter+=1\n",
    "  \n",
    "    return outPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getDistanceBtwPoints(point1, point2):\n",
    "    #return abs(point2[0] - point1[0]) + abs(point2[1] - point1[1]) \n",
    "    #return math.sqrt(math.pow((point2[0] - point1[0]), 2) + math.pow((point2[1] - point1[1]), 2) )\n",
    "    return math.sqrt(math.pow((point2[1] - point1[1]), 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRegError(registeredPoints, targetPointSet):\n",
    "    totalError = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(targetPointSet[0])):\n",
    "        totalError += getDistanceBtwPoints(registeredPoints[0][i], targetPointSet[0][i])\n",
    "        counter+=1\n",
    "        \n",
    "    return totalError/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRegisteredPointsV3(refkeyPointsDic, resDicForFrame, numberOfTeeth, verbose = False, numberOfLandmarks = 5):\n",
    "    errorWithAll = 10000\n",
    "    errorJustLipShrouds = 10000\n",
    "    resultsWithAll = []\n",
    "    resultsWithJustLipShroud = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############################################################################################################\n",
    "    #################################### USE ALL LANDMARKS ########################################\n",
    "    ###############################################################################################################\n",
    "    srcAr = []\n",
    "    trgAr = []\n",
    "    indexToKeyMap = []\n",
    "    resultsArRigid = [[[0, 0] for j in range(numberOfLandmarks)] for i in range(numberOfTeeth)]\n",
    "\n",
    "\n",
    "    landmakrsList = ['toothTip_', 'lipShroud_', 'liftingEye_', 'castLip_', 'bucketLandmark_']\n",
    "\n",
    "    for i in range(1, numberOfLandmarks, 1): #do not use toothtip (i=0) landmarks in calculating transfromation\n",
    "        keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "        if keypointsKey in resDicForFrame:\n",
    "            keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "            for j in range(numberOfTeeth):\n",
    "                if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                    srcAr.append(keyPoints[j])\n",
    "                    trgAr.append(refkeyPointsDic[landmakrsList[i] + str(j+1)])\n",
    "\n",
    "\n",
    "    srcPoints = getRegPointSetFromArray(srcAr)\n",
    "    trgPoints = getRegPointSetFromArray(trgAr)\n",
    "\n",
    "    transformationRigid = cv2.estimateRigidTransform(srcPoints, trgPoints, False)\n",
    "\n",
    "############################################################################################################### \n",
    "    points2moveAr = []\n",
    "    for i in range(numberOfLandmarks):\n",
    "        keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "        if keypointsKey in resDicForFrame:\n",
    "            keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "            for j in range(numberOfTeeth):\n",
    "                if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                    indexToKeyMap.append({'landmarkNb': i, 'toothNb':j})\n",
    "                    points2moveAr.append(keyPoints[j])\n",
    "\n",
    "\n",
    "    points2move = getRegPointSetFromArray(points2moveAr)\n",
    "###############################################################################################################    \n",
    "    if not transformationRigid is None:\n",
    "        if transformationRigid.any():\n",
    "            transformedPointsRigid = cv2.transform(points2move, transformationRigid)\n",
    "\n",
    "            for i in range(transformedPointsRigid.shape[1]):\n",
    "                pointRigid =  transformedPointsRigid[0, i, :].tolist()\n",
    "                resultsArRigid[indexToKeyMap[i]['toothNb']][indexToKeyMap[i]['landmarkNb']] = pointRigid\n",
    "\n",
    "            curError = getRegError(transformedPointsRigid, srcPoints)\n",
    "            \n",
    "            if verbose:\n",
    "                print('RegidTransformation error using all landmarks was:  ' + str(curError) + '\\n')\n",
    "                \n",
    "                \n",
    "            errorWithAll = curError\n",
    "            resultsWithAll = resultsArRigid\n",
    "\n",
    "    else:\n",
    "        print('failed to find Rigid transformation using all landmarks for:')\n",
    "        print(resDicForFrame['fileName'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ###############################################################################################################\n",
    "    #################################### USE JUST LIPSHROUD ########################################\n",
    "    ###############################################################################################################      \n",
    "    srcAr = []\n",
    "    trgAr = []\n",
    "    indexToKeyMap = []\n",
    "    resultsArRigid = [[[0, 0] for j in range(numberOfLandmarks)] for i in range(numberOfTeeth)]\n",
    "\n",
    "\n",
    "    landmakrsList = ['toothTip_', 'lipShroud_', 'liftingEye_', 'castLip_', 'bucketLandmark_']\n",
    "\n",
    "    i = 1 # use only lipShroud landmarks for registration\n",
    "    keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "    if keypointsKey in resDicForFrame:\n",
    "        keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "        for j in range(numberOfTeeth):\n",
    "            if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                srcAr.append(keyPoints[j])\n",
    "                trgAr.append(refkeyPointsDic[landmakrsList[i] + str(j+1)])\n",
    "\n",
    "\n",
    "    srcPoints = getRegPointSetFromArray(srcAr)\n",
    "    trgPoints = getRegPointSetFromArray(trgAr)\n",
    "\n",
    "    transformationRigid = cv2.estimateRigidTransform(srcPoints, trgPoints, False)\n",
    "\n",
    "############################################################################################################### \n",
    "    points2moveAr = []\n",
    "    for i in range(numberOfLandmarks):\n",
    "        keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "        if keypointsKey in resDicForFrame:\n",
    "            keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "            for j in range(numberOfTeeth):\n",
    "                if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                    indexToKeyMap.append({'landmarkNb': i, 'toothNb':j})\n",
    "                    points2moveAr.append(keyPoints[j])\n",
    "\n",
    "\n",
    "    points2move = getRegPointSetFromArray(points2moveAr)\n",
    "###############################################################################################################    \n",
    "    if not transformationRigid is None:\n",
    "        if transformationRigid.any():\n",
    "            transformedPointsRigid = cv2.transform(points2move, transformationRigid)\n",
    "\n",
    "            for i in range(transformedPointsRigid.shape[1]):\n",
    "                pointRigid =  transformedPointsRigid[0, i, :].tolist()\n",
    "                resultsArRigid[indexToKeyMap[i]['toothNb']][indexToKeyMap[i]['landmarkNb']] = pointRigid\n",
    "\n",
    "            curError = getRegError(transformedPointsRigid, srcPoints)\n",
    "            \n",
    "            if verbose:\n",
    "                print('RegidTransformation error using just LipShrouds was:  ' + str(curError) + '\\n')\n",
    "                \n",
    "                \n",
    "            errorJustLipShrouds = curError\n",
    "            resultsWithJustLipShroud = resultsArRigid\n",
    "            \n",
    "            if errorJustLipShrouds*regEr_WithLs_lessThan_withAll_multiple < errorWithAll:\n",
    "                print('RegidTransformation using just lipShroud was better than using all landmarks for log:\\n' + str(resDicForFrame['fileName']) +  '\\nusing all landmarks the error was  ' + str(errorWithAll) + '  using just lipshrouds it was  ' + str(errorJustLipShrouds) + '\\n')\n",
    "\n",
    "                return [], 10000\n",
    "                \n",
    "\n",
    "    else:\n",
    "        print('failed to find Rigid transformation using just LipShrouds for:')\n",
    "        print(resDicForFrame['fileName'])\n",
    "        \n",
    "\n",
    "        \n",
    "    return resultsWithAll, errorWithAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### length stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getLandmarkOrApproxY(keypointsForThisTooth, fittedCurves):\n",
    "        ttY = keypointsForThisTooth[0][1]\n",
    "        ttX = keypointsForThisTooth[0][0]\n",
    "        lsY = keypointsForThisTooth[1][1]\n",
    "        leY = keypointsForThisTooth[2][1]\n",
    "        clY = keypointsForThisTooth[3][1]\n",
    "        bkY = keypointsForThisTooth[4][1]\n",
    "        \n",
    "        if not ttY or ttY <= 0:\n",
    "            print(\"error: missing tooth tip point landmark. Returning None. This should NOT happen\")\n",
    "            return None, None, None, None, None\n",
    "        \n",
    "        if not lsY or lsY <= 0:\n",
    "            if 'keypoints_2' in fittedCurves:\n",
    "                lsY = fittedCurves['keypoints_2'](ttX)\n",
    "            else:\n",
    "                lsY = None\n",
    "            \n",
    "        if not leY or leY <= 0:\n",
    "            if 'keypoints_3' in fittedCurves:\n",
    "                leY = fittedCurves['keypoints_3'](ttX)\n",
    "            else:\n",
    "                leY = None\n",
    "                \n",
    "        if not clY or clY <= 0:\n",
    "            if 'keypoints_4' in fittedCurves:\n",
    "                clY = fittedCurves['keypoints_4'](ttX)\n",
    "            else:\n",
    "                clY = None\n",
    "                \n",
    "        if not bkY or bkY <= 0:\n",
    "            if 'keypoints_5' in fittedCurves:\n",
    "                bkY = fittedCurves['keypoints_5'](ttX)\n",
    "            else:\n",
    "                bkY = None\n",
    "                \n",
    "        return ttY, lsY, leY, clY, bkY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def areRatiosOk(lengths, referenceRatiosDict, maxAllowedDistBtwRatiosDict, toothKey):\n",
    "    refsAreOk = True\n",
    "    if\\\n",
    "    'le2bk' in lengths and abs( (lengths['tt2ls'] / lengths['le2bk']) - referenceRatiosDict[toothKey]['tt2ls_over_le2bk'] ) > maxAllowedDistBtwRatiosDict[toothKey]['tt2ls_over_le2bk'] or\\\n",
    "    'cl2bk' in lengths and abs( (lengths['tt2ls'] / lengths['cl2bk']) - referenceRatiosDict[toothKey]['tt2ls_over_cl2bk'] ) > maxAllowedDistBtwRatiosDict[toothKey]['tt2ls_over_cl2bk'] or\\\n",
    "    'le2cl' in lengths and abs( (lengths['tt2ls'] / lengths['le2cl']) - referenceRatiosDict[toothKey]['tt2ls_over_le2cl'] ) > maxAllowedDistBtwRatiosDict[toothKey]['tt2ls_over_le2cl'] or\\\n",
    "    'ls2bk' in lengths and abs( (lengths['tt2ls'] / lengths['ls2bk']) - referenceRatiosDict[toothKey]['tt2ls_over_ls2bk'] ) > maxAllowedDistBtwRatiosDict[toothKey]['tt2ls_over_ls2bk'] or\\\n",
    "    'ls2cl' in lengths and abs( (lengths['tt2ls'] / lengths['ls2cl']) - referenceRatiosDict[toothKey]['tt2ls_over_ls2cl'] ) > maxAllowedDistBtwRatiosDict[toothKey]['tt2ls_over_ls2cl'] or\\\n",
    "    'ls2le' in lengths and abs( (lengths['tt2ls'] / lengths['ls2le']) - referenceRatiosDict[toothKey]['tt2ls_over_ls2le'] ) > maxAllowedDistBtwRatiosDict[toothKey]['tt2ls_over_ls2le']:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     23,
     31,
     40,
     42,
     54,
     62,
     76,
     77,
     82,
     98,
     99
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getAllLengthsForOneTooth(resDicForFrame, refKeyPointsDic, toothNumber, keypointsTypeString, referenceRatiosDict, maxAllowedDistBtwRatiosDict, maxAllowed_detectedAboveRefTT, minAllowed_toothLength, maxAllowed_toothLength, path2saveRejected, filePath, verbose = False):\n",
    "    #toothNumber starts from 1\n",
    "    lengths = {}\n",
    "    landmarks = {}\n",
    "\n",
    "    if keypointsTypeString == 'keypointsForTooth_':\n",
    "        fittedCurves = resDicForFrame['fittedCurves']\n",
    "    elif keypointsTypeString == 'rigid_keypointsForTooth_':\n",
    "        if 'rigid_fittedCurves' in resDicForFrame.keys():\n",
    "            fittedCurves = resDicForFrame['rigid_fittedCurves']\n",
    "        else:\n",
    "            return lengths, landmarks\n",
    "    elif keypointsTypeString == 'affine_keypointsForTooth_':\n",
    "        fittedCurves = resDicForFrame['affine_fittedCurves']\n",
    "    else:\n",
    "        print('ERROR: getAllLengthsForOneTooth  got a keypointsTypeString that was not recognized')\n",
    "        \n",
    "        \n",
    "    ttY, lsY, leY, clY, bkY = getLandmarkOrApproxY(\n",
    "        resDicForFrame[keypointsTypeString + str(toothNumber)],\n",
    "        fittedCurves\n",
    "    )\n",
    "    \n",
    "    if (ttY, lsY, leY, clY, bkY) == (None, None, None, None, None):\n",
    "        print(resDicForFrame['fileName'])\n",
    "    \n",
    "    \n",
    "    toothKey = 'Tooth_' + str(toothNumber)\n",
    "\n",
    "    #lengths['box'] = resDicForFrame[toothKey][6]\n",
    "    \n",
    "    if refKeyPointsDic is None:\n",
    "        print('ERROR in getAllLengthsForOneTooth did not find: ' + 'lipShroud_' + str(toothNumber) + '  in refkeyPointsDic')\n",
    "    else:\n",
    "        refLsY = int(refKeyPointsDic['lipShroud_' + str(toothNumber)][1])\n",
    "        refTtY = int(refKeyPointsDic['toothTip_' + str(toothNumber)][1])\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    # ********** EARLY RETURN1***************\n",
    "    if not keypointsTypeString == 'keypointsForTooth_' and (refTtY - ttY) > maxAllowed_detectedAboveRefTT:\n",
    "        #shutil.copy(filePath, path2saveRejected)\n",
    "        try:\n",
    "            shutil.move(path2visFinal + filePath.split('/')[-1], path2saveRejected)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print('getAllLengthsForOneTooth did not receive info for log\\n\\n' + filePath + '\\n\\nbecause the registered toothTip was too far above the reference toothTip. This happened for:\\n---tooth  ' + str(toothKey) + '\\n--registration type  ' + str(keypointsTypeString) + '\\n\\n\\n')\n",
    "        \n",
    "        return {}, {}\n",
    "    # **************************************\n",
    "    '''\n",
    "\n",
    "\n",
    "    if lsY:\n",
    "        lengths['tt2ls'] = lsY - ttY\n",
    "        lengths['tt2_ref_ls'] = refLsY - ttY\n",
    "        landmarks['ttY'] = ttY\n",
    "        landmarks['lsY'] = lsY\n",
    "        \n",
    "        \n",
    "        # ********** EARLY RETURN1***************\n",
    "        if keypointsTypeString == 'keypointsForTooth_' and (lengths['tt2ls'] > maxAllowed_toothLength or lengths['tt2ls'] < minAllowed_toothLength):\n",
    "\n",
    "            #shutil.copy(filePath, path2saveRejected)\n",
    "            try:\n",
    "                shutil.move(path2visFinal + filePath.split('/')[-1], path2saveRejected)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if verbose:\n",
    "                print('getAllLengthsForOneTooth did not receive info for log\\n\\n' + filePath + '\\n\\nbecause the detected toothLengths was not withing the acceptable range. This happened for:\\n---tooth  ' + str(toothKey) + '\\n--registration type  ' + str(keypointsTypeString) + '\\npredicted toothLength:  ' + str(lengths['tt2ls']) + '\\n\\n\\n')\n",
    "\n",
    "            return {}, {}\n",
    "        # **************************************\n",
    "\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"\\n\\nError:getAllLengthsForOneTooth could not find the lipShroud point for this image for key:\\n\" + str(keypointsTypeString + str(toothNumber)) + '\\nandResults:\\n' +str(resDicForFrame[keypointsTypeString + str(toothNumber)]) + '\\n' + toothKey + '\\n this should not have happened')\n",
    "\n",
    "        \n",
    "        \n",
    "    if leY:\n",
    "        landmarks['leY'] = leY\n",
    "        if(leY - lsY) > 0:\n",
    "            lengths['ls2le'] = leY - lsY\n",
    "            \n",
    "        if clY:\n",
    "            landmarks['clY'] = clY\n",
    "            if(clY - leY ) > 0:\n",
    "                lengths['le2cl'] = clY - leY \n",
    "            \n",
    "        if bkY:\n",
    "            landmarks['bkY'] = bkY\n",
    "            if(bkY - leY) > 0:\n",
    "                lengths['le2bk'] = bkY - leY\n",
    "\n",
    "   \n",
    "    if verbose:\n",
    "        if 'le2bk' in lengths:\n",
    "            print('le2bk:  ' + str(lengths['le2bk']))\n",
    "            print()\n",
    "\n",
    "        if 'cl2bk' in lengths:\n",
    "            print('cl2bk:  ' + str(lengths['cl2bk']))\n",
    "            print()\n",
    "\n",
    "        if 'le2cl' in lengths:\n",
    "            print('le2cl:  ' + str(lengths['le2cl']))\n",
    "            print()\n",
    "\n",
    "        if 'ls2bk' in lengths:\n",
    "            print('ls2bk:  ' + str(lengths['ls2bk']))\n",
    "            print()\n",
    "\n",
    "        if 'ls2cl' in lengths:\n",
    "            print('ls2cl:  ' + str(lengths['ls2cl']))\n",
    "            print()\n",
    "\n",
    "        if 'ls2le' in lengths:\n",
    "            print('ls2le:  ' + str(lengths['ls2le']))\n",
    "            print()\n",
    "        \n",
    "        \n",
    "        \n",
    "     # ********** #reject from validation plots ***************\n",
    "    if areRatiosOk(lengths, referenceRatiosDict, maxAllowedDistBtwRatiosDict, 'tooth_' + str(toothNumber)):\n",
    "        lengths['valid_tt2ls'] = lengths['tt2ls']\n",
    "    else:\n",
    "        pass\n",
    "    # **************************************\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return lengths, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getAllLengthsForOneRegisterationType(resDicForThisResultsSet, refkeyPointsDic, toothNumber,refKey, regTypeKeyword, referenceRatiosDict, maxAllowedDistBtwRatiosDict, maxAllowed_detectedAboveRefTT,minAllowed_toothLength, maxAllowed_toothLength, path2saveRejected, verbose = False):\n",
    "    \n",
    "    #put everything in a list for easier plotting\n",
    "    all_times_list  = set()\n",
    "    all_tt2ls_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_ls2le_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_le2cl_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_le2bk_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_ls2cl_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_cl2bk_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_ls2bk_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    valid_tt2ls_dict= {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    tt2_ref_ls      = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    forSmoothing = {}\n",
    "\n",
    "    nbOfSuccessfulCalcs = 0\n",
    "    for time in sorted( resDicForThisResultsSet.keys() ):\n",
    "        \n",
    "        confidence = resDicForThisResultsSet[time]['confidences']['tooth_' + str(toothNumber)]\n",
    "        secondaryConfidence = resDicForThisResultsSet[time]['secondaryConfidences']['tooth_' + str(toothNumber)]\n",
    "        logConfidence = resDicForThisResultsSet[time]['logConfidence']\n",
    "        \n",
    "        if regTypeKeyword == 'keypointsForTooth_':\n",
    "            lengths, landmarks = getAllLengthsForOneTooth(\n",
    "                resDicForThisResultsSet[time],\n",
    "                refkeyPointsDic,\n",
    "                toothNumber,\n",
    "                regTypeKeyword,\n",
    "                referenceRatiosDict,\n",
    "                maxAllowedDistBtwRatiosDict,\n",
    "                maxAllowed_detectedAboveRefTT,\n",
    "                minAllowed_toothLength,\n",
    "                maxAllowed_toothLength,\n",
    "                path2saveRejected,\n",
    "                resDicForThisResultsSet[time]['fileName'],\n",
    "                verbose = verbose\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            lengths, landmarks = getAllLengthsForOneTooth(\n",
    "                resDicForThisResultsSet[time]['registrations'][refKey],\n",
    "                refkeyPointsDic,\n",
    "                toothNumber,\n",
    "                regTypeKeyword,\n",
    "                referenceRatiosDict,\n",
    "                maxAllowedDistBtwRatiosDict,\n",
    "                maxAllowed_detectedAboveRefTT,\n",
    "                minAllowed_toothLength, \n",
    "                maxAllowed_toothLength,\n",
    "                path2saveRejected,\n",
    "                resDicForThisResultsSet[time]['fileName'],\n",
    "                verbose = verbose\n",
    "            )\n",
    "            \n",
    "            \n",
    "        if len(lengths.keys()) > 0 and len(landmarks.keys()) > 0:\n",
    "            nbOfSuccessfulCalcs += 1\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('getAllLengthsForOneRegisterationType did not receive info for log\\n\\n' + resDicForThisResultsSet[time]['fileName'] + '\\n\\nbecause either the registered toothTip was too far above the reference toothTip or detected toothLengths was not withing the acceptable range. This happened for:\\n---reference frame  ' + str(refKey) + '\\n--registration type  ' + str(regTypeKeyword) +  '\\n---time step   ' + str(time) + '\\n\\n\\n')\n",
    "\n",
    "        \n",
    "        if 'tt2ls' in lengths:\n",
    "            all_tt2ls_dict['lengths'].append(lengths['tt2ls'])\n",
    "            all_tt2ls_dict['times'].append(time)\n",
    "            all_tt2ls_dict['confidences'].append(confidence)\n",
    "            all_tt2ls_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_tt2ls_dict['logConfidence'].append(logConfidence)\n",
    "            \n",
    "            all_times_list.add(time)\n",
    "            \n",
    "            forSmoothing[time] = lengths['tt2ls']\n",
    "            \n",
    "            \n",
    "            \n",
    "        if 'ls2le' in lengths:\n",
    "            all_ls2le_dict['lengths'].append(lengths['ls2le'])\n",
    "            all_ls2le_dict['times'].append(time)\n",
    "            all_ls2le_dict['confidences'].append(confidence)\n",
    "            all_ls2le_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_ls2le_dict['logConfidence'].append(logConfidence)\n",
    "        if 'le2cl' in lengths:\n",
    "            all_le2cl_dict['lengths'].append(lengths['le2cl'])\n",
    "            all_le2cl_dict['times'].append(time)\n",
    "            all_le2cl_dict['confidences'].append(confidence)\n",
    "            all_le2cl_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_le2cl_dict['logConfidence'].append(logConfidence)\n",
    "        if 'le2bk' in lengths:\n",
    "            all_le2bk_dict['lengths'].append(lengths['le2bk'])\n",
    "            all_le2bk_dict['times'].append(time)\n",
    "            all_le2bk_dict['confidences'].append(confidence)\n",
    "            all_le2bk_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_le2bk_dict['logConfidence'].append(logConfidence)\n",
    "        if 'cl2bk' in lengths:\n",
    "            all_cl2bk_dict['lengths'].append(lengths['cl2bk'])\n",
    "            all_cl2bk_dict['times'].append(time)\n",
    "            all_cl2bk_dict['confidences'].append(confidence)\n",
    "            all_cl2bk_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_cl2bk_dict['logConfidence'].append(logConfidence)\n",
    "        if 'ls2cl' in lengths:\n",
    "            all_ls2cl_dict['lengths'].append(lengths['ls2cl'])\n",
    "            all_ls2cl_dict['times'].append(time)\n",
    "            all_ls2cl_dict['confidences'].append(confidence)\n",
    "            all_ls2cl_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_ls2cl_dict['logConfidence'].append(logConfidence)\n",
    "        if 'ls2bk' in lengths:\n",
    "            all_ls2bk_dict['lengths'].append(lengths['ls2bk'])\n",
    "            all_ls2bk_dict['times'].append(time)\n",
    "            all_ls2bk_dict['confidences'].append(confidence)\n",
    "            all_ls2bk_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_ls2bk_dict['logConfidence'].append(logConfidence)\n",
    "        if 'valid_tt2ls' in lengths:\n",
    "            valid_tt2ls_dict['lengths'].append(lengths['valid_tt2ls'])\n",
    "            valid_tt2ls_dict['times'].append(time)\n",
    "            valid_tt2ls_dict['confidences'].append(confidence)\n",
    "            valid_tt2ls_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            valid_tt2ls_dict['logConfidence'].append(logConfidence)\n",
    "        if 'tt2_ref_ls' in lengths:\n",
    "            tt2_ref_ls['lengths'].append(lengths['tt2_ref_ls'])\n",
    "            tt2_ref_ls['times'].append(time)\n",
    "            tt2_ref_ls['confidences'].append(confidence)\n",
    "            tt2_ref_ls['secondaryConfidences'].append(secondaryConfidence)\n",
    "            tt2_ref_ls['logConfidence'].append(logConfidence)\n",
    "\n",
    "\n",
    "\n",
    "    outDict = {\n",
    "        'landmarks'       :  landmarks,\n",
    "        'all_times_list'  : all_times_list,\n",
    "        'all_tt2ls_dict'  : all_tt2ls_dict,\n",
    "        'all_ls2le_dict'  : all_ls2le_dict,\n",
    "        'all_le2cl_dict'  : all_le2cl_dict,\n",
    "        'all_le2bk_dict'  : all_le2bk_dict,\n",
    "        'all_ls2cl_dict'  : all_ls2cl_dict,\n",
    "        'all_cl2bk_dict'  : all_cl2bk_dict,\n",
    "        'all_ls2bk_dict'  : all_ls2bk_dict,\n",
    "        'valid_tt2ls_dict': valid_tt2ls_dict,\n",
    "        'tt2_ref_ls'      : tt2_ref_ls,\n",
    "    }\n",
    "    \n",
    "    return outDict, forSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getAllLengthsForOneRegisterationType(resDicForThisResultsSet, refkeyPointsDic, toothNumber,refKey, regTypeKeyword, referenceRatiosDict, maxAllowedDistBtwRatiosDict, maxAllowed_detectedAboveRefTT,minAllowed_toothLength, maxAllowed_toothLength, path2saveRejected, verbose = False):\n",
    "    \n",
    "    #put everything in a list for easier plotting\n",
    "    all_times_list  = set()\n",
    "    all_tt2ls_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_ls2le_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_le2cl_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_le2bk_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_ls2cl_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_cl2bk_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    all_ls2bk_dict  = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    valid_tt2ls_dict= {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    tt2_ref_ls      = {'times':[], 'lengths':[], 'confidences':[], 'secondaryConfidences':[], 'logConfidence':[]}\n",
    "    forSmoothing = {}\n",
    "\n",
    "    nbOfSuccessfulCalcs = 0\n",
    "    for time in sorted( resDicForThisResultsSet.keys() ):\n",
    "        \n",
    "        confidence = resDicForThisResultsSet[time]['confidences']['tooth_' + str(toothNumber)]\n",
    "        secondaryConfidence = resDicForThisResultsSet[time]['secondaryConfidences']['tooth_' + str(toothNumber)]\n",
    "        logConfidence = resDicForThisResultsSet[time]['logConfidence']\n",
    "        \n",
    "        if regTypeKeyword == 'keypointsForTooth_':\n",
    "            lengths, landmarks = getAllLengthsForOneTooth(\n",
    "                resDicForThisResultsSet[time],\n",
    "                refkeyPointsDic,\n",
    "                toothNumber,\n",
    "                regTypeKeyword,\n",
    "                referenceRatiosDict,\n",
    "                maxAllowedDistBtwRatiosDict,\n",
    "                maxAllowed_detectedAboveRefTT,\n",
    "                minAllowed_toothLength,\n",
    "                maxAllowed_toothLength,\n",
    "                path2saveRejected,\n",
    "                resDicForThisResultsSet[time]['fileName'],\n",
    "                verbose = verbose\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            lengths, landmarks = getAllLengthsForOneTooth(\n",
    "                resDicForThisResultsSet[time]['registrations'][refKey],\n",
    "                refkeyPointsDic,\n",
    "                toothNumber,\n",
    "                regTypeKeyword,\n",
    "                referenceRatiosDict,\n",
    "                maxAllowedDistBtwRatiosDict,\n",
    "                maxAllowed_detectedAboveRefTT,\n",
    "                minAllowed_toothLength, \n",
    "                maxAllowed_toothLength,\n",
    "                path2saveRejected,\n",
    "                resDicForThisResultsSet[time]['fileName'],\n",
    "                verbose = verbose\n",
    "            )\n",
    "            \n",
    "            \n",
    "        if len(lengths.keys()) > 0 and len(landmarks.keys()) > 0:\n",
    "            nbOfSuccessfulCalcs += 1\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('getAllLengthsForOneRegisterationType did not receive info for log\\n\\n' + resDicForThisResultsSet[time]['fileName'] + '\\n\\nbecause either the registered toothTip was too far above the reference toothTip or detected toothLengths was not withing the acceptable range. This happened for:\\n---reference frame  ' + str(refKey) + '\\n--registration type  ' + str(regTypeKeyword) +  '\\n---time step   ' + str(time) + '\\n\\n\\n')\n",
    "\n",
    "        \n",
    "        if 'tt2ls' in lengths:\n",
    "            all_tt2ls_dict['lengths'].append(lengths['tt2ls'])\n",
    "            all_tt2ls_dict['times'].append(time)\n",
    "            all_tt2ls_dict['confidences'].append(confidence)\n",
    "            all_tt2ls_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_tt2ls_dict['logConfidence'].append(logConfidence)\n",
    "            \n",
    "            all_times_list.add(time)\n",
    "            \n",
    "            forSmoothing[time] = lengths['tt2ls']\n",
    "            \n",
    "            \n",
    "            \n",
    "        if 'ls2le' in lengths:\n",
    "            all_ls2le_dict['lengths'].append(lengths['ls2le'])\n",
    "            all_ls2le_dict['times'].append(time)\n",
    "            all_ls2le_dict['confidences'].append(confidence)\n",
    "            all_ls2le_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_ls2le_dict['logConfidence'].append(logConfidence)\n",
    "        if 'le2cl' in lengths:\n",
    "            all_le2cl_dict['lengths'].append(lengths['le2cl'])\n",
    "            all_le2cl_dict['times'].append(time)\n",
    "            all_le2cl_dict['confidences'].append(confidence)\n",
    "            all_le2cl_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_le2cl_dict['logConfidence'].append(logConfidence)\n",
    "        if 'le2bk' in lengths:\n",
    "            all_le2bk_dict['lengths'].append(lengths['le2bk'])\n",
    "            all_le2bk_dict['times'].append(time)\n",
    "            all_le2bk_dict['confidences'].append(confidence)\n",
    "            all_le2bk_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_le2bk_dict['logConfidence'].append(logConfidence)\n",
    "        if 'cl2bk' in lengths:\n",
    "            all_cl2bk_dict['lengths'].append(lengths['cl2bk'])\n",
    "            all_cl2bk_dict['times'].append(time)\n",
    "            all_cl2bk_dict['confidences'].append(confidence)\n",
    "            all_cl2bk_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_cl2bk_dict['logConfidence'].append(logConfidence)\n",
    "        if 'ls2cl' in lengths:\n",
    "            all_ls2cl_dict['lengths'].append(lengths['ls2cl'])\n",
    "            all_ls2cl_dict['times'].append(time)\n",
    "            all_ls2cl_dict['confidences'].append(confidence)\n",
    "            all_ls2cl_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_ls2cl_dict['logConfidence'].append(logConfidence)\n",
    "        if 'ls2bk' in lengths:\n",
    "            all_ls2bk_dict['lengths'].append(lengths['ls2bk'])\n",
    "            all_ls2bk_dict['times'].append(time)\n",
    "            all_ls2bk_dict['confidences'].append(confidence)\n",
    "            all_ls2bk_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            all_ls2bk_dict['logConfidence'].append(logConfidence)\n",
    "        if 'valid_tt2ls' in lengths:\n",
    "            valid_tt2ls_dict['lengths'].append(lengths['valid_tt2ls'])\n",
    "            valid_tt2ls_dict['times'].append(time)\n",
    "            valid_tt2ls_dict['confidences'].append(confidence)\n",
    "            valid_tt2ls_dict['secondaryConfidences'].append(secondaryConfidence)\n",
    "            valid_tt2ls_dict['logConfidence'].append(logConfidence)\n",
    "        if 'tt2_ref_ls' in lengths:\n",
    "            tt2_ref_ls['lengths'].append(lengths['tt2_ref_ls'])\n",
    "            tt2_ref_ls['times'].append(time)\n",
    "            tt2_ref_ls['confidences'].append(confidence)\n",
    "            tt2_ref_ls['secondaryConfidences'].append(secondaryConfidence)\n",
    "            tt2_ref_ls['logConfidence'].append(logConfidence)\n",
    "\n",
    "\n",
    "\n",
    "    outDict = {\n",
    "        'landmarks'       :  landmarks,\n",
    "        'all_times_list'  : all_times_list,\n",
    "        'all_tt2ls_dict'  : all_tt2ls_dict,\n",
    "        'all_ls2le_dict'  : all_ls2le_dict,\n",
    "        'all_le2cl_dict'  : all_le2cl_dict,\n",
    "        'all_le2bk_dict'  : all_le2bk_dict,\n",
    "        'all_ls2cl_dict'  : all_ls2cl_dict,\n",
    "        'all_cl2bk_dict'  : all_cl2bk_dict,\n",
    "        'all_ls2bk_dict'  : all_ls2bk_dict,\n",
    "        'valid_tt2ls_dict': valid_tt2ls_dict,\n",
    "        'tt2_ref_ls'      : tt2_ref_ls,\n",
    "    }\n",
    "    \n",
    "    return outDict, forSmoothingdef getAllLengthsAndLandmarks(finalResultsDict, numberOfTeeth, referenceRatiosDict, maxAllowedDistBtwRatiosDict, maxAllowed_detectedAboveRefTT, minAllowed_toothLength, maxAllowed_toothLength, path2saveRejected, verbose = False):\n",
    "    \n",
    "    listOfKeyWords = ['keypointsForTooth_', 'rigid_keypointsForTooth_']\n",
    "    \n",
    "    toothLengthsDict = {}\n",
    "    \n",
    "    for resKey in finalResultsDict.keys():\n",
    "        toothLengthsDict[resKey] = {}\n",
    "        totalNbOfExpectedTimeSteps = len(finalResultsDict[resKey].keys()) \n",
    "        totalNbOfSuccessfullCalcs = 0\n",
    "    \n",
    "        toothLengthsDict[resKey]['forSmoothing'] = getEmptySmoothedDict(\n",
    "            numberOfTeeth,\n",
    "            ['rigid_keypointsForTooth_'],\n",
    "            references2use\n",
    "        )\n",
    "        \n",
    "        for regTypeKeyWord in listOfKeyWords:\n",
    "            \n",
    "            toothLengthsDict[resKey][regTypeKeyWord] = {}\n",
    "\n",
    "            for refKey in references2use:\n",
    "                \n",
    "                #if refKey in finalResultsDict[resKey][time]['registrations'].keys(): bug from script. time was not recognized\n",
    "                if refKey in finalResultsDict[resKey][0]['registrations'].keys():\n",
    "                \n",
    "                    path2RefImage = mainPath + 'referenceFrames/images/' + refKey + '.png'\n",
    "                    path2Reflabel = mainPath + 'referenceFrames/labels/' + refKey + '_landmarkCoords.xml'\n",
    "                    refkeyPointsDic = getRefDict(path2Reflabel, path2RefImage)\n",
    "                    \n",
    "                    toothLengthsDict[resKey][regTypeKeyWord][refKey] = {}\n",
    "                    \n",
    "                    for i in range(numberOfTeeth):\n",
    "                        toothNumber = i + 1\n",
    "\n",
    "                        lengthsForRegType, dicForSmoothing = getAllLengthsForOneRegisterationType(\n",
    "                            finalResultsDict[resKey],\n",
    "                            refkeyPointsDic,\n",
    "                            toothNumber,\n",
    "                            refKey,\n",
    "                            regTypeKeyWord,\n",
    "                            referenceRatiosDict,\n",
    "                            maxAllowedDistBtwRatiosDict,\n",
    "                            maxAllowed_detectedAboveRefTT,\n",
    "                            minAllowed_toothLength,\n",
    "                            maxAllowed_toothLength,\n",
    "                            path2saveRejected,\n",
    "                            verbose = verbose\n",
    "                        )\n",
    "                        \n",
    "                        toothNbKey = 'tooth_'+str(toothNumber)+'_info'\n",
    "                        \n",
    "                        toothLengthsDict[resKey][regTypeKeyWord][refKey][toothNbKey] = lengthsForRegType\n",
    "\n",
    "                        if len(lengthsForRegType['all_tt2ls_dict']['lengths']) == totalNbOfExpectedTimeSteps:\n",
    "                            totalNbOfSuccessfullCalcs += 1\n",
    "                        else:\n",
    "                            if verbose:\n",
    "                                print('\\n\\n\\n*****************************************************')\n",
    "                                print('getAllLengthsAndLandmarks did not find the values for all of the  ' +\\\n",
    "                                      str(totalNbOfExpectedTimeSteps) + '  it expected to find values for.\\nrefKey: '\\\n",
    "                                      + str(refKey) + '\\nregType:  ' + str(regTypeKeyWord) + '\\n')\n",
    "                                print('*************************************************************\\n\\n\\n')\n",
    "                        \n",
    "                        if regTypeKeyWord == 'rigid_keypointsForTooth_':\n",
    "                            toothLengthsDict[resKey]['forSmoothing'][toothNbKey]['all_times'].update(lengthsForRegType['all_times_list']) \n",
    "\n",
    "                            toothLengthsDict[resKey]['forSmoothing'][toothNbKey][regTypeKeyWord][refKey] = dicForSmoothing\n",
    "\n",
    "                \n",
    "    totalNbOfSuccessfullCalcs = str(totalNbOfSuccessfullCalcs/numberOfTeeth)\n",
    "    nbOfExpectedCalcs = str(len(listOfKeyWords) * len(references2use))\n",
    "    print('\\n\\n****for results set: ' + resKey + '\\ngetAllLengthsAndLandmarks successfully calculated all of the  '+ str(totalNbOfExpectedTimeSteps)+ ' expected lengths in   ' + totalNbOfSuccessfullCalcs + '   out of the   ' + nbOfExpectedCalcs + '   total number of referenceFrame-registerationType combinations that we processed. You can turn on verbose to get more info.')                       \n",
    "    return toothLengthsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getEmptySmoothedDict(numberOfTeeth, listOfRegTypeKeyWords, listOfReferences2use):\n",
    "    \n",
    "    outDict = {}\n",
    "    \n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_'+str(i+1)+'_info'\n",
    "        \n",
    "        outDict[toothNbKey] = {}\n",
    "        outDict[toothNbKey]['all_times'] = set()\n",
    "        \n",
    "        \n",
    "        for regTypeKeyWord in listOfRegTypeKeyWords:\n",
    "            outDict[toothNbKey][regTypeKeyWord] = {}\n",
    "            \n",
    "            \n",
    "            for refKey in listOfReferences2use: \n",
    "                \n",
    "                outDict[toothNbKey][regTypeKeyWord][refKey] = {}\n",
    "                \n",
    "                \n",
    "    return outDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Registering, Calculating, and plotting all the Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Register all frames to multiple common references\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "numberOfLandmarks = numberOflandmarksIncludingToothTip\n",
    "\n",
    "for resKey in finalResultsDict.keys():\n",
    "    numberOfProcessesFrames = 0\n",
    "    totalNbOfRegisterations = 0\n",
    "    \n",
    "    for time in finalResultsDict[resKey].keys():\n",
    "        numberOfProcessesFrames += 1\n",
    "        numberOfSuccessfulRegistrationsForThisFrame = 0\n",
    "        finalResultsDict[resKey][time]['registrations'] = {}\n",
    "            \n",
    "        for refKey in references2use:\n",
    "            finalResultsDict[resKey][time]['registrations'][refKey] = {}\n",
    "            \n",
    "            \n",
    "            path2RefImage = mainPath + 'referenceFrames/images/' + refKey + '.png'\n",
    "            path2Reflabel = mainPath + 'referenceFrames/labels/' + refKey + '_landmarkCoords.xml'\n",
    "            refkeyPointsDic = getRefDict(path2Reflabel, path2RefImage)\n",
    "            \n",
    "        \n",
    "            resultsArRigid, regError = getRegisteredPointsV3(\n",
    "                refkeyPointsDic,\n",
    "                finalResultsDict[resKey][time],\n",
    "                numberOfTeeth\n",
    "            )\n",
    "            \n",
    "            if len(resultsArRigid) > 0:\n",
    "            \n",
    "                if len(resultsArRigid) > 1:\n",
    "                    numberOfSuccessfulRegistrationsForThisFrame += 1\n",
    "                    totalNbOfRegisterations += 1\n",
    "\n",
    "                for i in range(numberOfTeeth):\n",
    "                    #rigid registration\n",
    "                    key2storRigid = 'rigid_keypointsForTooth_' + str(i+1)\n",
    "                    finalResultsDict[resKey][time]['registrations'][refKey][key2storRigid] = resultsArRigid[i]\n",
    "\n",
    "\n",
    "                for j in range(numberOfLandmarks):\n",
    "                    #rigid registration\n",
    "                    key2storRigid = 'rigid_keypoints_' + str(j+1)\n",
    "                    finalResultsDict[resKey][time]['registrations'][refKey][key2storRigid] = [p[j] for p in resultsArRigid]\n",
    "                    \n",
    "            else:\n",
    "                print('could not register this frame.')\n",
    "                \n",
    "                \n",
    "    print('\\nfor results set: ' + resKey + '\\n---found a total number of  ' + str(totalNbOfRegisterations) + '  registrations out of the  ' + str(numberOfProcessesFrames * len(references2use)) +'  registrations that were expected based on the number of processed frames and refernce images provided.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit curves to registered landmarks and calculate derivatives\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "\n",
    "for resKey in finalResultsDict.keys():\n",
    "    totalRegisteredFrames = 0\n",
    "    totalNbOfImagesWithFittedCurves = 0\n",
    "    for time in finalResultsDict[resKey].keys():\n",
    "        for refKey in references2use:\n",
    "            \n",
    "            if refKey in finalResultsDict[resKey][time]['registrations'].keys():\n",
    "                totalRegisteredFrames += 1\n",
    "                fileName = finalResultsDict[resKey][time]['fileName'].split('/')[-1]\n",
    "                \n",
    "                if len(finalResultsDict[resKey][time]['registrations'][refKey]) > 0:\n",
    "                    rigid_fittC = fitCurve2keypoints(\n",
    "                        finalResultsDict[resKey][time]['registrations'][refKey],\n",
    "                        numberOfTeeth,\n",
    "                        'rigid_keypoints_'\n",
    "                    )\n",
    "\n",
    "                    if len(rigid_fittC) > 1:\n",
    "                        totalNbOfImagesWithFittedCurves += 1\n",
    "\n",
    "                    finalResultsDict[resKey][time]['registrations'][refKey]['rigid_fittedCurves'] = rigid_fittC\n",
    "\n",
    "                    finalResultsDict[resKey][time]['registrations'][refKey]['rigid_2ndDerivFittedCurves'] = get2ndDerivativeOfCurves(rigid_fittC)\n",
    "                    #affine_fittC = fitCurve2keypoints(finalResultsDict[resKey][time], numberOfTeeth, 'affine_keypoints_')\n",
    "                    #finalResultsDict[resKey][time]['registrations'][refKey]['affine_fittedCurves'] = affine_fittC\n",
    "                    #finalResultsDict[resKey][time]['registrations'][refKey]['affine_2ndDerivFittedCurves'] = get2ndDerivativeOfCurves(affine_fittC)\n",
    "                \n",
    "    print('\\nfor results set: ' + resKey + '\\n---fitted at least one curve to  ' + str(totalNbOfImagesWithFittedCurves) + '  registered frames out of the total of  ' + str(totalRegisteredFrames) +'  registered frames that were processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# visualize all registered and original landmarks\n",
    "\n",
    "path2visFinal = mainPath + 'finalVis/'\n",
    "\n",
    "for resKey in finalResultsDict.keys():\n",
    "    for time in finalResultsDict[resKey].keys():\n",
    "        \n",
    "        fileName = finalResultsDict[resKey][time]['fileName'].split('/')[-1]\n",
    "        inImage = cv2.imread(rawFramesDir + fileName)\n",
    "        \n",
    "        outImage =  draw_all_keypoints_boxes_andCurves(\n",
    "            inImage,\n",
    "            finalResultsDict[resKey][time],\n",
    "            numberOfTeeth=NUMBER_OF_TEETH,\n",
    "            refKey=refKey,\n",
    "            regTypeKeyword='',\n",
    "            drawOnlyValidated=True,\n",
    "            doNotDrawBoxes=True\n",
    "        )\n",
    "        \n",
    "        cv2.putText(outImage,'validInputFrame', (30,70), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0), 2, 0)\n",
    "                       \n",
    "        for refKey in references2use:\n",
    "            if refKey in finalResultsDict[resKey][time]['registrations'].keys():\n",
    "            \n",
    "                path2RefImage = mainPath + 'referenceFrames/images/' + refKey + '.png'\n",
    "                path2Reflabel = mainPath + 'referenceFrames/labels/' + refKey + '_landmarkCoords.xml'\n",
    "                refkeyPointsDic = getRefDict(path2Reflabel, path2RefImage)\n",
    "\n",
    "                #uncomment this and comment the one below to see the ref image\n",
    "                #refVis = visualizeRefDict(refkeyPointsDic, path2RefImage)\n",
    "                #refVis = cv2.imread(wmsDir + fileName)\n",
    "\n",
    "\n",
    "                refImage = cv2.imread(path2RefImage)\n",
    "\n",
    "                if refImage is None or inImage is None:\n",
    "                    print(\"couldn't read refImage or inImage for:\")\n",
    "                    print(path2RefImage)\n",
    "                    print(rawFramesDir + fileName)\n",
    "                else:\n",
    "                    \n",
    "                    outImageRigid =  draw_all_keypoints_boxes_andCurves(\n",
    "                        refImage,\n",
    "                        finalResultsDict[resKey][time],\n",
    "                        numberOfTeeth=NUMBER_OF_TEETH,\n",
    "                        refKey=refKey,\n",
    "                        regTypeKeyword='rigid_',\n",
    "                        drawOnlyValidated=False,\n",
    "                        doNotDrawBoxes=True\n",
    "                    )\n",
    "                    \n",
    "                    cv2.putText(outImageRigid,refKey, (30,70), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0), 2, 0)\n",
    "\n",
    "\n",
    "                    '''\n",
    "                    outImageAffine =  draw_all_keypoints_boxes_andCurves(\n",
    "                        refImage,\n",
    "                        finalResultsDict[resKey][time],\n",
    "                        numberOfTeeth=NUMBER_OF_TEETH,\n",
    "                        regTypeKeyword='affine_',\n",
    "                        drawOnlyValidated=False,\n",
    "                        doNotDrawBoxes=True\n",
    "                    )\n",
    "                    '''\n",
    "\n",
    "\n",
    "\n",
    "                    if not outImageRigid is None:\n",
    "                        outImage = np.concatenate((outImage, outImageRigid), axis=1)\n",
    "                        \n",
    "            else:\n",
    "                print(\"\\nrefKey:  \" + str(refKey) + \" did not exist for:\\n\" + str(fileName) + \"\\n\")\n",
    "                    \n",
    "        cv2.imwrite(path2visFinal + fileName, outImage)\n",
    "        \n",
    "        \n",
    "    print('\\nfor results set: ' + resKey + '\\n---Saved the final visualized images for  ' + str(len(os.listdir(path2visFinal)))  + '   frames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all the lengths and reject frames where ratio of test image are too far from ratios of reference\n",
    "path2saveRejectedBadRatio = mainPath + 'rejected_badRatio/'\n",
    "\n",
    "lengthsAndLandmarksDict = getAllLengthsAndLandmarks(finalResultsDict, NUMBER_OF_TEETH, referenceRatiosDict, maxAllowedDistBtwRatiosDict, maxAllowed_detectedAboveRefTT, minAllowed_toothLength, maxAllowed_toothLength, path2saveRejectedBadRatio, verbose= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (Version 3) plot everything but filter based on confidence also\n",
    "\n",
    "path2savePlots = mainPath + 'finalPlots/'\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "\n",
    "listOfRegTypes = ['rigid_keypointsForTooth_'] \n",
    "#, 'affine_keypointsForTooth_', , 'rigid_keypointsForTooth_', 'keypointsForTooth_'\n",
    "\n",
    "listOfLengthTypes = ['all_tt2ls_dict']\n",
    "#['all_tt2ls_dict', 'valid_tt2ls_dict','tt2_ref_ls', 'all_times_list', 'landmarks', 'all_ls2cl_dict', 'all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict','all_ls2bk_dict','all_ls2cl_dict','all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict', 'all_ls2bk_dict']\n",
    "\n",
    "\n",
    "minAllowedConfidence = 0.7  #1 to 5 for conf1 --- 0-1 for conf 2 and 3\n",
    "filterBasedOnConf = 2    # 1 for conf1 2 for conf2, 3 for logConf\n",
    "\n",
    "listOfReferences2PlotFor = ['WMDL_2018.09.11_06.21.57'] # ['WMDL_2019.02.27_10.03.11'] #['WMDL_2018.09.11_06.21.57'] #references2use for cable\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    \n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "\n",
    "        for regTypeKeyWord in listOfRegTypes:\n",
    "            for refKey in listOfReferences2PlotFor:\n",
    "                for infoKey in listOfLengthTypes:\n",
    "                    if not(regTypeKeyWord=='keypointsForTooth_' and infoKey=='valid_tt2ls_dict'):\n",
    "                        \n",
    "                        #filter based on Confidence\n",
    "                        selectedLengths = []\n",
    "                        selectedTimes = []\n",
    "                        selectedConfidence = []\n",
    "                        \n",
    "                        for i in range(len(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'])):\n",
    "                            if filterBasedOnConf == 1:\n",
    "                                if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['confidences'][i] >= minAllowedConfidence:\n",
    "\n",
    "                                    selectedLengths.append(\n",
    "                                        lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "                                    )\n",
    "                                    selectedTimes.append(\n",
    "                                        lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "                                    )\n",
    "                                    selectedConfidence.append(\n",
    "                                        lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['confidences'][i]\n",
    "                                    )\n",
    "                                    \n",
    "                            elif filterBasedOnConf == 2:\n",
    "                                if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['secondaryConfidences'][i] >= minAllowedConfidence:\n",
    "\n",
    "                                    selectedLengths.append(\n",
    "                                        lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "                                    )\n",
    "                                    selectedTimes.append(\n",
    "                                        lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "                                    )\n",
    "                                    selectedConfidence.append(\n",
    "                                        lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['secondaryConfidences'][i]\n",
    "                                    )\n",
    "                                    \n",
    "                                    \n",
    "                            elif filterBasedOnConf == 3:\n",
    "                                if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['logConfidence'][i] >= minAllowedConfidence:\n",
    "\n",
    "                                    selectedLengths.append(\n",
    "                                        lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "                                    )\n",
    "                                    selectedTimes.append(\n",
    "                                        lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "                                    )\n",
    "                                    selectedConfidence.append(\n",
    "                                        lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['logConfidence'][i]\n",
    "                                    )\n",
    "                                \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        plt.figure(figsize=(30,10))\n",
    "                        #plt.axis([0, 130, 10, 50])\n",
    "                        #plt.axis([0, 70, 30, 60])\n",
    "                        \n",
    "                        plt.axis([0, 250, 10, 50]) # for cable GT\n",
    "                        \n",
    "                        #plt.axis([0, 300, 50, 90])#for Hyd GT\n",
    "                        ax = plt.axes()\n",
    "                        ax.grid()\n",
    "\n",
    "                        plt.xlabel('Hours')\n",
    "                        plt.xlabel('Pixels')\n",
    "                        \n",
    "                        plotTitle = str(resKey + '__' + str(toothNbKey) + '__' + regTypeKeyWord + '__' + infoKey + '__'+ refKey)\n",
    "                        plt.title(plotTitle)\n",
    "                        \n",
    "                        plt.plot(selectedTimes, selectedLengths, label='nbOfPoints: ' + str(len(selectedLengths)))\n",
    "\n",
    "                        plt.plot(selectedTimes, selectedLengths,'o')\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        for i in range(len(selectedTimes)):\n",
    "                            ax.annotate( round(selectedConfidence[i], 1), (selectedTimes[i], selectedLengths[i]) )\n",
    "                            \n",
    "                            \n",
    "                        \n",
    "                        ax.legend()\n",
    "\n",
    "                        plt.savefig(path2savePlots + plotTitle + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Smoothing out lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# smooth using averaging within a sliding time window\n",
    "path2savePlots = mainPath + 'finalPlots_smooth/'\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "\n",
    "listOfRegTypes = ['rigid_keypointsForTooth_'] \n",
    "#, 'affine_keypointsForTooth_', , 'rigid_keypointsForTooth_', 'keypointsForTooth_'\n",
    "\n",
    "listOfLengthTypes = ['all_tt2ls_dict']\n",
    "#['all_tt2ls_dict', 'valid_tt2ls_dict','tt2_ref_ls', 'all_times_list', 'landmarks', 'all_ls2cl_dict', 'all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict','all_ls2bk_dict','all_ls2cl_dict','all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict', 'all_ls2bk_dict']\n",
    "\n",
    "listOfReferences2PlotFor = ['WMDL_2018.09.11_06.21.57'] # for cable GT ['WMDL_2018.09.11_06.21.57'] for hyd GT: 'WMDL_2019.02.27_10.03.11' #references2use[0] didnt work\n",
    "\n",
    "minAllowedConfidence = 1# used value of 1 for cable and for hydraulic. So we basically allow all confidences\n",
    "minAllowedConfidence2ndSmoothing = 4 # used value of 7 for cable. 4 for hydraulic. This is the number of points withing the time window\n",
    "\n",
    "timeWindowLength = 2\n",
    "\n",
    "verbose = False\n",
    "\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    \n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "\n",
    "        for regTypeKeyWord in listOfRegTypes:\n",
    "            for refKey in listOfReferences2PlotFor:\n",
    "                for infoKey in listOfLengthTypes:\n",
    "                    if not(regTypeKeyWord=='keypointsForTooth_' and infoKey=='valid_tt2ls_dict'):\n",
    "                        \n",
    "                        ########################################################################################\n",
    "                        #filter based on Confidence (# of detected landmarks)\n",
    "                        selectedTimes = []\n",
    "                        selectedLengths = []\n",
    "                        selectedConfidence = []\n",
    "                        \n",
    "                        for i in range(len(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'])):\n",
    "                            if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['confidences'][i] >= minAllowedConfidence:\n",
    "\n",
    "                                selectedTimes.append(\n",
    "                                    lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "                                )\n",
    "                            \n",
    "                                selectedLengths.append(\n",
    "                                    lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "                                )\n",
    "\n",
    "                                selectedConfidence.append(\n",
    "                                    lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['confidences'][i]\n",
    "                                )\n",
    "                        ########################################################################################\n",
    "                        \n",
    "                        \n",
    "                        ########################################################################################\n",
    "                        #smooth out the selected lengths\n",
    "                        smoothedTimes = []\n",
    "                        smoothedLengths = []\n",
    "                        smoothedConfidence = []\n",
    "                        \n",
    "                        timeRange_lowerBound = 0\n",
    "                        lastUpperBound = math.ceil( max(selectedTimes) )\n",
    "\n",
    "                        for timeRange_upperBound in range(timeWindowLength, lastUpperBound, timeWindowLength):\n",
    "\n",
    "                            timeIndices = [i for i,x in enumerate(selectedTimes) if (x >= timeRange_lowerBound and x < timeRange_upperBound)]\n",
    "                            \n",
    "                            if verbose:\n",
    "                                print('timeRange_lowerBound:'  + str(timeRange_lowerBound))\n",
    "                                print('timeRange_upperBound:'  + str(timeRange_upperBound))\n",
    "                                print('timeIndices:'  + str(timeIndices))\n",
    "                            \n",
    "                            \n",
    "                            if len(timeIndices) > 0:\n",
    "                                npIndices = np.array(timeIndices)\n",
    "                                npTimes = np.array(selectedTimes)\n",
    "                                npLengths = np.array(selectedLengths)\n",
    "                                \n",
    "                                smoothedTimes.append(npTimes[npIndices].mean())\n",
    "                                smoothedLengths.append(npLengths[npIndices].mean())\n",
    "                                smoothedConfidence.append(len(timeIndices))\n",
    "                                \n",
    "                                if verbose:\n",
    "                                    print('\\nmeantime')\n",
    "                                    print(npTimes[npIndices].mean())\n",
    "                                    print('\\nmeanLengths')\n",
    "                                    print(npLengths[npIndices].mean())\n",
    "                                    print('\\n')\n",
    "    \n",
    "\n",
    "                            timeRange_lowerBound = timeRange_upperBound\n",
    "                        ########################################################################################\n",
    "            \n",
    "                        plt.figure(figsize=(30,10))\n",
    "                        #plt.axis([0, 130, 10, 50])\n",
    "                        #plt.axis([0, 70, 30, 60])\n",
    "                        plt.axis([0, 250, 10, 50]) # used for sishen 1\n",
    "                        #plt.axis([0, 300, 50, 90])  # for hyd GT\n",
    "                        \n",
    "                        ax = plt.axes()\n",
    "                        ax.grid()\n",
    "\n",
    "                        plt.xlabel('Hours')\n",
    "                        plt.xlabel('Pixels')\n",
    "                        \n",
    "                        plotTitle = str(resKey + '__' + str(toothNbKey) + '__' + regTypeKeyWord + '__' + infoKey + '__'+ refKey + '__SMOOTHED')\n",
    "                        plt.title(plotTitle)\n",
    "                        \n",
    "                        plt.plot(smoothedTimes, smoothedLengths, label='nbOfPoints: ' + str(len(smoothedLengths)))\n",
    "\n",
    "                        plt.plot(smoothedTimes, smoothedLengths,'o')\n",
    "                        \n",
    "                        \n",
    "                        #add the confidence annotation\n",
    "                        for i in range(len(smoothedTimes)):\n",
    "                            ax.annotate( smoothedConfidence[i], (smoothedTimes[i], smoothedLengths[i]) )\n",
    "                            \n",
    "                            \n",
    "                        ax.legend()\n",
    "                        plt.savefig(path2savePlots + plotTitle + '.png')\n",
    "                        \n",
    "                        \n",
    "            \n",
    "            \n",
    "                        ########################################################################################\n",
    "                        #secondary smoothing based on Confidence2 (# of logs in timeWindow)\n",
    "                        smoothed2Times = []\n",
    "                        smoothed2Lengths = []\n",
    "                        smoothed2Confidence = []\n",
    "                        \n",
    "                        for i in range(len(smoothedTimes)):\n",
    "                            if smoothedConfidence[i] >= minAllowedConfidence2ndSmoothing:\n",
    "                                \n",
    "                                smoothed2Times.append(\n",
    "                                    smoothedTimes[i]\n",
    "                                )\n",
    "                                smoothed2Lengths.append(\n",
    "                                    smoothedLengths[i]\n",
    "                                )\n",
    "                                smoothed2Confidence.append(\n",
    "                                    smoothedConfidence[i]\n",
    "                                )\n",
    "                        ########################################################################################\n",
    "                        \n",
    "                        plt.figure(figsize=(30,10))\n",
    "                        #plt.axis([0, 130, 10, 50])\n",
    "                        #plt.axis([0, 70, 30, 60])\n",
    "                        plt.axis([0, 250, 10, 50]) # used for sishen 1\n",
    "                        #plt.axis([0, 300, 50, 90]) # for hyd GT\n",
    "                        \n",
    "                        ax = plt.axes()\n",
    "                        ax.grid()\n",
    "\n",
    "                        plt.xlabel('Hours')\n",
    "                        plt.xlabel('Pixels')\n",
    "                        \n",
    "                        plotTitle = str(resKey + '__' + str(toothNbKey) + '__' + regTypeKeyWord + '__' + infoKey + '__'+ refKey + '__SMOOTHED-2')\n",
    "                        plt.title(plotTitle)\n",
    "                        \n",
    "                        plt.plot(smoothed2Times, smoothed2Lengths, label='nbOfPoints: ' + str(len(smoothed2Lengths)))\n",
    "\n",
    "                        plt.plot(smoothed2Times, smoothed2Lengths,'o')\n",
    "                        \n",
    "                        \n",
    "                        #add the confidence annotation\n",
    "                        for i in range(len(smoothed2Times)):\n",
    "                            ax.annotate( smoothed2Confidence[i], (smoothed2Times[i], smoothed2Lengths[i]) )\n",
    "                            \n",
    "                            \n",
    "                        ax.legend()\n",
    "                        plt.savefig(path2savePlots + plotTitle + '.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Investigating different points on a length plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get frame name for a given points\n",
    "lengthValue = min(lengthsAndLandmarksDict['wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10']['rigid_keypointsForTooth_']['WMDL_2019.02.27_10.03.11']['tooth_1_info']['all_tt2ls_dict']['lengths'][140:200])\n",
    "\n",
    "indexInLengths = lengthsAndLandmarksDict['wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10']['rigid_keypointsForTooth_']['WMDL_2019.02.27_10.03.11']['tooth_1_info']['all_tt2ls_dict']['lengths'].index(lengthValue)\n",
    "\n",
    "timeOfLog = lengthsAndLandmarksDict['wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10']['rigid_keypointsForTooth_']['WMDL_2019.02.27_10.03.11']['tooth_1_info']['all_tt2ls_dict']['times'][indexInLengths]\n",
    "\n",
    "imageName = finalResultsDict['wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10'][timeOfLog]['fileName']\n",
    "\n",
    "print('lengthValue')\n",
    "print(lengthValue)\n",
    "print()\n",
    "print('indexInLengths')\n",
    "print(indexInLengths)\n",
    "print()\n",
    "print('timeOfLog')\n",
    "print(timeOfLog)\n",
    "print()\n",
    "print('imageName')\n",
    "print(imageName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looking at lengthsAndLandmarksDict keys:\n",
    "print('lengthsAndLandmarksDict.keys:')\n",
    "print(lengthsAndLandmarksDict.keys())\n",
    "print()\n",
    "key1 = list(lengthsAndLandmarksDict.keys())[0]\n",
    "print('lengthsAndLandmarksDict[key1].keys:')\n",
    "print(lengthsAndLandmarksDict[key1].keys())\n",
    "print()\n",
    "\n",
    "\n",
    "print('lengthsAndLandmarksDict[key1][rigid_keypointsForTooth_].keys:')\n",
    "print(lengthsAndLandmarksDict[key1]['rigid_keypointsForTooth_'].keys())\n",
    "key2 = list(lengthsAndLandmarksDict[key1]['rigid_keypointsForTooth_'].keys())[0]\n",
    "print()\n",
    "\n",
    "print('lengthsAndLandmarksDict[key1][rigid_keypointsForTooth_][key2].keys:')\n",
    "print(lengthsAndLandmarksDict[key1]['rigid_keypointsForTooth_'][key2].keys())\n",
    "print()\n",
    "\n",
    "print('lengthsAndLandmarksDict[key1][rigid_keypointsForTooth_][key2][tooth_1_info].keys:')\n",
    "print(lengthsAndLandmarksDict[key1]['rigid_keypointsForTooth_'][key2]['tooth_1_info'].keys())\n",
    "print()\n",
    "\n",
    "print('lengthsAndLandmarksDict[key1][rigid_keypointsForTooth_][key2][tooth_1_info][all_tt2ls_dict].keys:')\n",
    "print(lengthsAndLandmarksDict[key1]['rigid_keypointsForTooth_'][key2]['tooth_1_info']['all_tt2ls_dict'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#get frame time from its name\n",
    "getFrameTime(paresedResultsDict,'wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10',\"/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10/groundTruthVisualization/WMDL_2019.02.28_13.06.37\")\n",
    "\n",
    "getFrameTime(cleanedUpResultsDict,'wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10','/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_aitik_Komatsu_SH1142_PC5500_2019-02-26_to_2019-03-10/groundTruthLabels/WMDL_2019.02.28_00.02.59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#checking confidence values\n",
    "print(cleanedUpResultsDict['PH01_2800'][0]['confidences']['tooth_1'])\n",
    "print(cleanedUpResultsDict['PH01_2800'][0]['logConfidence'])\n",
    "print(cleanedUpResultsDict['PH01_2800'][0]['secondaryConfidences']['tooth_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Making Predictions using Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Method Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def solve1stOrder(yVal, poly1d):\n",
    "    return (yVal - poly1d[0]) / poly1d[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Configs for fitting trajectory curves\n",
    "minAllowedConfidence = 0.7  #1 to 5 for conf1 --- 0-1 for conf 2 and 3\n",
    "filterBasedOnConf = 2    # 1 for conf1 2 for conf2, 3 for logConf\n",
    "degreeOfPolyn = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# getting the arrays for trajectory fitting\n",
    "resKey = list(lengthsAndLandmarksDict.keys())[0]\n",
    "\n",
    "i = 0\n",
    "toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "\n",
    "regTypeKeyWord = 'rigid_keypointsForTooth_'\n",
    "refKey = 'WMDL_2018.09.11_06.21.57'\n",
    "infoKey = 'all_tt2ls_dict'\n",
    "\n",
    "\n",
    "#filter based on Confidence\n",
    "selectedLengths_forTraj = []\n",
    "selectedTimes_forTraj = []\n",
    "selectedConfidence_forTraj = []\n",
    "\n",
    "for i in range(len(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'])):\n",
    "    if filterBasedOnConf == 1:\n",
    "        if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['confidences'][i] >= minAllowedConfidence:\n",
    "\n",
    "            selectedLengths_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "            )\n",
    "            selectedTimes_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "            )\n",
    "            selectedConfidence_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['confidences'][i]\n",
    "            )\n",
    "\n",
    "    elif filterBasedOnConf == 2:\n",
    "        if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['secondaryConfidences'][i] >= minAllowedConfidence:\n",
    "\n",
    "            selectedLengths_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "            )\n",
    "            selectedTimes_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "            )\n",
    "            selectedConfidence_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['secondaryConfidences'][i]\n",
    "            )\n",
    "\n",
    "\n",
    "    elif filterBasedOnConf == 3:\n",
    "        if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['logConfidence'][i] >= minAllowedConfidence:\n",
    "\n",
    "            selectedLengths_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "            )\n",
    "            selectedTimes_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "            )\n",
    "            selectedConfidence_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['logConfidence'][i]\n",
    "            )\n",
    "\n",
    "            \n",
    "print('len selectedLengths_forTraj:  ' + str(len(selectedLengths_forTraj)))\n",
    "print()\n",
    "print('len selectedTimes_forTraj:  ' + str(len(selectedTimes_forTraj)))\n",
    "print()\n",
    "print('len selectedConfidence_forTraj:  ' + str(len(selectedConfidence_forTraj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# finding time index where the tooth change happens\n",
    "toothChangeLengthTresh = 10\n",
    "last_smTooth_index = len(selectedLengths_forTraj)\n",
    "last_smTooth_length = 0\n",
    "first_bgTooth_index = 0\n",
    "first_bgTooth_length = 0\n",
    "\n",
    "prevLen = selectedLengths_forTraj[0]\n",
    "for curInd in range(1, 4):\n",
    "    curLen = selectedLengths_forTraj[curInd]\n",
    "    \n",
    "    '''\n",
    "    print('curInd: ' + str(curInd))\n",
    "    print('prevLen: ' + str(prevLen))\n",
    "    print('curLen: ' + str(curLen))\n",
    "    print('curLen: ' + str((curLen - prevLen)))\n",
    "    print()\n",
    "    '''\n",
    "    \n",
    "    if (curLen - prevLen) > toothChangeLengthTresh:\n",
    "        last_smTooth_index = curInd - 1\n",
    "        first_bgTooth_index = curInd\n",
    "        last_smTooth_length = prevLen\n",
    "        first_bgTooth_length = curLen\n",
    "        break\n",
    "        \n",
    "    prevLen = curLen\n",
    "        \n",
    "print('last_smTooth_index:  ' + str(last_smTooth_index))\n",
    "print('last_smTooth_length:  ' + str(last_smTooth_length))\n",
    "print('first_bgTooth_index:  ' + str(first_bgTooth_index))\n",
    "print('first_bgTooth_length:  ' + str(first_bgTooth_length))\n",
    "print('difference:  ' + str(first_bgTooth_length - last_smTooth_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit to before tooth change segment\n",
    "x = np.ndarray(shape=(1,))\n",
    "y = np.ndarray(shape=(1,))\n",
    "\n",
    "for pInd in range(last_smTooth_index):\n",
    "    x = np.vstack([x, selectedTimes_forTraj[pInd]])\n",
    "    y = np.vstack([y, selectedLengths_forTraj[pInd]])\n",
    "\n",
    "x = x[1:,]\n",
    "y = y[1:,]\n",
    "x = x.reshape(-1)\n",
    "y = y.reshape(-1)\n",
    "\n",
    "z = np.polyfit(x, y, degreeOfPolyn)\n",
    "estimatedFunction_beforeToothChange = np.poly1d(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit to after tooth change segment\n",
    "x = np.ndarray(shape=(1,))\n",
    "y = np.ndarray(shape=(1,))\n",
    "\n",
    "for pInd in range(first_bgTooth_index, len(selectedLengths_forTraj), 1):\n",
    "    x = np.vstack([x, selectedTimes_forTraj[pInd]])\n",
    "    y = np.vstack([y, selectedLengths_forTraj[pInd]])\n",
    "\n",
    "x = x[1:,]\n",
    "y = y[1:,]\n",
    "x = x.reshape(-1)\n",
    "y = y.reshape(-1)\n",
    "\n",
    "z = np.polyfit(x, y, degreeOfPolyn)\n",
    "estimatedFunction_afterToothChange = np.poly1d(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plotting the fittend lines\n",
    "pts_beforeToothChange = [estimatedFunction_beforeToothChange(time) for time in selectedTimes_forTraj[:last_smTooth_index]]\n",
    "\n",
    "pts_afterToothChange = [estimatedFunction_afterToothChange(time) for time in selectedTimes_forTraj[first_bgTooth_index:]]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.axis([0, 250, 10, 50])\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "\n",
    "plt.xlabel('Hours')\n",
    "plt.xlabel('Pixels')\n",
    "\n",
    "\n",
    "plt.plot(selectedTimes_forTraj, selectedLengths_forTraj)\n",
    "plt.plot(selectedTimes_forTraj, selectedLengths_forTraj,'o')\n",
    "\n",
    "plt.plot(selectedTimes_forTraj[:last_smTooth_index], pts_beforeToothChange)\n",
    "plt.plot(selectedTimes_forTraj[first_bgTooth_index:], pts_afterToothChange)\n",
    "\n",
    "plt.savefig(mainPath + 'finalPlots/fitted.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Image 2 Image Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Method Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def displayXmlPointsOnImage(img, xmlRoot):\n",
    "    img_name = xmlRoot.find('img_name').text[:-5]\n",
    "    toothTips = xmlRoot.find('toothTip')\n",
    "    lipShrouds = xmlRoot.find('lipShroud')\n",
    "    liftingEyes = xmlRoot.find('liftingEye')\n",
    "    castLips = xmlRoot.find('castLip')\n",
    "    bucketLandmarks = xmlRoot.find('bucketLandmark')\n",
    "    \n",
    "    displayPointOnImage(img, toothTips, 1)\n",
    "    displayPointOnImage(img, lipShrouds, 2)\n",
    "    displayPointOnImage(img, liftingEyes, 3)\n",
    "    displayPointOnImage(img, castLips, 4)\n",
    "    displayPointOnImage(img, bucketLandmarks, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def displayPointOnImage(img, points, lmNb):\n",
    "    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255)]\n",
    "    height, width, dim=img.shape\n",
    "    \n",
    "    for point in points:\n",
    "        xcor = int(float(point.get('x')) * width)\n",
    "        ycor = int(float(point.get('y') )* height)\n",
    "        \n",
    "        cv2.circle(img, (xcor, ycor), 5, colors[lmNb-1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def displayPointsSetOnImage(img, points, color=0):\n",
    "    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255)]\n",
    "    for point in points[0]:\n",
    "        xcor = point[0]\n",
    "        ycor = point[1]\n",
    "        \n",
    "        cv2.circle(img, (xcor, ycor), 5, colors[color], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getPointsSet(img, xmlRoot, totalNbOfLandmarks, includeTT):\n",
    "    counter = 0\n",
    "\n",
    "    points = np.zeros((1, totalNbOfLandmarks, 2), np.int32)\n",
    "  \n",
    "    \n",
    "    height, width, dim=img.shape\n",
    "    \n",
    "    \n",
    "    lipShrouds = xmlRoot.find('lipShroud')\n",
    "    liftingEyes = xmlRoot.find('liftingEye')\n",
    "    castLips = xmlRoot.find('castLip')\n",
    "    bucketLandmarks = xmlRoot.find('bucketLandmark')\n",
    "    \n",
    "    if includeTT:\n",
    "        toothTips = xmlRoot.find('toothTip')\n",
    "\n",
    "        for pp in toothTips:\n",
    "            xcor = int(float(pp.get('x')) * width)\n",
    "            ycor = int(float(pp.get('y') )* height)\n",
    "            points[0, counter, 0] = xcor\n",
    "            points[0, counter, 1] = ycor\n",
    "            counter+=1\n",
    "        \n",
    "    \n",
    "    for pp in lipShrouds:\n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "    for pp in liftingEyes:\n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "    for pp in castLips:\n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "    for pp in bucketLandmarks:\n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getPointsArray():\n",
    "    srcAr = []\n",
    "    trgAr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getPointsSetMiddleTeeth(img, xmlRoot):\n",
    "    points = np.zeros((1, 20, 2), np.int32)\n",
    "    counter = 0\n",
    "    \n",
    "    height, width, dim=img.shape\n",
    "    \n",
    "    toothTips = xmlRoot.find('toothTip')\n",
    "    lipShrouds = xmlRoot.find('lipShroud')\n",
    "    liftingEyes = xmlRoot.find('liftingEye')\n",
    "    castLips = xmlRoot.find('castLip')\n",
    "    bucketLandmarks = xmlRoot.find('bucketLandmark')\n",
    "    \n",
    "    for i in range(len(toothTips)-2):\n",
    "        pp = toothTips[i+1] \n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "    for i in range(len(lipShrouds)-2):\n",
    "        pp = lipShrouds[i+1] \n",
    "\n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "        \n",
    "\n",
    "    for i in range(len(liftingEyes)-2):\n",
    "        pp = liftingEyes[i+1] \n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "    for i in range(len(castLips)-2):\n",
    "        pp = castLips[i+1] \n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "    for i in range(len(bucketLandmarks)-2):\n",
    "        pp = bucketLandmarks[i+1] \n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getPointsSetSpecific(img, xmlRoot, keyword):\n",
    "    height, width, dim=img.shape\n",
    "    \n",
    "    landmarks = xmlRoot.find(keyword)\n",
    "    points = np.zeros((1, len(landmarks), 2), np.int32)\n",
    "    counter = 0\n",
    "    \n",
    "    for pp in landmarks:\n",
    "        xcor = int(float(pp.get('x')) * width)\n",
    "        ycor = int(float(pp.get('y') )* height)\n",
    "        points[0, counter, 0] = xcor\n",
    "        points[0, counter, 1] = ycor\n",
    "        counter+=1\n",
    "  \n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Registering 2 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Peform FULL image2image registeration on tw o reference frames \n",
    "\n",
    "imagesPathDir = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_Pinto/referenceFrames/images/'\n",
    "labelsPathDir = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_Pinto/referenceFrames/labels/'\n",
    "\n",
    "file1 = '1_20161116-074000_0001n0_9767'\n",
    "file2 = '1_20161116-152500_0001n0_783'\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "img2 = cv2.imread(imagesPathDir + file2 + '.png')\n",
    "\n",
    "root1 = ET.parse(labelsPathDir + file1 + '_landmarkCoords.xml').getroot()\n",
    "root2 = ET.parse(labelsPathDir + file2 + '_landmarkCoords.xml').getroot()\n",
    "\n",
    "# Display loaded points on images \n",
    "displayXmlPointsOnImage(img1, root1)\n",
    "displayXmlPointsOnImage(img2, root2)\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "plt.imshow(img2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "landmarksSet1 = getPointsSet(img1, root1)\n",
    "landmarksSet2 = getPointsSet(img2, root2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display loaded landmarks on images \n",
    "print('landmarksSet1')\n",
    "print(landmarksSet1[0,1:3,:])\n",
    "print('landmarksSet2')\n",
    "print(landmarksSet2[0,1:3,:])\n",
    "\n",
    "displayPointsSetOnImage(img1, landmarksSet1)\n",
    "displayPointsSetOnImage(img2, landmarksSet2)\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "plt.imshow(img2)\n",
    "plt.show()\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "img2 = cv2.imread(imagesPathDir + file2 + '.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Learn different transformations\n",
    "transformationRegid5D = cv2.estimateRigidTransform(landmarksSet2, landmarksSet1, False)\n",
    "transformationRegid6D = cv2.estimateRigidTransform(landmarksSet2, landmarksSet1, True)\n",
    "transformationHomo, mask = cv2.findHomography(landmarksSet2, landmarksSet1, cv2.RANSAC)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# warp image using learned transformation\n",
    "\n",
    "transImageRegid5D = cv2.warpAffine(img2, transformationRegid5D,(720, 480))\n",
    "transImageRegid6D = cv2.warpAffine(img2, transformationRegid6D,(720, 480))\n",
    "transImageHomo = cv2.warpPerspective(img2, transformationHomo, (720, 480))\n",
    "\n",
    "plt.imshow(transImageRegid5D)\n",
    "plt.title('transImageRegid5D')\n",
    "plt.show()\n",
    "plt.imshow(transImageRegid6D)\n",
    "plt.title('transImageRegid6D')\n",
    "plt.show()\n",
    "plt.imshow(transImageHomo)\n",
    "plt.title('transImageHomo')\n",
    "plt.show()\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "img2 = cv2.imread(imagesPathDir + file2 + '.png')\n",
    "\n",
    "\n",
    "\n",
    "# Transform the landmark points using learned transformation\n",
    "transLandmarksRegid5D = cv2.transform(landmarksSet2, transformationRegid5D)\n",
    "transLandmarksRegid6D = cv2.transform(landmarksSet2, transformationRegid6D)\n",
    "transLandmarksHomo = cv2.transform(landmarksSet2, transformationHomo)\n",
    "\n",
    "displayPointsSetOnImage(img1, landmarksSet1, 0)\n",
    "displayPointsSetOnImage(img1, transLandmarksRegid5D, 1)\n",
    "displayPointsSetOnImage(img1, transLandmarksRegid6D, 2)\n",
    "\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Comparing tooth lengths\n",
    "print('\\nComparing tooth lengths\\n')\n",
    "print('src:')\n",
    "print(landmarksSet1[0, 9, 1] - landmarksSet1[0, 3, 1])\n",
    "print('\\nTarget:')\n",
    "print(landmarksSet2[0, 9, 1] - landmarksSet2[0, 3, 1])\n",
    "print('\\nRegid5D:')\n",
    "print(transLandmarksRegid5D[0, 9, 1] - transLandmarksRegid5D[0, 3, 1])\n",
    "print('\\nRegid6D:')\n",
    "print(transLandmarksRegid6D[0, 9, 1] - transLandmarksRegid6D[0, 3, 1])\n",
    "print('\\nPerspective:')\n",
    "print(transLandmarksHomo[0, 9, 1] - transLandmarksHomo[0, 3, 1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# comparing registeration errors\n",
    "print('\\ncomparing registeration errors\\n')\n",
    "print('\\nRegid5D:')\n",
    "print(getRegError(transLandmarksRegid5D, landmarksSet1))\n",
    "print('\\nRegid6D:')\n",
    "print(getRegError(transLandmarksRegid6D, landmarksSet1))\n",
    "print('\\nPerspective:')\n",
    "print(getRegError(transLandmarksHomo, landmarksSet1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Performing FULL row by row registeration between two reference frames\n",
    "\n",
    "imagesPathDir = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_Pinto/referenceFrames/images/'\n",
    "labelsPathDir = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_Pinto/referenceFrames/labels/'\n",
    "\n",
    "file1 = '1_20161116-074000_0001n0_9767'\n",
    "file2 = '1_20161116-152500_0001n0_783'\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "img2 = cv2.imread(imagesPathDir + file2 + '.png')\n",
    "\n",
    "root1 = ET.parse(labelsPathDir + file1 + '_landmarkCoords.xml').getroot()\n",
    "root2 = ET.parse(labelsPathDir + file2 + '_landmarkCoords.xml').getroot()\n",
    "\n",
    "for keyWord in ['toothTip', 'lipShroud', 'liftingEye', 'castLip', 'bucketLandmark']:\n",
    "    print('\\n\\n' + keyWord)\n",
    "    img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "    pointsSet1 = getPointsSetSpecific(img1, root1, keyWord)\n",
    "    pointsSet2 = getPointsSetSpecific(img2, root2, keyWord)\n",
    "\n",
    "    transFormation5D = cv2.estimateRigidTransform(pointsSet2, pointsSet1, False)\n",
    "    transFormation6D = cv2.estimateRigidTransform(pointsSet2, pointsSet1, True)\n",
    "\n",
    "    transFormedPoints5D = cv2.transform(pointsSet2, transFormation5D)\n",
    "    transFormedPoints6D = cv2.transform(pointsSet2, transFormation6D)\n",
    "\n",
    "\n",
    "    displayPointsSetOnImage(img1, pointsSet1, 0)\n",
    "    displayPointsSetOnImage(img1, transFormedPoints5D, 1)\n",
    "    displayPointsSetOnImage(img1, transFormedPoints6D, 2)\n",
    "\n",
    "    plt.imshow(img1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # comparing registeration errors\n",
    "    print('\\nRegid5D:')\n",
    "    print(getRegError(transFormedPoints5D, pointsSet1))\n",
    "    print('\\nRegid6D:')\n",
    "    print(getRegError(transFormedPoints6D, pointsSet1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# lean the transformations from other landmarks then move TTs (for two reference images)\n",
    "\n",
    "imagesPathDir = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_Sishen_cable/PH01_2800/referenceFrames/images/'\n",
    "labelsPathDir = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_Sishen_cable/PH01_2800/referenceFrames/labels/'\n",
    "\n",
    "file1 = 'WMDL_2018.09.11_06.43.19'\n",
    "file2 = 'WMDL_2018.09.11_06.21.57'\n",
    "\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "img2 = cv2.imread(imagesPathDir + file2 + '.png')\n",
    "\n",
    "root1 = ET.parse(labelsPathDir + file1 + '_landmarkCoords.xml').getroot()\n",
    "root2 = ET.parse(labelsPathDir + file2 + '_landmarkCoords.xml').getroot()\n",
    "\n",
    "\n",
    "landmarksSet1 = getPointsSet(img1, root1, 32, False)\n",
    "landmarksSet2 = getPointsSet(img2, root2, 32, False)\n",
    "\n",
    "\n",
    "\n",
    "# Learn different transformations\n",
    "transformationRegid5D = cv2.estimateRigidTransform(landmarksSet2, landmarksSet1, False)\n",
    "transformationRegid6D = cv2.estimateRigidTransform(landmarksSet2, landmarksSet1, True)\n",
    "transformationHomo, mask = cv2.findHomography(landmarksSet2, landmarksSet1, cv2.RANSAC)\n",
    "\n",
    "\n",
    "\n",
    "displayPointsSetOnImage(img1, landmarksSet1)\n",
    "displayPointsSetOnImage(img2, landmarksSet2)\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "plt.imshow(img2)\n",
    "plt.show()\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "img2 = cv2.imread(imagesPathDir + file2 + '.png')\n",
    "\n",
    "\n",
    "\n",
    "# Transform the landmark points using learned transformation. Lower one TT artificially\n",
    "root2 = ET.parse(labelsPathDir + file2 + '_landmarkCoords.xml').getroot()\n",
    "\n",
    "landmarksSet2Move = getPointsSet(img2, root2, 40, True)\n",
    "landmarksSet2Move[0][1] += 15  #Lower one TT artificially\n",
    "\n",
    "\n",
    "transLandmarksRegid5D = cv2.transform(landmarksSet2Move, transformationRegid5D)\n",
    "transLandmarksRegid6D = cv2.transform(landmarksSet2Move, transformationRegid6D)\n",
    "transLandmarksHomo = cv2.transform(landmarksSet2Move, transformationHomo)\n",
    "\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "\n",
    "displayPointsSetOnImage(img1, transLandmarksRegid5D, 1)\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.title('movedWithRegid')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "\n",
    "displayPointsSetOnImage(img1, transLandmarksRegid6D, 2)\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.title('movedWithAffine')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use 1 row to learn transformation then transform the TT with it\n",
    "\n",
    "imagesPathDir = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_Sishen_cable/PH01_2800/referenceFrames/images/'\n",
    "labelsPathDir = '/media/hooman/961293e3-04a5-40c5-afc0-2b205d0a7067/WM_PROJECT/algorithmDev/wmAlgo_usingWearLandmarsk_optical_hydraulics/try1/wmdlLogs_Sishen_cable/PH01_2800/referenceFrames/labels/'\n",
    "\n",
    "file1 = 'WMDL_2018.09.11_06.43.19'\n",
    "file2 = 'WMDL_2018.09.11_06.21.57'\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "img2 = cv2.imread(imagesPathDir + file2 + '.png')\n",
    "\n",
    "root1 = ET.parse(labelsPathDir + file1 + '_landmarkCoords.xml').getroot()\n",
    "root2 = ET.parse(labelsPathDir + file2 + '_landmarkCoords.xml').getroot()\n",
    "\n",
    "\n",
    "\n",
    "keyWord = 'lipShroud'\n",
    "\n",
    "pointsSet1 = getPointsSetSpecific(img1, root1, keyWord)\n",
    "pointsSet2 = getPointsSetSpecific(img2, root2, keyWord)\n",
    "\n",
    "displayPointsSetOnImage(img2, pointsSet2, 0)\n",
    "plt.imshow(img2)\n",
    "plt.title('srcPoints')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "transFormation5D = cv2.estimateRigidTransform(pointsSet2, pointsSet1, False)\n",
    "transFormation6D = cv2.estimateRigidTransform(pointsSet2, pointsSet1, True)\n",
    "\n",
    "\n",
    "displayPointsSetOnImage(img1, pointsSet1, 0)\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "displayPointsSetOnImage(img1, pointsSet1, 0)\n",
    "displayPointsSetOnImage(img1, pointsSet2, 1)\n",
    "plt.imshow(img1)\n",
    "plt.title('red=src, grn=trg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "keyWord = 'toothTip'\n",
    "pointsSet2 = getPointsSetSpecific(img2, root2, keyWord)\n",
    "\n",
    "pointsSet2[0][1] += 15 \n",
    "\n",
    "\n",
    "transFormedPoints5D = cv2.transform(pointsSet2, transFormation5D)\n",
    "transFormedPoints6D = cv2.transform(pointsSet2, transFormation6D)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nnow transforming TTs\\n\")\n",
    "\n",
    "img2 = cv2.imread(imagesPathDir + file2 + '.png')\n",
    "displayPointsSetOnImage(img2, pointsSet2, 0)\n",
    "plt.imshow(img2)\n",
    "plt.title('srcPoints')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "displayPointsSetOnImage(img1, transFormedPoints5D, 1)\n",
    "plt.imshow(img1)\n",
    "plt.title('registered 5d')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "img1 = cv2.imread(imagesPathDir + file1 + '.png')\n",
    "displayPointsSetOnImage(img1, transFormedPoints6D, 1)\n",
    "plt.imshow(img1)\n",
    "plt.title('registered 6d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (**Use this for debugging**) Registering a test frame to a Refrenece frame\n",
    "path2RefImage = mainPath + 'referenceFrames/images/WMDL_2019.02.27_10.03.11.png'\n",
    "path2Reflabel = mainPath + 'referenceFrames/labels/WMDL_2019.02.27_10.03.11_landmarkCoords.xml'\n",
    "timeOfTheLog2Test = 53.62861111111111#49.79888888888889 #53.62861111111111\n",
    "\n",
    "rawFramesDir = mainPath + 'Frame/'\n",
    "\n",
    "\n",
    "resKey = mainPath.split('/')[-2]\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "numberOfLandmarks = numberOflandmarksIncludingToothTip\n",
    "time = timeOfTheLog2Test\n",
    "refkeyPointsDic = getRefDict(path2Reflabel, path2RefImage)\n",
    "\n",
    "#visualizeRefDict(refkeyPointsDic, path2RefImage)\n",
    "\n",
    "\n",
    "fileName = finalResultsDict[resKey][time]['fileName'].split('/')[-1]\n",
    "inImage = cv2.imread(rawFramesDir + fileName)\n",
    "refImage = cv2.imread(path2RefImage)\n",
    "\n",
    "\n",
    "outImage =  draw_all_keypoints_boxes_andCurves(\n",
    "    inImage,\n",
    "    finalResultsDict[resKey][time],\n",
    "    numberOfTeeth=numberOfTeeth,\n",
    "    regTypeKeyword='',\n",
    "    drawOnlyValidated=True,\n",
    "    doNotDrawBoxes=True\n",
    ")\n",
    "\n",
    "plt.imshow(outImage)\n",
    "plt.title('validatedPoints_testFrame')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "resDicForFrame = finalResultsDict[resKey][time]\n",
    "\n",
    "\n",
    "\n",
    "############################# Getting the matched landmarks######################################################\n",
    "srcAr = []\n",
    "trgAr = []\n",
    "\n",
    "landmakrsList = ['toothTip_', 'lipShroud_', 'liftingEye_', 'castLip_', 'bucketLandmark_']\n",
    "for i in range(numberOfLandmarks):\n",
    "    keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "    \n",
    "    if keypointsKey in resDicForFrame:\n",
    "        keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "        for j in range(numberOfTeeth):\n",
    "            if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                \n",
    "                if i > 0: #do not use toothtip landmarks in calculating transfromation\n",
    "                    \n",
    "                    #if i == 1: # only use lipShroud\n",
    "                    srcAr.append(keyPoints[j])\n",
    "                    trgAr.append(refkeyPointsDic[landmakrsList[i] + str(j+1)])                   \n",
    "\n",
    "srcPoints = getRegPointSetFromArray(srcAr)\n",
    "trgPoints = getRegPointSetFromArray(trgAr)\n",
    "\n",
    "\n",
    "\n",
    "# Display src landmarks on images \n",
    "displayPointsSetOnImage(inImage, srcPoints)\n",
    "\n",
    "plt.imshow(inImage)\n",
    "plt.title('matched points refImage')\n",
    "plt.show()\n",
    "\n",
    "# reset the inImage\n",
    "inImage = cv2.imread(rawFramesDir + fileName)\n",
    "\n",
    "\n",
    "# Display trget landmarks on images \n",
    "displayPointsSetOnImage(refImage, trgPoints)\n",
    "\n",
    "plt.imshow(refImage)\n",
    "plt.title('matched points refImage')\n",
    "plt.show()\n",
    "#################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transformationRegid = cv2.estimateRigidTransform(srcPoints, trgPoints, False)\n",
    "transformationAffine= cv2.estimateRigidTransform(srcPoints, trgPoints, True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "points2moveAr = []\n",
    "indexToKeyMap = []\n",
    "\n",
    "\n",
    "for i in range(numberOfLandmarks):\n",
    "    keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "    \n",
    "    if keypointsKey in resDicForFrame:\n",
    "        keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "        for j in range(numberOfTeeth):\n",
    "            if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                indexToKeyMap.append({'landmarkNb': i, 'toothNb':j})\n",
    "                points2moveAr.append(keyPoints[j])\n",
    "\n",
    "                \n",
    "points2move = getRegPointSetFromArray(points2moveAr)\n",
    "\n",
    "#*************   lower this landmark to simulate a missing tooth\n",
    "#points2move[0][1] += 20  \n",
    "\n",
    "###################################### Transforming the points ##################################################\n",
    "transformedPointsRegid = cv2.transform(points2move, transformationRegid)\n",
    "transformedPointsAffine = cv2.transform(points2move, transformationAffine)\n",
    "\n",
    "# Display loaded landmarks on images \n",
    "refImage = cv2.imread(path2RefImage)\n",
    "displayPointsSetOnImage(refImage, transformedPointsRegid)\n",
    "\n",
    "plt.imshow(refImage)\n",
    "plt.title('transformedPointsRegid_refImage')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "refImage = cv2.imread(path2RefImage)\n",
    "displayPointsSetOnImage(refImage, transformedPointsAffine)\n",
    "  \n",
    "plt.imshow(refImage)\n",
    "plt.title('transformedPointsAffine_refImage')\n",
    "plt.show()\n",
    "#################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################3########### warping the images #######################################################\n",
    "transImageRegid5D = cv2.warpAffine(inImage, transformationRegid,(720, 480))\n",
    "transImageRegid6D = cv2.warpAffine(inImage, transformationAffine,(720, 480))\n",
    "\n",
    "plt.imshow(transImageRegid5D)\n",
    "plt.title('warpedImageRegid5D')\n",
    "plt.show()\n",
    "plt.imshow(transImageRegid6D)\n",
    "plt.title('warpedImageRegid6D')\n",
    "plt.show()\n",
    "#################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# comparing registeration errors\n",
    "print('\\n\\ncomparing registeration errors')\n",
    "print('\\nRegid5D:')\n",
    "print(getRegError(transformedPointsRegid, srcPoints))\n",
    "print('\\nRegid Affine:')\n",
    "print(getRegError(transformedPointsAffine, srcPoints))\n",
    "\n",
    "'''\n",
    "# Comparing tooth lengths\n",
    "print('\\nComparing tooth lengths\\n')\n",
    "print('src:')\n",
    "print(srcPoints[0, 9, 1] - srcPoints[0, 3, 1])\n",
    "print('\\nTarget:')\n",
    "print(trgPoints[0, 9, 1] - trgPoints[0, 3, 1])\n",
    "print('\\nRegid5D:')\n",
    "print(transformedPointsRegid[0, 9, 1] - transformedPointsRegid[0, 3, 1])\n",
    "print('\\nRegid6D:')\n",
    "print(transformedPointsAffine[0, 9, 1] - transformedPointsAffine[0, 3, 1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#DEBUGGING CODE FOR getRegisteredPointsV2\n",
    "\n",
    "timeOfTheLog2Test = 53.62861111111111#49.79888888888889 #53.62861111111111\n",
    "refKey = 'WMDL_2019.02.27_10.03.11'\n",
    "\n",
    "path2RefImage = mainPath + 'referenceFrames/images/' + refKey + '.png'\n",
    "path2Reflabel = mainPath + 'referenceFrames/labels/' + refKey + '_landmarkCoords.xml'\n",
    "refkeyPointsDic = getRefDict(path2Reflabel, path2RefImage)\n",
    "\n",
    "rawFramesDir = mainPath + 'Frame/'\n",
    "resKey = mainPath.split('/')[-2]\n",
    "\n",
    "resultsArRigid, regError = getRegisteredPointsV2(\n",
    "    refkeyPointsDic,\n",
    "    finalResultsDict[resKey][time],\n",
    "    numberOfTeeth\n",
    ")\n",
    "\n",
    "print(regError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# results generator script\n",
    "\n",
    "# Transform the landmark points using learned transformation\n",
    "transLandmarksRegid5D = cv2.transform(landmarksSet2, transformationRegid5D)\n",
    "transLandmarksRegid6D = cv2.transform(landmarksSet2, transformationRegid6D)\n",
    "transLandmarksHomo = cv2.transform(landmarksSet2, transformationHomo)\n",
    "\n",
    "displayPointsSetOnImage(img1, landmarksSet1, 0)\n",
    "displayPointsSetOnImage(img1, transLandmarksRegid5D, 1)\n",
    "displayPointsSetOnImage(img1, transLandmarksRegid6D, 2)\n",
    "\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "\n",
    "# Comparing tooth lengths\n",
    "print('src:')\n",
    "print(landmarksSet1[0, 9, 1] - landmarksSet1[0, 3, 1])\n",
    "print('\\nTarget:')\n",
    "print(landmarksSet2[0, 9, 1] - landmarksSet2[0, 3, 1])\n",
    "print('\\nRegid5D:')\n",
    "print(transLandmarksRegid5D[0, 9, 1] - transLandmarksRegid5D[0, 3, 1])\n",
    "print('\\nRegid6D:')\n",
    "print(transLandmarksRegid6D[0, 9, 1] - transLandmarksRegid6D[0, 3, 1])\n",
    "print('\\nPerspective:')\n",
    "print(transLandmarksHomo[0, 9, 1] - transLandmarksHomo[0, 3, 1])\n",
    "\n",
    "\n",
    "print('\\n\\nerrors:')\n",
    "\n",
    "# comparing registeration errors\n",
    "print('\\nRegid5D:')\n",
    "print(getRegError(transLandmarksRegid5D, landmarksSet1))\n",
    "print('\\nRegid6D:')\n",
    "print(getRegError(transLandmarksRegid6D, landmarksSet1))\n",
    "print('\\nPerspective:')\n",
    "print(getRegError(transLandmarksHomo, landmarksSet1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## For presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the stats of the total number of each landmark we detect in this set\n",
    "\n",
    "resKey = list(lengthsAndLandmarksDict.keys())[0]\n",
    "\n",
    "landmarksCountDic = {}\n",
    "for i in range(NUMBER_OF_TEETH):\n",
    "    ttCount = 0\n",
    "    lsCount = 0\n",
    "    leCount = 0\n",
    "    clCount = 0\n",
    "    bkCount = 0\n",
    "    \n",
    "    for time in sorted(paresedResultsDict[resKey].keys()):\n",
    "        if 'keypointsForTooth_' + str(i+1) in paresedResultsDict[resKey][time].keys():\n",
    "            keyPoints = paresedResultsDict[resKey][time]['keypointsForTooth_' + str(i+1)]\n",
    "\n",
    "            if keyPoints[0][0] > 1 and  keyPoints[0][1] > 1:\n",
    "                ttCount += 1\n",
    "\n",
    "            if keyPoints[1][0] > 1 and  keyPoints[1][1] > 1:\n",
    "                lsCount += 1\n",
    "\n",
    "            if keyPoints[2][0] > 1 and  keyPoints[2][1] > 1:\n",
    "                leCount += 1\n",
    "\n",
    "            if keyPoints[3][0] > 1 and  keyPoints[3][1] > 1:\n",
    "                clCount += 1\n",
    "\n",
    "            if keyPoints[4][0] > 1 and  keyPoints[4][1] > 1:\n",
    "                bkCount += 1\n",
    "    \n",
    "    landmarksCountDic['tooth_' + str(i+1)] = {'ttCount':ttCount,'lsCount':lsCount, 'leCount':leCount, 'clCount':clCount, 'bkCount':bkCount}\n",
    "        \n",
    "print(landmarksCountDic)\n",
    "print('\\n\\n')\n",
    "\n",
    "totalNbOfLogs = len(paresedResultsDict[resKey].keys())\n",
    "landmarksCountDicPerc = deepcopy(landmarksCountDic)\n",
    "for k1 in landmarksCountDicPerc.keys():\n",
    "    for k2 in landmarksCountDicPerc[k1].keys():\n",
    "        landmarksCountDicPerc[k1][k2] = landmarksCountDicPerc[k1][k2] / totalNbOfLogs\n",
    "        \n",
    "print(landmarksCountDicPerc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plotting everything on one graph for presentation.\n",
    "path2savePlots = mainPath + 'finalPlots_presentation/'\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "\n",
    "listOfRegTypes = ['keypointsForTooth_', 'rigid_keypointsForTooth_'] \n",
    "#, 'affine_keypointsForTooth_', , 'rigid_keypointsForTooth_', 'keypointsForTooth_'\n",
    "\n",
    "listOfLengthTypes = ['all_tt2ls_dict', 'valid_tt2ls_dict']\n",
    "#['all_tt2ls_dict', 'valid_tt2ls_dict','tt2_ref_ls', 'all_times_list', 'landmarks', 'all_ls2cl_dict', 'all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict','all_ls2bk_dict','all_ls2cl_dict','all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict', 'all_ls2bk_dict']\n",
    "\n",
    "listOfReferences2PlotFor = ['WMDL_2018.09.11_06.21.57']\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    \n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "        \n",
    "        plt.figure(figsize=(30,10))\n",
    "        #plt.axis([0, 130, 10, 50])\n",
    "        plt.axis([0, 250, 10, 50])\n",
    "        #plt.axis([0, 70, 30, 60])\n",
    "        ax = plt.axes()\n",
    "        ax.grid()\n",
    "\n",
    "        plt.xlabel('Hours')\n",
    "        plt.xlabel('Pixels')\n",
    "        plt.title(str(resKey + '__' + str(toothNbKey)))\n",
    "        \n",
    "        for regTypeKeyWord in listOfRegTypes:\n",
    "            for refKey in listOfReferences2PlotFor:\n",
    "                for infoKey in listOfLengthTypes:\n",
    "                    if not(regTypeKeyWord=='keypointsForTooth_' and infoKey=='valid_tt2ls_dict'):\n",
    "                        \n",
    "                        plt.plot(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'], lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'], label=str(regTypeKeyWord + '__' + str(infoKey) + '__'+ refKey + '__nbPoints:  ' + str(len(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths']))))\n",
    "\n",
    "                        plt.plot(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'], lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'],'o')\n",
    "\n",
    "                        ax.legend()\n",
    "                       \n",
    "                    \n",
    "        plt.savefig(path2savePlots + str(resKey) + '__tooth-' + str(toothNbKey) + '__ref-' + str(refKey) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plotting original lengths from filteredResultsDict \n",
    "\n",
    "path2savePlots = mainPath + 'original_groundTruthLengths/'\n",
    "\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "\n",
    "for i in range(numberOfTeeth):\n",
    "    toothLandmarkKey = 'keypointsForTooth_' + str(i + 1)\n",
    "    \n",
    "    lengths = []\n",
    "    times = []\n",
    "    \n",
    "    for time in sorted(filteredResultsDict['PH01_2800'].keys()):\n",
    "        times.append(time)\n",
    "        \n",
    "        length = filteredResultsDict['PH01_2800'][time][toothLandmarkKey][1][1] - filteredResultsDict['PH01_2800'][time][toothLandmarkKey][0][1]\n",
    "        lengths.append(length)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.axis([0, 250, 10, 50])\n",
    "    ax = plt.axes()\n",
    "    ax.grid()\n",
    "    \n",
    "    plt.xlabel('Hours')\n",
    "    plt.xlabel('Pixels')\n",
    "    plotTitle = 'originalLengths__tooth: ' + str(i + 1)\n",
    "    plt.title(plotTitle)\n",
    "\n",
    "\n",
    "    plt.plot(times, lengths, label='nbOfPoints:  ' + str(len(lengths)))\n",
    "\n",
    "    plt.plot(times, lengths,'o')\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    plt.savefig(path2savePlots + plotTitle  + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font color='red'> Sandbox Area (DO NOT DELETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# First create some toy data:\n",
    "x = np.linspace(0, 2*np.pi, 400)\n",
    "y = np.sin(x**2)\n",
    "\n",
    "# Creates just a figure and only one subplot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.set_title('Simple plot')\n",
    "\n",
    "# Creates two subplots and unpacks the output array immediately\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "ax1.plot(x, y)\n",
    "ax1.set_title('Sharing X axis')\n",
    "ax2.scatter(x, y)\n",
    "\n",
    "# Creates four polar axes, and accesses them through the returned array\n",
    "fig, axes = plt.subplots(2, 2, subplot_kw=dict(polar=True))\n",
    "axes[0, 0].plot(x, y)\n",
    "axes[1, 1].scatter(x, y)\n",
    "\n",
    "# Share a X axis with each column of subplots\n",
    "plt.subplots(2, 2, sharex='col')\n",
    "\n",
    "# Share a Y axis with each row of subplots\n",
    "plt.subplots(2, 2, sharey='row')\n",
    "\n",
    "# Share both X and Y axes with all subplots\n",
    "plt.subplots(2, 2, sharex='all', sharey='all')\n",
    "\n",
    "# Note that this is the same as\n",
    "plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "\n",
    "# Creates figure number 10 with a single subplot\n",
    "# and clears it if it already exists.\n",
    "fig, ax=plt.subplots(num=10, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ALTOGETHER (fitting trajectory curves)\n",
    "minAllowedConfidence = 0.7  #1 to 5 for conf1 --- 0-1 for conf 2 and 3\n",
    "filterBasedOnConf = 2    # 1 for conf1 2 for conf2, 3 for logConf\n",
    "degreeOfPolyn = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################  getting the arrays for trajectory fitting #########################################\n",
    "resKey = list(lengthsAndLandmarksDict.keys())[0]\n",
    "\n",
    "i = 0\n",
    "toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "\n",
    "regTypeKeyWord = 'rigid_keypointsForTooth_'\n",
    "refKey = 'WMDL_2018.09.11_06.21.57'\n",
    "infoKey = 'all_tt2ls_dict'\n",
    "\n",
    "\n",
    "#filter based on Confidence\n",
    "selectedLengths_forTraj = []\n",
    "selectedTimes_forTraj = []\n",
    "selectedConfidence_forTraj = []\n",
    "\n",
    "for i in range(len(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'])):\n",
    "    if filterBasedOnConf == 1:\n",
    "        if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['confidences'][i] >= minAllowedConfidence:\n",
    "\n",
    "            selectedLengths_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "            )\n",
    "            selectedTimes_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "            )\n",
    "            selectedConfidence_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['confidences'][i]\n",
    "            )\n",
    "\n",
    "    elif filterBasedOnConf == 2:\n",
    "        if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['secondaryConfidences'][i] >= minAllowedConfidence:\n",
    "\n",
    "            selectedLengths_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "            )\n",
    "            selectedTimes_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "            )\n",
    "            selectedConfidence_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['secondaryConfidences'][i]\n",
    "            )\n",
    "\n",
    "\n",
    "    elif filterBasedOnConf == 3:\n",
    "        if lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['logConfidence'][i] >= minAllowedConfidence:\n",
    "\n",
    "            selectedLengths_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "            )\n",
    "            selectedTimes_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i]\n",
    "            )\n",
    "            selectedConfidence_forTraj.append(\n",
    "                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['logConfidence'][i]\n",
    "            )\n",
    "\n",
    "            \n",
    "print('len selectedLengths_forTraj:  ' + str(len(selectedLengths_forTraj)))\n",
    "print()\n",
    "print('len selectedTimes_forTraj:  ' + str(len(selectedTimes_forTraj)))\n",
    "print()\n",
    "print('len selectedConfidence_forTraj:  ' + str(len(selectedConfidence_forTraj)))\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "###################  finding time index where the tooth change happens ##########################\n",
    "toothChangeLengthTresh = 10\n",
    "last_smTooth_index = -1\n",
    "last_smTooth_length = 0\n",
    "first_bgTooth_index = -1\n",
    "first_bgTooth_length = 0\n",
    "\n",
    "prevLen = selectedLengths_forTraj[0]\n",
    "for curInd in range(1, len(selectedLengths_forTraj)):\n",
    "    curLen = selectedLengths_forTraj[curInd]\n",
    "    \n",
    "    '''\n",
    "    print('curInd: ' + str(curInd))\n",
    "    print('prevLen: ' + str(prevLen))\n",
    "    print('curLen: ' + str(curLen))\n",
    "    print('curLen: ' + str((curLen - prevLen)))\n",
    "    print()\n",
    "    '''\n",
    "    \n",
    "    if (curLen - prevLen) > toothChangeLengthTresh:\n",
    "        last_smTooth_index = curInd - 1\n",
    "        first_bgTooth_index = curInd\n",
    "        last_smTooth_length = prevLen\n",
    "        first_bgTooth_length = curLen\n",
    "        break\n",
    "        \n",
    "    prevLen = curLen\n",
    "        \n",
    "print('last_smTooth_index:  ' + str(last_smTooth_index))\n",
    "print('last_smTooth_length:  ' + str(last_smTooth_length))\n",
    "print('first_bgTooth_index:  ' + str(first_bgTooth_index))\n",
    "print('first_bgTooth_length:  ' + str(first_bgTooth_length))\n",
    "print('difference:  ' + str(first_bgTooth_length - last_smTooth_length))\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################## Fit to before tooth change segment ############################\n",
    "x = np.ndarray(shape=(1,))\n",
    "y = np.ndarray(shape=(1,))\n",
    "\n",
    "for pInd in range(last_smTooth_index):\n",
    "    x = np.vstack([x, selectedTimes_forTraj[pInd]])\n",
    "    y = np.vstack([y, selectedLengths_forTraj[pInd]])\n",
    "\n",
    "x = x[1:,]\n",
    "y = y[1:,]\n",
    "x = x.reshape(-1)\n",
    "y = y.reshape(-1)\n",
    "\n",
    "z = np.polyfit(x, y, degreeOfPolyn)\n",
    "estimatedFunction_beforeToothChange = np.poly1d(z)\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "\n",
    "################## Fit to after tooth change segment ############################\n",
    "x = np.ndarray(shape=(1,))\n",
    "y = np.ndarray(shape=(1,))\n",
    "\n",
    "for pInd in range(first_bgTooth_index, len(selectedLengths_forTraj), 1):\n",
    "    x = np.vstack([x, selectedTimes_forTraj[pInd]])\n",
    "    y = np.vstack([y, selectedLengths_forTraj[pInd]])\n",
    "\n",
    "x = x[1:,]\n",
    "y = y[1:,]\n",
    "x = x.reshape(-1)\n",
    "y = y.reshape(-1)\n",
    "\n",
    "z = np.polyfit(x, y, degreeOfPolyn)\n",
    "estimatedFunction_afterToothChange = np.poly1d(z)\n",
    "######################################################################################\n",
    "\n",
    "################## # plotting the fittend lines #####################################\n",
    "pts_beforeToothChange = [estimatedFunction_beforeToothChange(time) for time in selectedTimes_forTraj[:last_smTooth_index]]\n",
    "\n",
    "pts_afterToothChange = [estimatedFunction_afterToothChange(time) for time in selectedTimes_forTraj[first_bgTooth_index:]]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.axis([0, 250, 10, 50])\n",
    "ax = plt.axes()\n",
    "ax.grid()\n",
    "\n",
    "plt.xlabel('Hours')\n",
    "plt.xlabel('Pixels')\n",
    "\n",
    "\n",
    "plt.plot(selectedTimes_forTraj, selectedLengths_forTraj)\n",
    "plt.plot(selectedTimes_forTraj, selectedLengths_forTraj,'o')\n",
    "\n",
    "plt.plot(selectedTimes_forTraj[:last_smTooth_index], pts_beforeToothChange)\n",
    "plt.plot(selectedTimes_forTraj[first_bgTooth_index:], pts_afterToothChange)\n",
    "\n",
    "plt.savefig(mainPath + 'finalPlots/fitted.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRegisteredPoints(refkeyPointsDic, resDicForFrame, numberOfTeeth, numberOfLandmarks = 5):\n",
    "    srcAr = []\n",
    "    trgAr = []\n",
    "    indexToKeyMap = []\n",
    "    resultsArRigid = [[[0, 0] for j in range(numberOfLandmarks)] for i in range(numberOfTeeth)]\n",
    "    resultsArAfine = [[[0, 0] for j in range(numberOfLandmarks)] for i in range(numberOfTeeth)]\n",
    "    \n",
    "    \n",
    "    landmakrsList = ['toothTip_', 'lipShroud_', 'liftingEye_', 'castLip_', 'bucketLandmark_']\n",
    "    \n",
    "    for i in range(1, numberOfLandmarks, 1): #do not use toothtip (i=0) landmarks in calculating transfromation\n",
    "        keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "        \n",
    "        if keypointsKey in resDicForFrame:\n",
    "            keyPoints = resDicForFrame[keypointsKey]\n",
    "            \n",
    "            for j in range(numberOfTeeth):\n",
    "                if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                    srcAr.append(keyPoints[j])\n",
    "                    trgAr.append(refkeyPointsDic[landmakrsList[i] + str(j+1)])\n",
    "        \n",
    "        \n",
    "    srcPoints = getRegPointSetFromArray(srcAr)\n",
    "    trgPoints = getRegPointSetFromArray(trgAr)\n",
    "        \n",
    "    transformationRigid = cv2.estimateRigidTransform(srcPoints, trgPoints, False)\n",
    "    transformationAffine= cv2.estimateRigidTransform(srcPoints, trgPoints, True)\n",
    "    \n",
    "    \n",
    "############################################################################################################### \n",
    "    points2moveAr = []\n",
    "    for i in range(numberOfLandmarks):\n",
    "        keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "        if keypointsKey in resDicForFrame:\n",
    "            keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "            for j in range(numberOfTeeth):\n",
    "                if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                    indexToKeyMap.append({'landmarkNb': i, 'toothNb':j})\n",
    "                    points2moveAr.append(keyPoints[j])\n",
    "\n",
    "\n",
    "    points2move = getRegPointSetFromArray(points2moveAr)\n",
    "###############################################################################################################    \n",
    "    if not transformationRigid is None:\n",
    "        if transformationRigid.any():\n",
    "            transformedPointsRigid = cv2.transform(points2move, transformationRigid)\n",
    "    else:\n",
    "        print('failed to find Rigid transformation for:')\n",
    "        print(resDicForFrame['fileName'])\n",
    "        \n",
    "    if not transformationAffine is None:\n",
    "        if transformationAffine.any():\n",
    "            transformedPointsAffine = cv2.transform(points2move, transformationAffine)\n",
    "    else:\n",
    "        print('failed to find Affine transformation for:')\n",
    "        print(resDicForFrame['fileName'])\n",
    "    \n",
    "    \n",
    "    if not transformationRigid is None:\n",
    "        if transformationRigid.any():\n",
    "            for i in range(transformedPointsRigid.shape[1]):\n",
    "                pointRigid =  transformedPointsRigid[0, i, :].tolist()\n",
    "                resultsArRigid[indexToKeyMap[i]['toothNb']][indexToKeyMap[i]['landmarkNb']] = pointRigid\n",
    "                \n",
    "                \n",
    "                \n",
    "    if not transformationAffine is None:\n",
    "        if transformationAffine.any():\n",
    "            for i in range(transformedPointsAffine.shape[1]):\n",
    "                pointAffine = transformedPointsAffine[0, i, :].tolist()\n",
    "                resultsArAfine[indexToKeyMap[i]['toothNb']][indexToKeyMap[i]['landmarkNb']] = pointAffine\n",
    "        \n",
    "        \n",
    "    return resultsArRigid, resultsArAfine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRegisteredPointsV2(refkeyPointsDic, resDicForFrame, numberOfTeeth, verbose = False, numberOfLandmarks = 5):\n",
    "    bestErrorSoFar = 10000\n",
    "    curError = bestErrorSoFar\n",
    "    bestResultsSoFar = []\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############################################################################################################\n",
    "    #################################### USE ALL LANDMARKS ########################################\n",
    "    ###############################################################################################################\n",
    "    srcAr = []\n",
    "    trgAr = []\n",
    "    indexToKeyMap = []\n",
    "    resultsArRigid = [[[0, 0] for j in range(numberOfLandmarks)] for i in range(numberOfTeeth)]\n",
    "\n",
    "\n",
    "    landmakrsList = ['toothTip_', 'lipShroud_', 'liftingEye_', 'castLip_', 'bucketLandmark_']\n",
    "\n",
    "    for i in range(1, numberOfLandmarks, 1): #do not use toothtip (i=0) landmarks in calculating transfromation\n",
    "        keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "        if keypointsKey in resDicForFrame:\n",
    "            keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "            for j in range(numberOfTeeth):\n",
    "                if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                    srcAr.append(keyPoints[j])\n",
    "                    trgAr.append(refkeyPointsDic[landmakrsList[i] + str(j+1)])\n",
    "\n",
    "\n",
    "    srcPoints = getRegPointSetFromArray(srcAr)\n",
    "    trgPoints = getRegPointSetFromArray(trgAr)\n",
    "\n",
    "    transformationRigid = cv2.estimateRigidTransform(srcPoints, trgPoints, False)\n",
    "\n",
    "############################################################################################################### \n",
    "    points2moveAr = []\n",
    "    for i in range(numberOfLandmarks):\n",
    "        keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "        if keypointsKey in resDicForFrame:\n",
    "            keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "            for j in range(numberOfTeeth):\n",
    "                if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                    indexToKeyMap.append({'landmarkNb': i, 'toothNb':j})\n",
    "                    points2moveAr.append(keyPoints[j])\n",
    "\n",
    "\n",
    "    points2move = getRegPointSetFromArray(points2moveAr)\n",
    "###############################################################################################################    \n",
    "    if not transformationRigid is None:\n",
    "        if transformationRigid.any():\n",
    "            transformedPointsRigid = cv2.transform(points2move, transformationRigid)\n",
    "\n",
    "            for i in range(transformedPointsRigid.shape[1]):\n",
    "                pointRigid =  transformedPointsRigid[0, i, :].tolist()\n",
    "                resultsArRigid[indexToKeyMap[i]['toothNb']][indexToKeyMap[i]['landmarkNb']] = pointRigid\n",
    "\n",
    "            curError = getRegError(transformedPointsRigid, srcPoints)\n",
    "            \n",
    "            if verbose:\n",
    "                print('RegidTransformation error using all landmarks was:  ' + str(curError) + '\\n')\n",
    "            \n",
    "            if curError < bestErrorSoFar:\n",
    "                bestErrorSoFar = curError\n",
    "                bestResultsSoFar = resultsArRigid\n",
    "    else:\n",
    "        print('failed to find Rigid transformation using all landmarks for:')\n",
    "        print(resDicForFrame['fileName'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ###############################################################################################################\n",
    "    #################################### USE JUST LIPSHROUD ########################################\n",
    "    ###############################################################################################################      \n",
    "    srcAr = []\n",
    "    trgAr = []\n",
    "    indexToKeyMap = []\n",
    "    resultsArRigid = [[[0, 0] for j in range(numberOfLandmarks)] for i in range(numberOfTeeth)]\n",
    "\n",
    "\n",
    "    landmakrsList = ['toothTip_', 'lipShroud_', 'liftingEye_', 'castLip_', 'bucketLandmark_']\n",
    "\n",
    "    i = 1 # use only lipShroud landmarks for registration\n",
    "    keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "    if keypointsKey in resDicForFrame:\n",
    "        keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "        for j in range(numberOfTeeth):\n",
    "            if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                srcAr.append(keyPoints[j])\n",
    "                trgAr.append(refkeyPointsDic[landmakrsList[i] + str(j+1)])\n",
    "\n",
    "\n",
    "    srcPoints = getRegPointSetFromArray(srcAr)\n",
    "    trgPoints = getRegPointSetFromArray(trgAr)\n",
    "\n",
    "    transformationRigid = cv2.estimateRigidTransform(srcPoints, trgPoints, False)\n",
    "\n",
    "############################################################################################################### \n",
    "    points2moveAr = []\n",
    "    for i in range(numberOfLandmarks):\n",
    "        keypointsKey = 'keypoints_' + str(i + 1 )\n",
    "\n",
    "        if keypointsKey in resDicForFrame:\n",
    "            keyPoints = resDicForFrame[keypointsKey]\n",
    "\n",
    "            for j in range(numberOfTeeth):\n",
    "                if keyPoints[j] in resDicForFrame['validatedKeypoints']:\n",
    "                    indexToKeyMap.append({'landmarkNb': i, 'toothNb':j})\n",
    "                    points2moveAr.append(keyPoints[j])\n",
    "\n",
    "\n",
    "    points2move = getRegPointSetFromArray(points2moveAr)\n",
    "###############################################################################################################    \n",
    "    if not transformationRigid is None:\n",
    "        if transformationRigid.any():\n",
    "            transformedPointsRigid = cv2.transform(points2move, transformationRigid)\n",
    "\n",
    "            for i in range(transformedPointsRigid.shape[1]):\n",
    "                pointRigid =  transformedPointsRigid[0, i, :].tolist()\n",
    "                resultsArRigid[indexToKeyMap[i]['toothNb']][indexToKeyMap[i]['landmarkNb']] = pointRigid\n",
    "\n",
    "            curError = getRegError(transformedPointsRigid, srcPoints)\n",
    "            \n",
    "            if verbose:\n",
    "                print('RegidTransformation error using just LipShrouds was:  ' + str(curError) + '\\n')\n",
    "            \n",
    "            if curError < bestErrorSoFar:\n",
    "                print('RegidTransformation using just lipShroud was better than using all landmarks for log:\\n' + str(resDicForFrame['fileName']) +  '\\nusing all landmarks the error was  ' + str(bestErrorSoFar) + '  using just lipshrouds it was  ' + str(curError) + '\\n')\n",
    "                \n",
    "                \n",
    "                bestErrorSoFar = curError\n",
    "                bestResultsSoFar = resultsArRigid\n",
    "                \n",
    "\n",
    "    else:\n",
    "        print('failed to find Rigid transformation using just LipShrouds for:')\n",
    "        print(resDicForFrame['fileName'])\n",
    "        \n",
    "\n",
    "        \n",
    "    return bestResultsSoFar, bestErrorSoFar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (Version 2) plot all registered lengths for all teeht and all registeration types and all references\n",
    "\n",
    "path2savePlots = mainPath + 'finalPlots/'\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "\n",
    "listOfRegTypes = ['rigid_keypointsForTooth_'] \n",
    "#, 'affine_keypointsForTooth_', , 'rigid_keypointsForTooth_', 'keypointsForTooth_'\n",
    "\n",
    "listOfLengthTypes = ['valid_tt2ls_dict']\n",
    "#['all_tt2ls_dict', 'valid_tt2ls_dict','tt2_ref_ls', 'all_times_list', 'landmarks', 'all_ls2cl_dict', 'all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict','all_ls2bk_dict','all_ls2cl_dict','all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict', 'all_ls2bk_dict']\n",
    "\n",
    "listOfReferences2PlotFor = ['WMDL_2018.09.11_06.21.57'] #references2use\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    \n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "\n",
    "        for regTypeKeyWord in listOfRegTypes:\n",
    "            for refKey in listOfReferences2PlotFor:\n",
    "                for infoKey in listOfLengthTypes:\n",
    "                    if not(regTypeKeyWord=='keypointsForTooth_' and infoKey=='valid_tt2ls_dict'):\n",
    "                        \n",
    "                        plt.figure(figsize=(30,10))\n",
    "                        #plt.axis([0, 130, 10, 50])\n",
    "                        plt.axis([0, 250, 10, 50])\n",
    "                        #plt.axis([0, 70, 30, 60])\n",
    "                        ax = plt.axes()\n",
    "                        ax.grid()\n",
    "\n",
    "                        plt.xlabel('Hours')\n",
    "                        plt.xlabel('Pixels')\n",
    "                        \n",
    "                        plotTitle = str(resKey + '__' + str(toothNbKey) + '__' + regTypeKeyWord + '__' + infoKey + '__'+ refKey)\n",
    "                        plt.title(plotTitle)\n",
    "                        \n",
    "                        plt.plot(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'], lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'], label='nbOfPoints: ' + str(len(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'])))\n",
    "\n",
    "                        plt.plot(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'], lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'],'o')\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        for i in range(len(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'])):\n",
    "                            ax.annotate(\n",
    "                                lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['confidences'][i],\n",
    "                                (\n",
    "                                    lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'][i],\n",
    "                                    lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'][i]\n",
    "                                )\n",
    "                            )\n",
    "                            \n",
    "                            \n",
    "                        \n",
    "                        ax.legend()\n",
    "\n",
    "                        plt.savefig(path2savePlots + plotTitle + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (Version 1) plot all registered lengths for all teeht and all registeration types and all references\n",
    "\n",
    "path2savePlots = mainPath + 'finalPlots/'\n",
    "\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "listOfRegTypes = ['rigid_keypointsForTooth_'] #, 'affine_keypointsForTooth_','keypointsForTooth_'\n",
    "listOfLengthTypes = ['valid_tt2ls_dict']#'all_tt2ls_dict',    ['tt2_ref_ls', 'all_times_list', 'landmarks', 'all_ls2cl_dict', 'all_le2bk_dict', 'all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict','all_ls2bk_dict','all_ls2cl_dict','all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict', 'all_ls2bk_dict']\n",
    "\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    \n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "        \n",
    "        for regTypeKeyWord in listOfRegTypes:\n",
    "            \n",
    "            if regTypeKeyWord == 'keypointsForTooth_':\n",
    "\n",
    "                for infoKey in lengthsAndLandmarksDict[resKey][regTypeKeyWord][toothNbKey].keys():\n",
    "                    if infoKey in listOfLengthTypes:\n",
    "                        #print('\\n' + str(infoKey))\n",
    "\n",
    "                        plt.figure(figsize=(30,10))\n",
    "                        #plt.axis([0, 130, 10, 50])\n",
    "                        plt.axis([0, 250, 10, 50])\n",
    "                        #plt.axis([0, 70, 30, 60])\n",
    "                        ax = plt.axes()\n",
    "                        ax.grid()\n",
    "\n",
    "\n",
    "                        plt.plot(lengthsAndLandmarksDict[resKey][regTypeKeyWord][toothNbKey][infoKey]['times'], lengthsAndLandmarksDict[resKey][regTypeKeyWord][toothNbKey][infoKey]['lengths'], label=str(resKey + ': ' + regTypeKeyWord + ': ' + str(toothNbKey) + ': ' + str(infoKey)))\n",
    "\n",
    "                        plt.plot(lengthsAndLandmarksDict[resKey][regTypeKeyWord][toothNbKey][infoKey]['times'], lengthsAndLandmarksDict[resKey][regTypeKeyWord][toothNbKey][infoKey]['lengths'],'ro')\n",
    "\n",
    "                        ax.legend()\n",
    "\n",
    "                        plt.savefig(path2savePlots + str(resKey) + '_' + str(toothNbKey) + '_' + str(infoKey) + '_' + str(regTypeKeyWord) + '.png')\n",
    "\n",
    "                        #plt.show()\n",
    "\n",
    "            else:\n",
    "                for refKey in lengthsAndLandmarksDict[resKey][regTypeKeyWord]:\n",
    "                    \n",
    "                    for infoKey in lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey].keys():\n",
    "                        if infoKey in listOfLengthTypes:\n",
    "                            #print('\\n' + str(infoKey))\n",
    "\n",
    "                            plt.figure(figsize=(30,10))\n",
    "                            #plt.axis([0, 130, 10, 50])\n",
    "                            plt.axis([0, 250, 10, 50])\n",
    "                            #plt.axis([0, 70, 30, 60])\n",
    "                            ax = plt.axes()\n",
    "                            ax.grid()\n",
    "\n",
    "\n",
    "                            plt.plot(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'], lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'], label=str(resKey + ': ' + regTypeKeyWord + ': '+ refKey + ': ' + str(toothNbKey) + ': ' + str(infoKey)))\n",
    "\n",
    "                            plt.plot(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['times'], lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'],'ro')\n",
    "\n",
    "                            ax.legend()\n",
    "\n",
    "                            plt.savefig(path2savePlots + str(resKey) + '_' + str(toothNbKey) + '_' + str(infoKey) + '_' + str(regTypeKeyWord) + '_ref-' + str(refKey) + '.png')\n",
    "\n",
    "                            #plt.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Smoothing Lengths Using combination of multiple refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pre-process for smoothing (this adds mooth dict, which stores the lengths using all refs, for each point)\n",
    "\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "listOfRegTypes = ['rigid_keypointsForTooth_']\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    \n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "        lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey]['all_lengths'] = {}\n",
    "        \n",
    "        for timeStep in sorted(lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey]['all_times']):\n",
    "            \n",
    "            if timeStep not in lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey]['all_lengths'].keys():\n",
    "                lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey]['all_lengths'][timeStep] = []\n",
    "                \n",
    "            for regTypeKeyWord in listOfRegTypes:\n",
    "\n",
    "                for refKey in references2use:\n",
    "                    if refKey in lengthsAndLandmarksDict[resKey]['forSmoothing']\\\n",
    "                    [toothNbKey][regTypeKeyWord].keys():\n",
    "                        \n",
    "                        if timeStep in lengthsAndLandmarksDict[resKey]['forSmoothing']\\\n",
    "                        [toothNbKey][regTypeKeyWord][refKey].keys():\n",
    "                            \n",
    "                            lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey]['all_lengths'][timeStep].append(lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey][regTypeKeyWord][refKey][timeStep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calculating the std of lengths \n",
    "\n",
    "import statistics \n",
    "\n",
    "numberOfTeeth = NUMBER_OF_TEETH\n",
    "regTypeKeyWord = 'rigid_keypointsForTooth_'\n",
    "infoKey =  'all_tt2ls_dict'\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    print(resKey)\n",
    "    \n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "\n",
    "        for refKey in references2use:\n",
    "            print(str(toothNbKey) + '  --' + str(refKey) + '\\n')\n",
    "\n",
    "            stdB = statistics.stdev(lengthsAndLandmarksDict[resKey][regTypeKeyWord][refKey][toothNbKey][infoKey]['lengths'])\n",
    "            stdA = statistics.stdev(lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey][regTypeKeyWord][refKey].values())\n",
    "\n",
    "            if not stdB == stdA:\n",
    "                print(\"std BEFORE smoothing is: \" + str(stdB))\n",
    "                print(\"std AFTER  smoothing is: \" + str(stdA))\n",
    "            else:\n",
    "                print(\"std both Before and After smoothing is: \" + str(stdA))\n",
    "                print('\\n\\n')\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "'''\n",
    "listOfRegTypes = ['rigid_keypointsForTooth_','keypointsForTooth_'] #, 'affine_keypointsForTooth_'\n",
    "listOfLengthTypes = ['all_tt2ls_dict', 'valid_tt2ls_dict', 'tt2_ref_ls']#['all_times_list', 'landmarks', 'all_ls2cl_dict', 'all_le2bk_dict', 'all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict','all_ls2bk_dict','all_ls2cl_dict','all_le2bk_dict','all_cl2bk_dict','all_le2cl_dict','all_ls2le_dict', 'all_ls2bk_dict']\n",
    "\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    \n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "        \n",
    "        for regTypeKeyWord in listOfRegTypes:\n",
    "\n",
    "            for infoKey in lengthsAndLandmarksDict[resKey][regTypeKeyWord][toothNbKey].keys():\n",
    "                if infoKey in listOfLengthTypes:\n",
    "                \n",
    "                    print('\\n' + str(resKey + ': ' + regTypeKeyWord + ': ' + str(toothNbKey) + ': ' + str(infoKey)))\n",
    "                    \n",
    "                    std = statistics.stdev(lengthsAndLandmarksDict[resKey][regTypeKeyWord][toothNbKey][infoKey]['lengths'])\n",
    "                    \n",
    "                    print(\"Calculated std is: \" + str(std) + '\\n')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look at the number of points for each ref, before and after smoothing\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "        \n",
    "        print(toothNbKey)\n",
    "        \n",
    "        for refKey in references2use:\n",
    "            print('\\nnumber of time steps for ref:  ' + refKey)\n",
    "            print('BEFORE smoothing:')\n",
    "            print(len(lengthsAndLandmarksDict[resKey]['rigid_keypointsForTooth_'][refKey][toothNbKey]['all_tt2ls_dict']['lengths']))\n",
    "            print('AFTER smoothing:')\n",
    "            print(len(lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey]['rigid_keypointsForTooth_'][refKey].keys()))\n",
    "            \n",
    "        print('\\n\\n\\n\\n\\n***********************************************')\n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test out the final number of points for each time step (you should only have as many points as you have refs)\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "        \n",
    "        print('for:  ' + toothNbKey)\n",
    "        \n",
    "        for key in sorted(lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey]['all_lengths'].keys()):\n",
    "            finalNbPointsForEachTimeStamp = len(lengthsAndLandmarksDict[resKey]['forSmoothing'][toothNbKey]['all_lengths'][key])\n",
    "\n",
    "            if finalNbPointsForEachTimeStamp < len(references2use):\n",
    "                print('for timeStep:  ' + str(key) + '  we have  ' + str(finalNbPointsForEachTimeStamp) + '   points but were expecting  ' + str(len(references2use)) +'  since that is the number of referenceFrames we registered to.')\n",
    "                \n",
    "                \n",
    "        print('\\n\\n\\n\\n\\n***********************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look at the values of different refs\n",
    "\n",
    "for resKey in lengthsAndLandmarksDict.keys():\n",
    "    for i in range(numberOfTeeth):\n",
    "        toothNbKey = 'tooth_' + str(i + 1) + '_info'\n",
    "        \n",
    "        print('for:  ' + toothNbKey)\n",
    "        \n",
    "        for refKey in references2use:\n",
    "\n",
    "            print(refKey)\n",
    "\n",
    "            if len(lengthsAndLandmarksDict[resKey]['rigid_keypointsForTooth_'][refKey][toothNbKey]['all_tt2ls_dict']['lengths']) > 0:\n",
    "\n",
    "\n",
    "                print(lengthsAndLandmarksDict[resKey]['rigid_keypointsForTooth_'][refKey][toothNbKey]['all_tt2ls_dict']['lengths'][0])\n",
    "                print(lengthsAndLandmarksDict[resKey]['rigid_keypointsForTooth_'][refKey][toothNbKey]['all_tt2ls_dict']['times'][0])\n",
    "\n",
    "\n",
    "            else:\n",
    "                print('*** IS EMPTY ***')\n",
    "\n",
    "\n",
    "            print()\n",
    "            \n",
    "            \n",
    "        print('\\n\\n\\n\\n\\n***********************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Calculating shortest distance from a point to a curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using scipy.cobyla Calculating shortest distance from a point to a curve\n",
    "from scipy.optimize import fmin_cobyla\n",
    "\n",
    "testPoint = [200, 100]\n",
    "curveFunc = np.lib.polynomial.poly1d([ 1.02736672e-03, -6.39722264e-01,  3.87908611e+02])\n",
    "\n",
    "maxItr = 10\n",
    "\n",
    "def minimizationObjective(X):\n",
    "    x,y = X\n",
    "    return np.sqrt( (x - testPoint[0])**2 + (y - testPoint[1])**2 )\n",
    "\n",
    "def minimizationCritaria(X):\n",
    "    #fmin_cobyla will make sure this is always >= 0. So I'm making sure this is > 0 only when the point is on the curve.\n",
    "    x,y = X\n",
    "    return abs(curveFunc(x) - y)*-1\n",
    "\n",
    "minDistanceSoFar = sys.maxsize\n",
    "initialGuess = testPoint\n",
    "\n",
    "for itr in range(maxItr):\n",
    "    projectedPoint = fmin_cobyla(minimizationObjective, x0=initialGuess, cons=[minimizationCritaria])\n",
    "    curDistance = minimizationObjective(projectedPoint)\n",
    "\n",
    "    print('itr:  ' + str(itr))\n",
    "    print('minDistanceSoFar:   ' + str(minDistanceSoFar))\n",
    "    print('projectedPoint is:   ' + str(projectedPoint))\n",
    "    print('shortestDistance is:  ' + str(curDistance))\n",
    "    \n",
    "    \n",
    "    x = np.linspace(-100, 1000, 100)\n",
    "\n",
    "    plt.plot(x, curveFunc(x), 'r-', label='f(x)')\n",
    "    plt.plot(testPoint[0], testPoint[1], 'bo', label='testPoint')\n",
    "    plt.plot(projectedPoint[0], projectedPoint[1], 'bx', label='projectedPoint')\n",
    "    plt.plot([testPoint[0], projectedPoint[0]], [testPoint[1], projectedPoint[1]], 'g-', label='shortest distance')\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    if curDistance < minDistanceSoFar:\n",
    "        minDistanceSoFar = curDistance\n",
    "        initialGuess = projectedPoint\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "x = np.linspace(-100, 1000, 100)\n",
    "\n",
    "plt.plot(x, curveFunc(x), 'r-', label='f(x)')\n",
    "plt.plot(testPoint[0], testPoint[1], 'bo', label='testPoint')\n",
    "plt.plot(projectedPoint[0], projectedPoint[1], 'bx', label='projectedPoint')\n",
    "plt.plot([testPoint[0], projectedPoint[0]], [testPoint[1], projectedPoint[1]], 'g-', label='shortest distance')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# find shortest distance using fminbound\n",
    "\n",
    "from scipy.optimize import fminbound\n",
    "\n",
    "testPoint = [200, 100]\n",
    "curveFunc = np.lib.polynomial.poly1d([ 1.02736672e-03, -6.39722264e-01,  3.87908611e+02])\n",
    "\n",
    "\n",
    "def minimizationObjective(x):\n",
    "    return np.sqrt( (x - testPoint[0])**2 + (curveFunc(x) - testPoint[1])**2 )\n",
    "    #return int( (x - testPoint[0])**2 + (curveFunc(x) - testPoint[1])**2 )\n",
    "    #return abs(curveFunc(x) - testPoint[1])\n",
    "\n",
    "\n",
    "mindist = fminbound(minimizationObjective, -1000, 1000)\n",
    "\n",
    "print('shortest distance is:   ' + str(mindist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Unused Image2Image Registeration techniques available in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing transformations (by Mahdi)\n",
    "\n",
    "import numpy as np\n",
    "def rotationmatrix(theta):\n",
    "    R = np.array([[np.cos(np.pi*theta/180), -np.sin(np.pi*theta/180),  0],\n",
    "          [np.sin(np.pi*theta/180), np.cos(np.pi*theta/180), 0],\n",
    "          [0,0,1]])\n",
    "    return R\n",
    "\n",
    "def translationmatrix(tx,ty):\n",
    "    T = np.array([[1, 0,  tx],\n",
    "          [0, 1, ty],\n",
    "          [0,0,1]])\n",
    "    return T\n",
    "\n",
    "def scalematrix(sx,sy):\n",
    "    S = np.array([[sx, 0,  0],\n",
    "          [0, sy, 0],\n",
    "          [0,0,1]])\n",
    "    return S\n",
    "\n",
    "\n",
    "def rigidtransform(sx=1,sy=1, tx=0, ty = 0, theta = 0):\n",
    "    R = rotationmatrix(theta)\n",
    "    T = translationmatrix(tx,ty)\n",
    "    S = scalematrix(sx,sy)\n",
    "    transformMatrix = np.matmul(S,np.matmul(R,T))\n",
    "    return transformMatrix\n",
    "\n",
    "def transformpoints(points, transformMatrix):\n",
    "    if points.shape[1] < 3:\n",
    "        points = np.concatenate((points, np.ones((points.shape[0],1))),axis = 1).T\n",
    "    trans_points = np.matmul(transformMatrix, points)\n",
    "    return trans_points[0:2,:].T\n",
    "\n",
    "\n",
    "transformMatrix = rigidtransform(2,2,0,0,90)\n",
    "points = np.array([[1,0],[1,1],[0,-1]])\n",
    "new_points = transformpoints(points, transformMatrix)\n",
    "\n",
    "\n",
    "cv2.estimateRigidTransform(np.float64(points[np.newaxis,:]), new_points[np.newaxis,:], False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# no need for these. These take only 3 and 4 points (respectively) and solve an exact transformation (instead of an estimated one)\n",
    "\n",
    "# Define the motion model\n",
    "warp_mode = cv2.MOTION_TRANSLATION\n",
    "\n",
    "# Specify the number of iterations.\n",
    "number_of_iterations = 5000;\n",
    " \n",
    "# Specify the threshold of the increment\n",
    "# in the correlation coefficient between two iterations\n",
    "termination_eps = 1e-10;\n",
    "\n",
    "# Define termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations,  termination_eps)\n",
    "\n",
    "# Find size of image1\n",
    "sz = img1.shape\n",
    " \n",
    "\n",
    "# Define 2x3 or 3x3 matrices and initialize the matrix to identity\n",
    "if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "    warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "else :\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "im1_gray = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "im2_gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Run the ECC algorithm. The results are stored in warp_matrix.\n",
    "(cc, warp_matrix) = cv2.findTransformECC (im1_gray,im2_gray,warp_matrix, warp_mode, criteria)\n",
    "\n",
    "im2_aligned = cv2.warpAffine(im2_gray, warp_matrix, (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP);\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.title('img1')\n",
    "plt.show()\n",
    "plt.imshow(img2)\n",
    "plt.title('img2')\n",
    "plt.show()\n",
    "plt.imshow(im2_aligned)\n",
    "plt.title('im2_aligned')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# no need for these. These take only 3 and 4 points (respectively) and solve an exact transformation (instead of an estimated one)\n",
    "\n",
    "transformationAffine = cv2.getAffineTransform(landmarksSet1, landmarksSet2)\n",
    "transformationPerspective = cv2.getPerspectiveTransform(landmarksSet1, landmarksSet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (Debug) single frame of above : Fit curves to landmarks and plot them for a single frame\n",
    "resultsKey = 'wmdlLogs_Pinto'\n",
    "imgFileName = 'WMDL_2017.10.18_22.53.03.png'\n",
    "logNb = getFrameTime(filteredResultsDict, resultsKey, imgFileName)\n",
    "\n",
    "\n",
    "fittC = fitCurve2keypoints(filteredResultsDict[resultsKey][logNb], 6)\n",
    "\n",
    "inImage = cv2.imread(wmsDir + imgFileName)\n",
    "\n",
    "outImage =  draw_all_keypoints_boxes_andCurves(inImage, filteredResultsDict[resultsKey][logNb], fittC, 6)\n",
    "\n",
    "plt.imshow(outImage)\n",
    "plt.show()\n",
    "\n",
    "for key in fittC.keys():\n",
    "    print(key)\n",
    "    print(fittC[key].deriv().deriv().c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calculate the second derivative of a curve. For validation.\n",
    "secondDerivative = fittC['keypoints_4'].deriv().deriv().c[0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
